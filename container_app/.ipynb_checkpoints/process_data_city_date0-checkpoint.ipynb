{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from glob import glob \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fix_datetime(df, timevar='created_at_h'):\n",
    "    df[timevar] = pd.to_datetime(df[timevar])\n",
    "\n",
    "def fix_token_counter(df):\n",
    "    df.token_counter = df.token_counter.apply(lambda x: Counter(x))  \n",
    "\n",
    "def fix_RT_id(df):\n",
    "    df.RT_id = df.RT_id.astype(str) \n",
    "\n",
    "\n",
    "def convert_floats(df, float_dtype='float32'):\n",
    "    floats = df.select_dtypes(include=['float64']).columns.tolist()\n",
    "    df[floats] = df[floats].astype(float_dtype)\n",
    "    return df\n",
    "\n",
    "def tw_data_files_to_df_csv(files):\n",
    "    '''append and concat data files into a pandas.DataFrame'''\n",
    "    df = []\n",
    "    [ df.append(pd.read_csv(file)) for file in files ]\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def tw_data_files_to_df_csv2(files, frac=0.05, float_dtype=None):\n",
    "    '''append and concat a sample of data into a pandas.DataFrame'''\n",
    "    df = []\n",
    "    [ df.append(pd.read_csv(file, low_memory=True)\n",
    "        .sample(frac=frac, replace=True)) for file in files ]\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    if float_dtype is None: return df\n",
    "    return convert_floats(df, float_dtype)\n",
    "\n",
    "\n",
    "def tw_data_files_to_df_json(files, lines=False):\n",
    "    '''append and concat data files into a pandas.DataFrame'''\n",
    "    df = []\n",
    "    [ df.append(pd.read_json(file, orient='records', lines=lines)) for file in files ]\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def tw_data_files_to_df_json3(files, lines=False, frac=0.05, float_dtype=None, verbose=False):\n",
    "    '''append and concat a sample of data into a pandas.DataFrame'''\n",
    "    df = []\n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)\n",
    "        df.append(pd.read_json(file, orient='records', lines=lines)\n",
    "                 .sample(frac=frac, replace=True)) \n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    if float_dtype is None: return df\n",
    "    return convert_floats(df, float_dtype)\n",
    "\n",
    "def keep_recent_files(files, base_timestamp, file_type= '.json', days = 14):\n",
    "    timestamps = [pd.Timestamp(file.split('created_at_',1)[1]\n",
    "                               .replace(file_type,'').replace('_',' ')) for file in files ]\n",
    "    keep_idx1 = [(base_timestamp - timestamp) <= pd.Timedelta(days, unit='d') for timestamp in timestamps]\n",
    "    return(list(itertools.compress(files,keep_idx1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/kotaminegishi/big_data_training/python/dash_demo1/'\n",
    "data_dest = '/Users/kotaminegishi/big_data_training/python/dash_demo1/'\n",
    "\n",
    "process_datatime = pd.to_datetime(datetime(2020,7,13))\n",
    "process_datatime_d = process_datatime.floor('d')\n",
    "#_dt = latest_datatime.floor('d').to_pydatetime()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/retweet/created_at_2020-07-04_00:00:00.json', orient='records', lines=True)\n",
    "idx = [mark_tokens_contain_keyword(df, keyword) for keyword in ['Los Angeles','L.A.','L. A.']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(idx).agg(max).astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_tokens_contain_keyword(df, keyword):\n",
    "    # returns an index indicating whether variable 'tokens' contains keyword\n",
    "    return df.tokens.apply(lambda x: keyword.lower() in x)\n",
    "\n",
    "def mark_tokens_contain_keywords(df, keywords):\n",
    "    idx = [mark_tokens_contain_keyword(df, keyword) for keyword in keywords]\n",
    "    return pd.DataFrame(idx).agg(max).astype(bool)\n",
    "    \n",
    "def mark_tokens_contain_keyword_jointly(df, keywords):\n",
    "    # returns an index indicating whether variable 'tokens' contains keyword\n",
    "    idx = [mark_tokens_contain_keyword(df, keyword) for keyword in keywords]\n",
    "    return pd.DataFrame(idx).agg(min).astype(bool) \n",
    "    \n",
    "def get_columns_json(file):\n",
    "    chunk1 = pd.read_json(file, chunksize=1, orient='records', lines=True)\n",
    "    data1 = [d.iloc[0] for d in chunk1]\n",
    "    return list(data1[0].keys())\n",
    "\n",
    "def get_columns_csv(file):\n",
    "    chunk1 = pd.read_csv(file, chunksize=1)\n",
    "    return list(chunk1.read(1).keys())\n",
    "\n",
    "\n",
    "def tw_data_files_to_df_json_filter(files, filter_word, lines=True, float_dtype=None, verbose=False):\n",
    "    '''append and concat filtered data into a pandas.DataFrame'''\n",
    "    if type(filter_word) != list: raise ValueError(\"filter_word must be a list\")\n",
    "\n",
    "    df = []\n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files[0]:\n",
    "            columns = get_columns_json(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            \n",
    "        df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        if (len(filter_word) >1): idx = mark_tokens_contain_keywords(df_file, filter_word)\n",
    "        else: idx = mark_tokens_contain_keyword(df_file, filter_word[0])\n",
    "        df_file_filtered = df_file[idx]\n",
    "        if len(df_file_filtered)>0:\n",
    "            df.append(df_file_filtered)\n",
    "    \n",
    "    if len(df)==0: return df_null\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    if float_dtype is None: return df\n",
    "    return convert_floats(df, float_dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_csv(file):\n",
    "    chunk1 = pd.read_csv(file, chunksize=1)\n",
    "    return list(chunk1.read(1).keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'created_at_h', 'neg', 'neu', 'pos', 'compound']"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_columns_csv(files_sentiments[0])\n",
    "#chunk1 = pd.read_csv(files_sentiments[0], chunksize=1)\n",
    "#[d for d in chunk1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_retweet = pd.read_json(data_dest + \"data_cumulative/retweet/2020_all_retweets.json\",\n",
    "         lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  30799939\n",
       "1                 319901933\n",
       "2                 422798683\n",
       "3       1163289131394334720\n",
       "4                2473243064\n",
       "               ...         \n",
       "8316    1115637931094360064\n",
       "8317               68568238\n",
       "8318             1654567320\n",
       "8319               49330477\n",
       "8320               19598680\n",
       "Name: user_id, Length: 8321, dtype: object"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_retweet.RT_id.astype(str)\n",
    "cum_retweet.user_id.astype(str)\n",
    "cum_retweet.created_at.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_vars_convert_to_str(df, vars):\n",
    "    for var in vars:\n",
    "        df[var] = df[var].astype(str)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vars_convert_to_str(cum_retweet, ['RT_id','user_id','created_at','created_at_h'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2020-06-30 13:52:34\n",
       "1       2020-06-19 16:29:04\n",
       "2       2020-06-29 23:07:04\n",
       "3       2020-05-29 23:37:51\n",
       "4       2020-06-03 00:44:20\n",
       "               ...         \n",
       "8316    2020-05-27 22:59:23\n",
       "8317    2020-06-01 15:32:15\n",
       "8318    2020-06-05 13:37:39\n",
       "8319    2020-06-02 18:09:41\n",
       "8320    2020-06-08 23:37:51\n",
       "Name: created_at, Length: 8321, dtype: object"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_retweet.created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>1267092045870567424</td>\n",
       "      <td>2020-05-31 07:54:19</td>\n",
       "      <td>887275420990795776</td>\n",
       "      <td>Mkilic76</td>\n",
       "      <td>1913</td>\n",
       "      <td>169</td>\n",
       "      <td>#Diren√ßliMadde #ResilientMatter Mutlak hi√ßlik ...</td>\n",
       "      <td>You are the police, you secure the people.\\n\\n...</td>\n",
       "      <td>220</td>\n",
       "      <td>https://t.co/Qq0fN4A80b</td>\n",
       "      <td>[#LosAngeles, #GeorgeFloydProtests, #Anonymous...</td>\n",
       "      <td>[https://t.co/ewvOus9OlL]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 07:00:00</td>\n",
       "      <td>[police,, secure, people., cuff, batons., kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>1282640691944779776</td>\n",
       "      <td>2020-07-13 05:39:05</td>\n",
       "      <td>2940882906</td>\n",
       "      <td>BLMLA</td>\n",
       "      <td>133202</td>\n",
       "      <td>436</td>\n",
       "      <td>Official Twitter for #BlackLivesMatter-Los Ang...</td>\n",
       "      <td>Today, July 13th, is the 7 year anniversary of...</td>\n",
       "      <td>101</td>\n",
       "      <td>https://t.co/K3MnLNwuCj</td>\n",
       "      <td>[#BlackLivesMatter,, #LosAngeles, #TrayvonMart...</td>\n",
       "      <td>[https://t.co/yJXpWOOeN7]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-13 05:00:00</td>\n",
       "      <td>[today,, july, 13th,, 7, year, anniversary, #b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RT_id          created_at             user_id user_name  \\\n",
       "4019  1267092045870567424 2020-05-31 07:54:19  887275420990795776  Mkilic76   \n",
       "6468  1282640691944779776 2020-07-13 05:39:05          2940882906     BLMLA   \n",
       "\n",
       "      followers_count  following_count  \\\n",
       "4019             1913              169   \n",
       "6468           133202              436   \n",
       "\n",
       "                                       user_description  \\\n",
       "4019  #Diren√ßliMadde #ResilientMatter Mutlak hi√ßlik ...   \n",
       "6468  Official Twitter for #BlackLivesMatter-Los Ang...   \n",
       "\n",
       "                                                   text  retweet_count  \\\n",
       "4019  You are the police, you secure the people.\\n\\n...            220   \n",
       "6468  Today, July 13th, is the 7 year anniversary of...            101   \n",
       "\n",
       "                         t_co  \\\n",
       "4019  https://t.co/Qq0fN4A80b   \n",
       "6468  https://t.co/K3MnLNwuCj   \n",
       "\n",
       "                                                   tags  \\\n",
       "4019  [#LosAngeles, #GeorgeFloydProtests, #Anonymous...   \n",
       "6468  [#BlackLivesMatter,, #LosAngeles, #TrayvonMart...   \n",
       "\n",
       "                           urls lang         created_at_h  \\\n",
       "4019  [https://t.co/ewvOus9OlL]   en  2020-05-31 07:00:00   \n",
       "6468  [https://t.co/yJXpWOOeN7]   en  2020-07-13 05:00:00   \n",
       "\n",
       "                                                 tokens  \n",
       "4019  [police,, secure, people., cuff, batons., kill...  \n",
       "6468  [today,, july, 13th,, 7, year, anniversary, #b...  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_idx = mark_tokens_contain_keyword(cum_retweet, '#LosAngeles')\n",
    "filtered_retweet2 = cum_retweet[tmp_idx]\n",
    "filtered_retweet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_idx = mark_tokens_contain_keyword_jointly(cum_retweet, ['Los', 'Angeles'])\n",
    "filtered_retweet3 = cum_retweet[tmp_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1266978310556389376</td>\n",
       "      <td>2020-05-31 00:22:23</td>\n",
       "      <td>1703320855</td>\n",
       "      <td>ArianaToday</td>\n",
       "      <td>371394</td>\n",
       "      <td>196</td>\n",
       "      <td>Your ultimate fan-source for the latest @Arian...</td>\n",
       "      <td>Another photo of Ariana at the #BlackLivesMatt...</td>\n",
       "      <td>14705</td>\n",
       "      <td>https://t.co/IpeD7QznPp</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 00:00:00</td>\n",
       "      <td>[another, photo, ariana, protest, los, angeles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>1267239801448783872</td>\n",
       "      <td>2020-05-31 17:41:27</td>\n",
       "      <td>1012800001</td>\n",
       "      <td>PontoffelPock</td>\n",
       "      <td>151</td>\n",
       "      <td>467</td>\n",
       "      <td>You pull on the pull-em, and push on the push-...</td>\n",
       "      <td>PROTEST! But, keep this in mind before you des...</td>\n",
       "      <td>346</td>\n",
       "      <td>https://t.co/f6hYFeEDVO</td>\n",
       "      <td>[#BlackLivesMatter, #protests2020, #Minneapoli...</td>\n",
       "      <td>[https://t.co/WX4oUqXLWA]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 17:00:00</td>\n",
       "      <td>[protest!, but,, keep, mind, destroy, people's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>1279828664448778240</td>\n",
       "      <td>2020-07-05 11:25:06</td>\n",
       "      <td>297254650</td>\n",
       "      <td>calexity</td>\n",
       "      <td>6489</td>\n",
       "      <td>2304</td>\n",
       "      <td>üìà Growth Designer. Designing for impact @lexro...</td>\n",
       "      <td>\"Under DA Jackie Lacey's watch, 609 people in ...</td>\n",
       "      <td>100</td>\n",
       "      <td>https://t.co/4r1njMRpBE</td>\n",
       "      <td>[#BlackLivesMatter, #JackieLaceyMustGo]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-05 11:00:00</td>\n",
       "      <td>[\"under, da, jackie, lacey's, watch,, 609, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>1279826150752223232</td>\n",
       "      <td>2020-07-05 11:15:07</td>\n",
       "      <td>109326781</td>\n",
       "      <td>ricci_sergienko</td>\n",
       "      <td>3856</td>\n",
       "      <td>2323</td>\n",
       "      <td>my views 100% represent my employer | we are g...</td>\n",
       "      <td>Full page ad in today‚Äôs LA times:\\n\\nOver 609 ...</td>\n",
       "      <td>100</td>\n",
       "      <td>https://t.co/Y888pWdEoC</td>\n",
       "      <td>[#BlackLivesMatter, #JackieLaceyMustGo]</td>\n",
       "      <td>[https://t.co/Rogj5X6pba]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-05 11:00:00</td>\n",
       "      <td>[full, page, ad, today‚Äôs, la, times:, 609, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>1270078331149357056</td>\n",
       "      <td>2020-06-08 13:40:45</td>\n",
       "      <td>525589542</td>\n",
       "      <td>6AMGroup</td>\n",
       "      <td>20422</td>\n",
       "      <td>7959</td>\n",
       "      <td>Digital platform ‚ûï online resource inspiring &amp;...</td>\n",
       "      <td>.@yakooza (IG) captured the 20,000 peaceful pr...</td>\n",
       "      <td>226</td>\n",
       "      <td>https://t.co/XtJVcLrVyH</td>\n",
       "      <td>[#BlackLivesMatter, #losangelesprotest, #Equal...</td>\n",
       "      <td>[https://t.co/QKmvQWy2xY]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-08 13:00:00</td>\n",
       "      <td>[(ig), capture, 20,000, peaceful, protestors, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3088</th>\n",
       "      <td>1276746284074823680</td>\n",
       "      <td>2020-06-26 23:16:49</td>\n",
       "      <td>1276318554992726016</td>\n",
       "      <td>ConcernedLACity</td>\n",
       "      <td>365</td>\n",
       "      <td>26</td>\n",
       "      <td>Current and former City of LA staff in support...</td>\n",
       "      <td>In support of #BlackLivesMatter , Los Angeles ...</td>\n",
       "      <td>137</td>\n",
       "      <td>https://t.co/punnSM08Ub</td>\n",
       "      <td>[#BlackLivesMatter, #PeoplesBudgetLA.]</td>\n",
       "      <td>[https://t.co/xNgZBUDFsj]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 23:00:00</td>\n",
       "      <td>[support, los, angeles, city, workers, call, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>1267577663536852992</td>\n",
       "      <td>2020-06-01 16:04:00</td>\n",
       "      <td>2940882906</td>\n",
       "      <td>BLMLA</td>\n",
       "      <td>131744</td>\n",
       "      <td>436</td>\n",
       "      <td>Official Twitter for #BlackLivesMatter-Los Ang...</td>\n",
       "      <td>We need everyone to show up...virtually...to t...</td>\n",
       "      <td>2234</td>\n",
       "      <td>https://t.co/4gQFpymC6w</td>\n",
       "      <td>[#GeorgeFloyd...It's, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/p3sevLDwUQ]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-01 16:00:00</td>\n",
       "      <td>[need, everyone, show, up...virtually...to, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>1267600885389066240</td>\n",
       "      <td>2020-06-01 17:36:16</td>\n",
       "      <td>1187773045949247488</td>\n",
       "      <td>BTWthisShit</td>\n",
       "      <td>101</td>\n",
       "      <td>31</td>\n",
       "      <td>#BlackLiveMatters‚úäüèª‚úäüèº‚úäüèΩ‚úäüèæ‚úäüèø</td>\n",
       "      <td>Halsey and YUNGBLUD are on the streets of Los ...</td>\n",
       "      <td>847</td>\n",
       "      <td>https://t.co/r3q9tjIr7A</td>\n",
       "      <td>[#PizzaGate, #BlackLivesMatter, #Anonymuos]</td>\n",
       "      <td>[https://t.co/x9Tib7VSu5]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-01 17:00:00</td>\n",
       "      <td>[halsey, yungblud, street, los, angeles, medic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>1269458708611899392</td>\n",
       "      <td>2020-06-06 20:38:36</td>\n",
       "      <td>4429003533</td>\n",
       "      <td>PopCrave</td>\n",
       "      <td>529264</td>\n",
       "      <td>2297</td>\n",
       "      <td>Your Go-to Source for Pop Culture News, Chart ...</td>\n",
       "      <td>Billie Eilish at a #BlackLivesMatter¬† protest ...</td>\n",
       "      <td>2623</td>\n",
       "      <td>https://t.co/9to3ANQCDu</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-06 20:00:00</td>\n",
       "      <td>[billie, eilish, protest, los, angeles, today.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>1267930507494465536</td>\n",
       "      <td>2020-06-02 15:26:04</td>\n",
       "      <td>766674511475474432</td>\n",
       "      <td>BestAffleck</td>\n",
       "      <td>5014</td>\n",
       "      <td>130</td>\n",
       "      <td>The best of @BenAffleck . Director, actor, wri...</td>\n",
       "      <td>Ben Affleck and Ana de Armas \\nattend the #Bla...</td>\n",
       "      <td>362</td>\n",
       "      <td>https://t.co/mclwU1GXoQ</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 15:00:00</td>\n",
       "      <td>[ben, affleck, ana, de, armas, attend, protest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6813</th>\n",
       "      <td>1272185411197038592</td>\n",
       "      <td>2020-06-14 09:13:32</td>\n",
       "      <td>14700316</td>\n",
       "      <td>hrw</td>\n",
       "      <td>4404801</td>\n",
       "      <td>20245</td>\n",
       "      <td>Exposing #HumanRights abuses around the world....</td>\n",
       "      <td>#WhyIProtest\\n\\n‚ÄúWe are no longer standing in ...</td>\n",
       "      <td>348</td>\n",
       "      <td>https://t.co/g3MU5bO3jd</td>\n",
       "      <td>[#WhyIProtest, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/qHmFLyCM2d]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-14 09:00:00</td>\n",
       "      <td>[#whyiprotest, ‚Äúwe, long, stand, silent, oppre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RT_id          created_at              user_id  \\\n",
       "442   1266978310556389376 2020-05-31 00:22:23           1703320855   \n",
       "2590  1267239801448783872 2020-05-31 17:41:27           1012800001   \n",
       "2793  1279828664448778240 2020-07-05 11:25:06            297254650   \n",
       "2815  1279826150752223232 2020-07-05 11:15:07            109326781   \n",
       "2927  1270078331149357056 2020-06-08 13:40:45            525589542   \n",
       "3088  1276746284074823680 2020-06-26 23:16:49  1276318554992726016   \n",
       "4205  1267577663536852992 2020-06-01 16:04:00           2940882906   \n",
       "4931  1267600885389066240 2020-06-01 17:36:16  1187773045949247488   \n",
       "4978  1269458708611899392 2020-06-06 20:38:36           4429003533   \n",
       "5479  1267930507494465536 2020-06-02 15:26:04   766674511475474432   \n",
       "6813  1272185411197038592 2020-06-14 09:13:32             14700316   \n",
       "\n",
       "            user_name  followers_count  following_count  \\\n",
       "442       ArianaToday           371394              196   \n",
       "2590    PontoffelPock              151              467   \n",
       "2793         calexity             6489             2304   \n",
       "2815  ricci_sergienko             3856             2323   \n",
       "2927         6AMGroup            20422             7959   \n",
       "3088  ConcernedLACity              365               26   \n",
       "4205            BLMLA           131744              436   \n",
       "4931      BTWthisShit              101               31   \n",
       "4978         PopCrave           529264             2297   \n",
       "5479      BestAffleck             5014              130   \n",
       "6813              hrw          4404801            20245   \n",
       "\n",
       "                                       user_description  \\\n",
       "442   Your ultimate fan-source for the latest @Arian...   \n",
       "2590  You pull on the pull-em, and push on the push-...   \n",
       "2793  üìà Growth Designer. Designing for impact @lexro...   \n",
       "2815  my views 100% represent my employer | we are g...   \n",
       "2927  Digital platform ‚ûï online resource inspiring &...   \n",
       "3088  Current and former City of LA staff in support...   \n",
       "4205  Official Twitter for #BlackLivesMatter-Los Ang...   \n",
       "4931                        #BlackLiveMatters‚úäüèª‚úäüèº‚úäüèΩ‚úäüèæ‚úäüèø   \n",
       "4978  Your Go-to Source for Pop Culture News, Chart ...   \n",
       "5479  The best of @BenAffleck . Director, actor, wri...   \n",
       "6813  Exposing #HumanRights abuses around the world....   \n",
       "\n",
       "                                                   text  retweet_count  \\\n",
       "442   Another photo of Ariana at the #BlackLivesMatt...          14705   \n",
       "2590  PROTEST! But, keep this in mind before you des...            346   \n",
       "2793  \"Under DA Jackie Lacey's watch, 609 people in ...            100   \n",
       "2815  Full page ad in today‚Äôs LA times:\\n\\nOver 609 ...            100   \n",
       "2927  .@yakooza (IG) captured the 20,000 peaceful pr...            226   \n",
       "3088  In support of #BlackLivesMatter , Los Angeles ...            137   \n",
       "4205  We need everyone to show up...virtually...to t...           2234   \n",
       "4931  Halsey and YUNGBLUD are on the streets of Los ...            847   \n",
       "4978  Billie Eilish at a #BlackLivesMatter¬† protest ...           2623   \n",
       "5479  Ben Affleck and Ana de Armas \\nattend the #Bla...            362   \n",
       "6813  #WhyIProtest\\n\\n‚ÄúWe are no longer standing in ...            348   \n",
       "\n",
       "                         t_co  \\\n",
       "442   https://t.co/IpeD7QznPp   \n",
       "2590  https://t.co/f6hYFeEDVO   \n",
       "2793  https://t.co/4r1njMRpBE   \n",
       "2815  https://t.co/Y888pWdEoC   \n",
       "2927  https://t.co/XtJVcLrVyH   \n",
       "3088  https://t.co/punnSM08Ub   \n",
       "4205  https://t.co/4gQFpymC6w   \n",
       "4931  https://t.co/r3q9tjIr7A   \n",
       "4978  https://t.co/9to3ANQCDu   \n",
       "5479  https://t.co/mclwU1GXoQ   \n",
       "6813  https://t.co/g3MU5bO3jd   \n",
       "\n",
       "                                                   tags  \\\n",
       "442                                 [#BlackLivesMatter]   \n",
       "2590  [#BlackLivesMatter, #protests2020, #Minneapoli...   \n",
       "2793            [#BlackLivesMatter, #JackieLaceyMustGo]   \n",
       "2815            [#BlackLivesMatter, #JackieLaceyMustGo]   \n",
       "2927  [#BlackLivesMatter, #losangelesprotest, #Equal...   \n",
       "3088             [#BlackLivesMatter, #PeoplesBudgetLA.]   \n",
       "4205           [#GeorgeFloyd...It's, #BlackLivesMatter]   \n",
       "4931        [#PizzaGate, #BlackLivesMatter, #Anonymuos]   \n",
       "4978                                [#BlackLivesMatter]   \n",
       "5479                                [#BlackLivesMatter]   \n",
       "6813                  [#WhyIProtest, #BlackLivesMatter]   \n",
       "\n",
       "                           urls lang         created_at_h  \\\n",
       "442                          []   en  2020-05-31 00:00:00   \n",
       "2590  [https://t.co/WX4oUqXLWA]   en  2020-05-31 17:00:00   \n",
       "2793                         []   en  2020-07-05 11:00:00   \n",
       "2815  [https://t.co/Rogj5X6pba]   en  2020-07-05 11:00:00   \n",
       "2927  [https://t.co/QKmvQWy2xY]   en  2020-06-08 13:00:00   \n",
       "3088  [https://t.co/xNgZBUDFsj]   en  2020-06-26 23:00:00   \n",
       "4205  [https://t.co/p3sevLDwUQ]   en  2020-06-01 16:00:00   \n",
       "4931  [https://t.co/x9Tib7VSu5]   en  2020-06-01 17:00:00   \n",
       "4978                         []   en  2020-06-06 20:00:00   \n",
       "5479                         []   en  2020-06-02 15:00:00   \n",
       "6813  [https://t.co/qHmFLyCM2d]   en  2020-06-14 09:00:00   \n",
       "\n",
       "                                                 tokens  \n",
       "442     [another, photo, ariana, protest, los, angeles]  \n",
       "2590  [protest!, but,, keep, mind, destroy, people's...  \n",
       "2793  [\"under, da, jackie, lacey's, watch,, 609, peo...  \n",
       "2815  [full, page, ad, today‚Äôs, la, times:, 609, peo...  \n",
       "2927  [(ig), capture, 20,000, peaceful, protestors, ...  \n",
       "3088  [support, los, angeles, city, workers, call, m...  \n",
       "4205  [need, everyone, show, up...virtually...to, te...  \n",
       "4931  [halsey, yungblud, street, los, angeles, medic...  \n",
       "4978    [billie, eilish, protest, los, angeles, today.]  \n",
       "5479  [ben, affleck, ana, de, armas, attend, protest...  \n",
       "6813  [#whyiprotest, ‚Äúwe, long, stand, silent, oppre...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_retweet3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_retweet = glob.glob(data_path + \"data_cumulative/retweet/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    RT_id          created_at              user_id  \\\n",
      "339   1271228625933619200 2020-06-11 17:51:37           2835451658   \n",
      "564   1277286903641866240 2020-06-28 11:05:03             98956941   \n",
      "635   1266515656037588992 2020-05-29 17:43:57  1258993079287197696   \n",
      "1561  1266752338221506560 2020-05-30 09:24:27            175065805   \n",
      "2232  1266782245869805568 2020-05-30 11:23:17   743998433455808512   \n",
      "2277  1267058623911428096 2020-05-31 05:41:31  1219534043210973184   \n",
      "2682  1267218415736872960 2020-05-31 16:16:28            195271137   \n",
      "2905  1267001484387840000 2020-05-31 01:54:28           1538581122   \n",
      "2914  1265744876823609344 2020-05-27 14:41:09  1187684601315115008   \n",
      "3163  1266286100743520256 2020-05-29 02:31:47           2835451658   \n",
      "3505  1276695049628155904 2020-06-26 19:53:14  1090715513586679808   \n",
      "3932  1266224353420759040 2020-05-28 22:26:25   793282577733971968   \n",
      "4122  1267249755949658112 2020-05-31 18:21:00            373157754   \n",
      "4290  1265324197846437888 2020-05-26 10:49:32  1237424166439211008   \n",
      "4331  1267294687657816064 2020-05-31 21:19:33             46764346   \n",
      "4672  1266232670423375872 2020-05-28 22:59:28           2835451658   \n",
      "4818  1280325917571678208 2020-07-06 20:21:00  1090715513586679808   \n",
      "4881  1280644907267502080 2020-07-07 17:28:33  1268182793441468416   \n",
      "5008  1270601548851081216 2020-06-10 00:19:50           2835451658   \n",
      "5391  1276627066889179136 2020-06-26 15:23:05            279390084   \n",
      "5515  1267818307358306304 2020-06-02 08:00:14  1260614797307109376   \n",
      "5694  1274765258578628608 2020-06-21 12:04:56            422798683   \n",
      "6031  1279928744342433792 2020-07-05 18:02:47   815977295575912448   \n",
      "6785  1276892357858865152 2020-06-27 08:57:16  1146645420099215360   \n",
      "6830  1276991586581319680 2020-06-27 15:31:34            422798683   \n",
      "6960  1267975822310207488 2020-06-02 18:26:08            328167568   \n",
      "6992  1265430916769501184 2020-05-26 17:53:35            476478812   \n",
      "7089  1265313992546934784 2020-05-26 10:08:58           1328853859   \n",
      "7142  1276868178161872896 2020-06-27 07:21:11             21149655   \n",
      "7179  1266490213255217152 2020-05-29 16:02:51           1221434521   \n",
      "7280  1276627295071989760 2020-06-26 15:24:00            187429137   \n",
      "7672  1265909367351599104 2020-05-28 01:34:47           3023037872   \n",
      "7759  1270061804886974464 2020-06-08 12:35:05            373157754   \n",
      "8168  1266788641269047296 2020-05-30 11:48:42            148137271   \n",
      "8194  1267982520911527936 2020-06-02 18:52:45             31108138   \n",
      "8314  1268243960004132864 2020-06-03 12:11:37            373157754   \n",
      "\n",
      "            user_name  followers_count  following_count  \\\n",
      "339         MrAndyNgo           457035              667   \n",
      "564          afbranco            44179             2197   \n",
      "635           NedWhat              825              203   \n",
      "1561           dviyer            14843             6822   \n",
      "2232     JoeyMillsXXX           273650              474   \n",
      "2277      ilcanhavhav             1570              276   \n",
      "2682       larryelder           796374               98   \n",
      "2905       Zionocracy            19074              290   \n",
      "2914       selenesrat              532              434   \n",
      "3163        MrAndyNgo           462908              665   \n",
      "3505     JoshuaPotash            99403              595   \n",
      "3932  BrittaneyCheers              157              126   \n",
      "4122  YourAnonCentral          6473187              828   \n",
      "4290   ProBlacktivist             1477               87   \n",
      "4331      MisterPreda           244684              523   \n",
      "4672        MrAndyNgo           467735              667   \n",
      "4818     JoshuaPotash           101233              605   \n",
      "4881    Eric6H6rtm6nn              268              174   \n",
      "5008        MrAndyNgo           467652              666   \n",
      "5391     YourAnonNews          7528103              817   \n",
      "5515     AOC_movement              852               90   \n",
      "5694   LatestAnonNews           347388              186   \n",
      "6031       herwithluv             3415              281   \n",
      "6785       PeopleMvmt            11277              570   \n",
      "6830   LatestAnonNews           347521              187   \n",
      "6960       MsIsisKing            44956              619   \n",
      "6992      SollyBandz_             3551                0   \n",
      "7089  Belive_Kinuthia            69824            26852   \n",
      "7142   ArthurSchwartz            95478              167   \n",
      "7179      Athenselder             2159             1724   \n",
      "7280         minhtngo            41526              395   \n",
      "7672    TruthRaiderHQ            80646             5442   \n",
      "7759  YourAnonCentral          6521097              833   \n",
      "8168       rickastley           148566             1767   \n",
      "8194    RaquelWillis_            66670             6770   \n",
      "8314  YourAnonCentral          6488044              827   \n",
      "\n",
      "                                       user_description  \\\n",
      "339   Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
      "564   Nationally syndicated Political Cartoonist (Cr...   \n",
      "635   #GLROfficial\\nGreat Lakes Region \\nContent of ...   \n",
      "1561  South Asian American activist, lawyer. Senior ...   \n",
      "2232  14x award winning pornstar‚Äî Your mothers worst...   \n",
      "2277                             fƒ±rat aydƒ±nus fan club   \n",
      "2682  Sage from South Central; Larry Elder Show; Sal...   \n",
      "2905  Founder of #PalestineRemainsForEver & #Palesti...   \n",
      "2914  Ôº©ÔΩçÔΩçÔΩÅ Ôº≥ÔΩÖÔΩåÔΩÖÔΩéÔΩÅ Ôº≥ÔΩîÔΩÅÔΩé ÔΩâÔΩé ÔΩîÔΩàÔΩÖ ÔΩêÔΩïÔΩíÔΩÖÔΩìÔΩî ÔΩÜÔΩèÔΩíÔΩçüíñ\\n\\nùìò ùì™ùìµùìºùì∏...   \n",
      "3163  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
      "3505  Trump is the biggest threat to Democracy that ...   \n",
      "3932  God is everythingüôèüèæBorn and Raised Georgia Pea...   \n",
      "4122  We support the weak against the powerful. #Bla...   \n",
      "4290               Unapologetically Black. she/her/hers   \n",
      "4331  a little bit of everything | producer ‚Ä¢ creato...   \n",
      "4672  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
      "4818  Trump is the biggest threat to Democracy that ...   \n",
      "4881                                                  ìÇÄ   \n",
      "5008  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
      "5391  We are Anonymous, we are legion, we do not for...   \n",
      "5515  We are a student-led independent network that ...   \n",
      "5694  Multiple Anons reporting Anonymous intel, worl...   \n",
      "6031  #VMINKOOK: on god if you pay hyung line dust w...   \n",
      "6785  Wellesley üìö ‚Ä¢ Progressive Cat Mom ‚Ä¢ Justice an...   \n",
      "6830  Multiple Anons reporting Anonymous intel, worl...   \n",
      "6960  Actress & Top Model - MGMT: BGolden@PinkHammer...   \n",
      "6992  SollyBandz || HMU FOR FEATURES, SEND BEATS, ET...   \n",
      "7089  Son of a Peasant.Father.Murang'a Senatorial As...   \n",
      "7142                                               None   \n",
      "7179              IG:CNCCMI \\nArtist/Producer\\n\\n„ÅÆÂ≠¶Áîü ÂπªË°ì   \n",
      "7280  Aquila non capit muscas. | Usual caveats apply...   \n",
      "7672            #bitcoin Veteran. Libertarian. üáÆüá±üè≥Ô∏è‚Äçüåàüá∫üá≤   \n",
      "7759  We support the weak against the powerful. Resi...   \n",
      "8168  My new album The Best Of Me is out now! It‚Äôs b...   \n",
      "8194  director of comms, @msfoundation ‚ú¶ writer, act...   \n",
      "8314  We support the weak against the powerful. #Bla...   \n",
      "\n",
      "                                                   text  retweet_count  \\\n",
      "339   This is what rioters did to the Minneapolis Sh...          21050   \n",
      "564   A.F. Branco Cartoon - Alpha News: Welcome to M...            207   \n",
      "635   Support from the #Amish community in Minneapol...         100842   \n",
      "1561  The story of the #GandhiMahal restaurant in Mi...            198   \n",
      "2232  All proceeds for the next 48 hours that I rece...            406   \n",
      "2277  A man shoots a black protester with a shotgun ...           1783   \n",
      "2682  Black lives matter. Black businesses, not so m...            435   \n",
      "2905  Dear America\\nWhat Happened to #GeorgeFloyd in...           2568   \n",
      "2914  Please call either (612) 348-5550 or (844) 278...            135   \n",
      "3163  Person at Minneapolis BLM race riot makes it c...           3140   \n",
      "3505  Don‚Äôt let the #BlackLivesMatter¬† protests disa...         112504   \n",
      "3932  When people ask you why the people in Minneapo...           1593   \n",
      "4122  Here‚Äôs a template to use when emailing the Min...           6988   \n",
      "4290  A Black man was murdered last night by the Min...           9795   \n",
      "4331  NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...           2501   \n",
      "4672  Looters are ransacking the third police precin...           1669   \n",
      "4818  It‚Äôs crazy how when the fires died down Minnea...           1227   \n",
      "4881  They still haven't arrested or even looked har...            283   \n",
      "5008  The DOJ has charged Branden Michael Wolfe, 23,...           4825   \n",
      "5391  Law Enforcement Scoured Protester Communicatio...            371   \n",
      "5515  From London to Minneapolis and Jerusalem we ha...            105   \n",
      "5694  A woman spots and confronts one of the officer...            837   \n",
      "6031  daniel nelson. works at blue plate &amp; co in...            100   \n",
      "6785  BREAKING: Minneapolis yesterday. Protests have...            290   \n",
      "6830  The FBI is investigating after a piece of rope...            141   \n",
      "6960  This black trans woman was beating in Minneapo...            334   \n",
      "6992  They Going Crazy In Minneapolis RnüíØüëèüèæ #ICantBr...          39746   \n",
      "7089  A Minneapolis police officer killed this Black...            502   \n",
      "7142  They don‚Äôt want you calling anyone for help wh...            178   \n",
      "7179  \"A Mirror to our Times\"\\nA freestyle about the...            246   \n",
      "7280  The Minneapolis City Council unanimously voted...            124   \n",
      "7672  Minneapolis is burning down. No law enforcemen...            125   \n",
      "7759  Derek Chauvin, the former Minneapolis police o...           4880   \n",
      "8168  I‚Äôve been wanting to post something about the ...            757   \n",
      "8194  A young Black trans woman named #IyannaDior wa...          11671   \n",
      "8314  Under massive public pressure, Minnesota Attor...          16580   \n",
      "\n",
      "                         t_co  \\\n",
      "339   https://t.co/GTAGV805i6   \n",
      "564   https://t.co/Web3mRCuEP   \n",
      "635   https://t.co/IBcGGubFAo   \n",
      "1561  https://t.co/cHGBMwtDRh   \n",
      "2232  https://t.co/c0EzZoJYvE   \n",
      "2277  https://t.co/7qU01ryYV0   \n",
      "2682  https://t.co/aZPPHBLtSZ   \n",
      "2905  https://t.co/T9y8UT4btT   \n",
      "2914  https://t.co/t2pBxgo176   \n",
      "3163  https://t.co/XL6Dil4vX1   \n",
      "3505  https://t.co/uTcDbAWOnu   \n",
      "3932  https://t.co/BzTJ6E1IgF   \n",
      "4122  https://t.co/1FizCM94lu   \n",
      "4290  https://t.co/CBmzhz7MPq   \n",
      "4331  https://t.co/SqKVx7ezfP   \n",
      "4672  https://t.co/mbhS1qyZum   \n",
      "4818  https://t.co/UJdJikVhdR   \n",
      "4881  https://t.co/RQGZ7BvKYI   \n",
      "5008  https://t.co/REQsiVCDaD   \n",
      "5391  https://t.co/dSp76LYFoG   \n",
      "5515  https://t.co/EW2gH1yn0h   \n",
      "5694  https://t.co/0ZlqsBtIKj   \n",
      "6031  https://t.co/kVlhqeOM2z   \n",
      "6785  https://t.co/MwMZ8BpJy7   \n",
      "6830  https://t.co/sI6VlOcleT   \n",
      "6960  https://t.co/3DV8I1aC3H   \n",
      "6992  https://t.co/6efmPeDMa1   \n",
      "7089  https://t.co/sMYoh1VLcc   \n",
      "7142  https://t.co/vYIJegmGlX   \n",
      "7179  https://t.co/OfkOyx9a0h   \n",
      "7280  https://t.co/yCoS9XfQnb   \n",
      "7672  https://t.co/WzRTSKOxAx   \n",
      "7759  https://t.co/k03OZgI5Px   \n",
      "8168  https://t.co/IZsrRw4mA4   \n",
      "8194  https://t.co/hRTHlLINLq   \n",
      "8314  https://t.co/ii1es7eaSK   \n",
      "\n",
      "                                                   tags  \\\n",
      "339                                 [#BlackLivesMatter]   \n",
      "564   [#DefundThePolice, #AntifaTerrorist, #Democrat...   \n",
      "635   [#Amish, #AllLivesMatter, #BlackLivesMatter, #...   \n",
      "1561     [#GandhiMahal, #solidarity, #BlackLivesMatter]   \n",
      "2232  [#BlackLivesMatter, #JusticeForGeorgeFlyod, #J...   \n",
      "2277                                [#BlackLivesMatter]   \n",
      "2682  [#BlackLivesMatter, #BlackBusinessMatters, #Ge...   \n",
      "2905  [#GeorgeFloyd, #BlackLivesMatter, #Palestinian...   \n",
      "2914  [#1087), #7162), #GeorgeFloyd, #BlackLivesMatter]   \n",
      "3163         [#BlackLivesMatter, #GeorgeFloyd, #antifa]   \n",
      "3505                                [#BlackLivesMatter]   \n",
      "3932  [#3rdprecinct, #minneapolisriots, #Minneapolis...   \n",
      "4122  [#BlackLivesMater, #BlackLivesMatter, #GeorgeF...   \n",
      "4290                                [#BlackLivesMatter]   \n",
      "4331                                [#BlackLivesMatter]   \n",
      "4672         [#BlackLivesMatter, #Antifa, #GeorgeFloyd]   \n",
      "4818                                [#BlackLivesMatter]   \n",
      "4881                                                 []   \n",
      "5008                                [#BlackLivesMatter]   \n",
      "5391                                [#BlackLivesMatter]   \n",
      "5515                                [#BlackLivesMatter]   \n",
      "5694                  [#GeorgeFloyd, #BlackLivesMatter]   \n",
      "6031                                [#BlackLivesMatter]   \n",
      "6785                                [#BlackLivesMatter]   \n",
      "6830                                [#BlackLivesMatter]   \n",
      "6960                         [#BlackLivesMatter....ALL]   \n",
      "6992   [#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]   \n",
      "7089                                [#BlackLivesMatter]   \n",
      "7142                                [#BlackLivesMatter]   \n",
      "7179  [#BlackLivesMatter, #JusticeForGeorgeFlyod, #G...   \n",
      "7280                 [#GeorgeFloyd., #BlackLivesMatter]   \n",
      "7672                  [#Minneapolis, #BlackLivesMatter]   \n",
      "7759                 [#GeorgeFloyd,, #BlackLivesMatter]   \n",
      "8168       [#equality, #georgefloyd, #blacklivesmatter]   \n",
      "8194                   [#IyannaDior, #BlackLivesMatter]   \n",
      "8314  [#GeorgeFloyd,, #ICantBreathe, #BlackLivesMatter]   \n",
      "\n",
      "                                                   urls lang  \\\n",
      "339                           [https://t.co/GDYvNRmYi2]   en   \n",
      "564                           [https://t.co/zqUYrv0CPE]   en   \n",
      "635                           [https://t.co/qEkVkmOhGA]   en   \n",
      "1561                          [https://t.co/sseVxOiFCe]   en   \n",
      "2232  [https://t.co/uqQog24F7V, https://t.co/4jXkhvd...   en   \n",
      "2277                                                 []   en   \n",
      "2682  [https://t.co/nl7Hzo919z, https://t.co/wtjSmVE...   en   \n",
      "2905                          [https://t.co/a3Z50ffn1c]   en   \n",
      "2914                          [https://t.co/0VFZORnGcf]   en   \n",
      "3163                          [https://t.co/5JNhq0qags]   en   \n",
      "3505                          [https://t.co/TqSMix6Mpx]   en   \n",
      "3932                          [https://t.co/5zvfCePZ7D]   en   \n",
      "4122                          [https://t.co/uKjVdjfqYD]   en   \n",
      "4290                          [https://t.co/C85N7OTJhr]   en   \n",
      "4331                                                 []   en   \n",
      "4672                                                 []   en   \n",
      "4818                          [https://t.co/zjw0puBPap]   en   \n",
      "4881  [https://t.co/uvCPQ4IxoB, https://t.co/y0xbpxt...   en   \n",
      "5008  [https://t.co/PGWCjn8yr7, https://t.co/3QX3e93...   en   \n",
      "5391                          [https://t.co/bMfXd5GpdO]   en   \n",
      "5515                          [https://t.co/BGIJdTa3pu]   en   \n",
      "5694                          [https://t.co/flnJ6SaMxd]   en   \n",
      "6031                          [https://t.co/MHakh4rCOp]   en   \n",
      "6785                          [https://t.co/snsHAYrxhd]   en   \n",
      "6830                          [https://t.co/9Rn8owvg9y]   en   \n",
      "6960                          [https://t.co/trPGprwVrS]   en   \n",
      "6992                                                 []   en   \n",
      "7089                          [https://t.co/fJLRXgK3Vb]   en   \n",
      "7142                          [https://t.co/tZFmsDvLrS]   en   \n",
      "7179                          [https://t.co/L6cWmrt4fe]   en   \n",
      "7280                          [https://t.co/c3d25ohK7t]   en   \n",
      "7672                          [https://t.co/6zWvmDBpiU]   en   \n",
      "7759                          [https://t.co/ncgBUgP5Rg]   en   \n",
      "8168                          [https://t.co/BPwbKYYRtY]   en   \n",
      "8194                                                 []   en   \n",
      "8314                          [https://t.co/dGkLEiiryr]   en   \n",
      "\n",
      "             created_at_h                                             tokens  \n",
      "339   2020-06-11 17:00:00  [rioter, minneapolis, sheraton, take, riots., ...  \n",
      "564   2020-06-28 11:00:00  [a.f., branco, cartoon, alpha, news:, welcome,...  \n",
      "635   2020-05-29 17:00:00  [support, #amish, community, minneapolis, #all...  \n",
      "1561  2020-05-30 09:00:00  [story, #gandhimahal, restaurant, minneapolis,...  \n",
      "2232  2020-05-30 11:00:00  [proceeds, next, 48, hour, receive, onlyfans, ...  \n",
      "2277  2020-05-31 05:00:00  [man, shoot, black, protester, shotgun, minnea...  \n",
      "2682  2020-05-31 16:00:00  [black, live, matter., black, businesses,, muc...  \n",
      "2905  2020-05-31 01:00:00  [dear, america, happened, #georgefloyd, minnea...  \n",
      "2914  2020-05-27 14:00:00  [call, either, (612), 348-5550, (844), 278-283...  \n",
      "3163  2020-05-29 02:00:00  [person, minneapolis, blm, race, riot, make, c...  \n",
      "3505  2020-06-26 19:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "3932  2020-05-28 22:00:00  [people, ask, people, minneapolis, act, out., ...  \n",
      "4122  2020-05-31 18:00:00  [here‚Äôs, template, use, email, minneapolis, po...  \n",
      "4290  2020-05-26 10:00:00  [black, man, murder, last, night, minneapolis,...  \n",
      "4331  2020-05-31 21:00:00  [numbers, call, incase, unlawful, arrests, pro...  \n",
      "4672  2020-05-28 22:00:00  [looters, ransack, third, police, precinct, mi...  \n",
      "4818  2020-07-06 20:00:00  [it‚Äôs, crazy, fire, die, minneapolis, lose, sp...  \n",
      "4881  2020-07-07 17:00:00  [still, arrest, even, look, hard, 3, black, gu...  \n",
      "5008  2020-06-10 00:00:00  [doj, charge, branden, michael, wolfe,, 23,, s...  \n",
      "5391  2020-06-26 15:00:00  [law, enforcement, scoured, protester, communi...  \n",
      "5515  2020-06-02 08:00:00  [london, minneapolis, jerusalem, take, street,...  \n",
      "5694  2020-06-21 12:00:00  [woman, spot, confronts, one, officers,, j., a...  \n",
      "6031  2020-07-05 18:00:00  [daniel, nelson., work, blue, plate, co, minne...  \n",
      "6785  2020-06-27 08:00:00  [breaking:, minneapolis, yesterday., protests,...  \n",
      "6830  2020-06-27 15:00:00  [fbi, investigate, piece, rope, resemble, noos...  \n",
      "6960  2020-06-02 18:00:00  [black, trans, woman, beat, minneapolis, hair,...  \n",
      "6992  2020-05-26 17:00:00  [going, crazy, minneapolis, rnüíØüëèüèæ, #icantbreat...  \n",
      "7089  2020-05-26 10:00:00  [minneapolis, police, officer, kill, black, ma...  \n",
      "7142  2020-06-27 07:00:00  [don‚Äôt, want, call, anyone, help, terrorists, ...  \n",
      "7179  2020-05-29 16:00:00  [\"a, mirror, times\", freestyle, situation, ame...  \n",
      "7280  2020-06-26 15:00:00  [minneapolis, city, council, unanimously, vote...  \n",
      "7672  2020-05-28 01:00:00  [minneapolis, burn, down., law, enforcement, a...  \n",
      "7759  2020-06-08 12:00:00  [derek, chauvin,, former, minneapolis, police,...  \n",
      "8168  2020-05-30 11:00:00  [i‚Äôve, want, post, something, terrible, event,...  \n",
      "8194  2020-06-02 18:00:00  [young, black, trans, woman, name, #iyannadior...  \n",
      "8314  2020-06-03 12:00:00  [massive, public, pressure,, minnesota, attorn...  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1271228625933619200</td>\n",
       "      <td>2020-06-11 17:51:37</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>457035</td>\n",
       "      <td>667</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>This is what rioters did to the Minneapolis Sh...</td>\n",
       "      <td>21050</td>\n",
       "      <td>https://t.co/GTAGV805i6</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/GDYvNRmYi2]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-11 17:00:00</td>\n",
       "      <td>[rioter, minneapolis, sheraton, take, riots., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1277286903641866240</td>\n",
       "      <td>2020-06-28 11:05:03</td>\n",
       "      <td>98956941</td>\n",
       "      <td>afbranco</td>\n",
       "      <td>44179</td>\n",
       "      <td>2197</td>\n",
       "      <td>Nationally syndicated Political Cartoonist (Cr...</td>\n",
       "      <td>A.F. Branco Cartoon - Alpha News: Welcome to M...</td>\n",
       "      <td>207</td>\n",
       "      <td>https://t.co/Web3mRCuEP</td>\n",
       "      <td>[#DefundThePolice, #AntifaTerrorist, #Democrat...</td>\n",
       "      <td>[https://t.co/zqUYrv0CPE]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-28 11:00:00</td>\n",
       "      <td>[a.f., branco, cartoon, alpha, news:, welcome,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1266515656037588992</td>\n",
       "      <td>2020-05-29 17:43:57</td>\n",
       "      <td>1258993079287197696</td>\n",
       "      <td>NedWhat</td>\n",
       "      <td>825</td>\n",
       "      <td>203</td>\n",
       "      <td>#GLROfficial\\nGreat Lakes Region \\nContent of ...</td>\n",
       "      <td>Support from the #Amish community in Minneapol...</td>\n",
       "      <td>100842</td>\n",
       "      <td>https://t.co/IBcGGubFAo</td>\n",
       "      <td>[#Amish, #AllLivesMatter, #BlackLivesMatter, #...</td>\n",
       "      <td>[https://t.co/qEkVkmOhGA]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-29 17:00:00</td>\n",
       "      <td>[support, #amish, community, minneapolis, #all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1266752338221506560</td>\n",
       "      <td>2020-05-30 09:24:27</td>\n",
       "      <td>175065805</td>\n",
       "      <td>dviyer</td>\n",
       "      <td>14843</td>\n",
       "      <td>6822</td>\n",
       "      <td>South Asian American activist, lawyer. Senior ...</td>\n",
       "      <td>The story of the #GandhiMahal restaurant in Mi...</td>\n",
       "      <td>198</td>\n",
       "      <td>https://t.co/cHGBMwtDRh</td>\n",
       "      <td>[#GandhiMahal, #solidarity, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/sseVxOiFCe]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-30 09:00:00</td>\n",
       "      <td>[story, #gandhimahal, restaurant, minneapolis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1266782245869805568</td>\n",
       "      <td>2020-05-30 11:23:17</td>\n",
       "      <td>743998433455808512</td>\n",
       "      <td>JoeyMillsXXX</td>\n",
       "      <td>273650</td>\n",
       "      <td>474</td>\n",
       "      <td>14x award winning pornstar‚Äî Your mothers worst...</td>\n",
       "      <td>All proceeds for the next 48 hours that I rece...</td>\n",
       "      <td>406</td>\n",
       "      <td>https://t.co/c0EzZoJYvE</td>\n",
       "      <td>[#BlackLivesMatter, #JusticeForGeorgeFlyod, #J...</td>\n",
       "      <td>[https://t.co/uqQog24F7V, https://t.co/4jXkhvd...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-30 11:00:00</td>\n",
       "      <td>[proceeds, next, 48, hour, receive, onlyfans, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1267058623911428096</td>\n",
       "      <td>2020-05-31 05:41:31</td>\n",
       "      <td>1219534043210973184</td>\n",
       "      <td>ilcanhavhav</td>\n",
       "      <td>1570</td>\n",
       "      <td>276</td>\n",
       "      <td>fƒ±rat aydƒ±nus fan club</td>\n",
       "      <td>A man shoots a black protester with a shotgun ...</td>\n",
       "      <td>1783</td>\n",
       "      <td>https://t.co/7qU01ryYV0</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 05:00:00</td>\n",
       "      <td>[man, shoot, black, protester, shotgun, minnea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1267218415736872960</td>\n",
       "      <td>2020-05-31 16:16:28</td>\n",
       "      <td>195271137</td>\n",
       "      <td>larryelder</td>\n",
       "      <td>796374</td>\n",
       "      <td>98</td>\n",
       "      <td>Sage from South Central; Larry Elder Show; Sal...</td>\n",
       "      <td>Black lives matter. Black businesses, not so m...</td>\n",
       "      <td>435</td>\n",
       "      <td>https://t.co/aZPPHBLtSZ</td>\n",
       "      <td>[#BlackLivesMatter, #BlackBusinessMatters, #Ge...</td>\n",
       "      <td>[https://t.co/nl7Hzo919z, https://t.co/wtjSmVE...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 16:00:00</td>\n",
       "      <td>[black, live, matter., black, businesses,, muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1267001484387840000</td>\n",
       "      <td>2020-05-31 01:54:28</td>\n",
       "      <td>1538581122</td>\n",
       "      <td>Zionocracy</td>\n",
       "      <td>19074</td>\n",
       "      <td>290</td>\n",
       "      <td>Founder of #PalestineRemainsForEver &amp; #Palesti...</td>\n",
       "      <td>Dear America\\nWhat Happened to #GeorgeFloyd in...</td>\n",
       "      <td>2568</td>\n",
       "      <td>https://t.co/T9y8UT4btT</td>\n",
       "      <td>[#GeorgeFloyd, #BlackLivesMatter, #Palestinian...</td>\n",
       "      <td>[https://t.co/a3Z50ffn1c]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 01:00:00</td>\n",
       "      <td>[dear, america, happened, #georgefloyd, minnea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1265744876823609344</td>\n",
       "      <td>2020-05-27 14:41:09</td>\n",
       "      <td>1187684601315115008</td>\n",
       "      <td>selenesrat</td>\n",
       "      <td>532</td>\n",
       "      <td>434</td>\n",
       "      <td>Ôº©ÔΩçÔΩçÔΩÅ Ôº≥ÔΩÖÔΩåÔΩÖÔΩéÔΩÅ Ôº≥ÔΩîÔΩÅÔΩé ÔΩâÔΩé ÔΩîÔΩàÔΩÖ ÔΩêÔΩïÔΩíÔΩÖÔΩìÔΩî ÔΩÜÔΩèÔΩíÔΩçüíñ\\n\\nùìò ùì™ùìµùìºùì∏...</td>\n",
       "      <td>Please call either (612) 348-5550 or (844) 278...</td>\n",
       "      <td>135</td>\n",
       "      <td>https://t.co/t2pBxgo176</td>\n",
       "      <td>[#1087), #7162), #GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/0VFZORnGcf]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-27 14:00:00</td>\n",
       "      <td>[call, either, (612), 348-5550, (844), 278-283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1266286100743520256</td>\n",
       "      <td>2020-05-29 02:31:47</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>462908</td>\n",
       "      <td>665</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>Person at Minneapolis BLM race riot makes it c...</td>\n",
       "      <td>3140</td>\n",
       "      <td>https://t.co/XL6Dil4vX1</td>\n",
       "      <td>[#BlackLivesMatter, #GeorgeFloyd, #antifa]</td>\n",
       "      <td>[https://t.co/5JNhq0qags]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-29 02:00:00</td>\n",
       "      <td>[person, minneapolis, blm, race, riot, make, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1276695049628155904</td>\n",
       "      <td>2020-06-26 19:53:14</td>\n",
       "      <td>1090715513586679808</td>\n",
       "      <td>JoshuaPotash</td>\n",
       "      <td>99403</td>\n",
       "      <td>595</td>\n",
       "      <td>Trump is the biggest threat to Democracy that ...</td>\n",
       "      <td>Don‚Äôt let the #BlackLivesMatter¬† protests disa...</td>\n",
       "      <td>112504</td>\n",
       "      <td>https://t.co/uTcDbAWOnu</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/TqSMix6Mpx]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 19:00:00</td>\n",
       "      <td>[don‚Äôt, let, protest, disappear, tls., minneap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1266224353420759040</td>\n",
       "      <td>2020-05-28 22:26:25</td>\n",
       "      <td>793282577733971968</td>\n",
       "      <td>BrittaneyCheers</td>\n",
       "      <td>157</td>\n",
       "      <td>126</td>\n",
       "      <td>God is everythingüôèüèæBorn and Raised Georgia Pea...</td>\n",
       "      <td>When people ask you why the people in Minneapo...</td>\n",
       "      <td>1593</td>\n",
       "      <td>https://t.co/BzTJ6E1IgF</td>\n",
       "      <td>[#3rdprecinct, #minneapolisriots, #Minneapolis...</td>\n",
       "      <td>[https://t.co/5zvfCePZ7D]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-28 22:00:00</td>\n",
       "      <td>[people, ask, people, minneapolis, act, out., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1267249755949658112</td>\n",
       "      <td>2020-05-31 18:21:00</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6473187</td>\n",
       "      <td>828</td>\n",
       "      <td>We support the weak against the powerful. #Bla...</td>\n",
       "      <td>Here‚Äôs a template to use when emailing the Min...</td>\n",
       "      <td>6988</td>\n",
       "      <td>https://t.co/1FizCM94lu</td>\n",
       "      <td>[#BlackLivesMater, #BlackLivesMatter, #GeorgeF...</td>\n",
       "      <td>[https://t.co/uKjVdjfqYD]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 18:00:00</td>\n",
       "      <td>[here‚Äôs, template, use, email, minneapolis, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1265324197846437888</td>\n",
       "      <td>2020-05-26 10:49:32</td>\n",
       "      <td>1237424166439211008</td>\n",
       "      <td>ProBlacktivist</td>\n",
       "      <td>1477</td>\n",
       "      <td>87</td>\n",
       "      <td>Unapologetically Black. she/her/hers</td>\n",
       "      <td>A Black man was murdered last night by the Min...</td>\n",
       "      <td>9795</td>\n",
       "      <td>https://t.co/CBmzhz7MPq</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/C85N7OTJhr]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-26 10:00:00</td>\n",
       "      <td>[black, man, murder, last, night, minneapolis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1267294687657816064</td>\n",
       "      <td>2020-05-31 21:19:33</td>\n",
       "      <td>46764346</td>\n",
       "      <td>MisterPreda</td>\n",
       "      <td>244684</td>\n",
       "      <td>523</td>\n",
       "      <td>a little bit of everything | producer ‚Ä¢ creato...</td>\n",
       "      <td>NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...</td>\n",
       "      <td>2501</td>\n",
       "      <td>https://t.co/SqKVx7ezfP</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 21:00:00</td>\n",
       "      <td>[numbers, call, incase, unlawful, arrests, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1266232670423375872</td>\n",
       "      <td>2020-05-28 22:59:28</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>467735</td>\n",
       "      <td>667</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>Looters are ransacking the third police precin...</td>\n",
       "      <td>1669</td>\n",
       "      <td>https://t.co/mbhS1qyZum</td>\n",
       "      <td>[#BlackLivesMatter, #Antifa, #GeorgeFloyd]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-28 22:00:00</td>\n",
       "      <td>[looters, ransack, third, police, precinct, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1280325917571678208</td>\n",
       "      <td>2020-07-06 20:21:00</td>\n",
       "      <td>1090715513586679808</td>\n",
       "      <td>JoshuaPotash</td>\n",
       "      <td>101233</td>\n",
       "      <td>605</td>\n",
       "      <td>Trump is the biggest threat to Democracy that ...</td>\n",
       "      <td>It‚Äôs crazy how when the fires died down Minnea...</td>\n",
       "      <td>1227</td>\n",
       "      <td>https://t.co/UJdJikVhdR</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/zjw0puBPap]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-06 20:00:00</td>\n",
       "      <td>[it‚Äôs, crazy, fire, die, minneapolis, lose, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1280644907267502080</td>\n",
       "      <td>2020-07-07 17:28:33</td>\n",
       "      <td>1268182793441468416</td>\n",
       "      <td>Eric6H6rtm6nn</td>\n",
       "      <td>268</td>\n",
       "      <td>174</td>\n",
       "      <td>ìÇÄ</td>\n",
       "      <td>They still haven't arrested or even looked har...</td>\n",
       "      <td>283</td>\n",
       "      <td>https://t.co/RQGZ7BvKYI</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/uvCPQ4IxoB, https://t.co/y0xbpxt...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-07 17:00:00</td>\n",
       "      <td>[still, arrest, even, look, hard, 3, black, gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1270601548851081216</td>\n",
       "      <td>2020-06-10 00:19:50</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>467652</td>\n",
       "      <td>666</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>The DOJ has charged Branden Michael Wolfe, 23,...</td>\n",
       "      <td>4825</td>\n",
       "      <td>https://t.co/REQsiVCDaD</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/PGWCjn8yr7, https://t.co/3QX3e93...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-10 00:00:00</td>\n",
       "      <td>[doj, charge, branden, michael, wolfe,, 23,, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1276627066889179136</td>\n",
       "      <td>2020-06-26 15:23:05</td>\n",
       "      <td>279390084</td>\n",
       "      <td>YourAnonNews</td>\n",
       "      <td>7528103</td>\n",
       "      <td>817</td>\n",
       "      <td>We are Anonymous, we are legion, we do not for...</td>\n",
       "      <td>Law Enforcement Scoured Protester Communicatio...</td>\n",
       "      <td>371</td>\n",
       "      <td>https://t.co/dSp76LYFoG</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/bMfXd5GpdO]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 15:00:00</td>\n",
       "      <td>[law, enforcement, scoured, protester, communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1267818307358306304</td>\n",
       "      <td>2020-06-02 08:00:14</td>\n",
       "      <td>1260614797307109376</td>\n",
       "      <td>AOC_movement</td>\n",
       "      <td>852</td>\n",
       "      <td>90</td>\n",
       "      <td>We are a student-led independent network that ...</td>\n",
       "      <td>From London to Minneapolis and Jerusalem we ha...</td>\n",
       "      <td>105</td>\n",
       "      <td>https://t.co/EW2gH1yn0h</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/BGIJdTa3pu]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 08:00:00</td>\n",
       "      <td>[london, minneapolis, jerusalem, take, street,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1274765258578628608</td>\n",
       "      <td>2020-06-21 12:04:56</td>\n",
       "      <td>422798683</td>\n",
       "      <td>LatestAnonNews</td>\n",
       "      <td>347388</td>\n",
       "      <td>186</td>\n",
       "      <td>Multiple Anons reporting Anonymous intel, worl...</td>\n",
       "      <td>A woman spots and confronts one of the officer...</td>\n",
       "      <td>837</td>\n",
       "      <td>https://t.co/0ZlqsBtIKj</td>\n",
       "      <td>[#GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/flnJ6SaMxd]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-21 12:00:00</td>\n",
       "      <td>[woman, spot, confronts, one, officers,, j., a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1279928744342433792</td>\n",
       "      <td>2020-07-05 18:02:47</td>\n",
       "      <td>815977295575912448</td>\n",
       "      <td>herwithluv</td>\n",
       "      <td>3415</td>\n",
       "      <td>281</td>\n",
       "      <td>#VMINKOOK: on god if you pay hyung line dust w...</td>\n",
       "      <td>daniel nelson. works at blue plate &amp;amp; co in...</td>\n",
       "      <td>100</td>\n",
       "      <td>https://t.co/kVlhqeOM2z</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/MHakh4rCOp]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-05 18:00:00</td>\n",
       "      <td>[daniel, nelson., work, blue, plate, co, minne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1276892357858865152</td>\n",
       "      <td>2020-06-27 08:57:16</td>\n",
       "      <td>1146645420099215360</td>\n",
       "      <td>PeopleMvmt</td>\n",
       "      <td>11277</td>\n",
       "      <td>570</td>\n",
       "      <td>Wellesley üìö ‚Ä¢ Progressive Cat Mom ‚Ä¢ Justice an...</td>\n",
       "      <td>BREAKING: Minneapolis yesterday. Protests have...</td>\n",
       "      <td>290</td>\n",
       "      <td>https://t.co/MwMZ8BpJy7</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/snsHAYrxhd]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-27 08:00:00</td>\n",
       "      <td>[breaking:, minneapolis, yesterday., protests,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1276991586581319680</td>\n",
       "      <td>2020-06-27 15:31:34</td>\n",
       "      <td>422798683</td>\n",
       "      <td>LatestAnonNews</td>\n",
       "      <td>347521</td>\n",
       "      <td>187</td>\n",
       "      <td>Multiple Anons reporting Anonymous intel, worl...</td>\n",
       "      <td>The FBI is investigating after a piece of rope...</td>\n",
       "      <td>141</td>\n",
       "      <td>https://t.co/sI6VlOcleT</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/9Rn8owvg9y]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-27 15:00:00</td>\n",
       "      <td>[fbi, investigate, piece, rope, resemble, noos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1267975822310207488</td>\n",
       "      <td>2020-06-02 18:26:08</td>\n",
       "      <td>328167568</td>\n",
       "      <td>MsIsisKing</td>\n",
       "      <td>44956</td>\n",
       "      <td>619</td>\n",
       "      <td>Actress &amp; Top Model - MGMT: BGolden@PinkHammer...</td>\n",
       "      <td>This black trans woman was beating in Minneapo...</td>\n",
       "      <td>334</td>\n",
       "      <td>https://t.co/3DV8I1aC3H</td>\n",
       "      <td>[#BlackLivesMatter....ALL]</td>\n",
       "      <td>[https://t.co/trPGprwVrS]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 18:00:00</td>\n",
       "      <td>[black, trans, woman, beat, minneapolis, hair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1265430916769501184</td>\n",
       "      <td>2020-05-26 17:53:35</td>\n",
       "      <td>476478812</td>\n",
       "      <td>SollyBandz_</td>\n",
       "      <td>3551</td>\n",
       "      <td>0</td>\n",
       "      <td>SollyBandz || HMU FOR FEATURES, SEND BEATS, ET...</td>\n",
       "      <td>They Going Crazy In Minneapolis RnüíØüëèüèæ #ICantBr...</td>\n",
       "      <td>39746</td>\n",
       "      <td>https://t.co/6efmPeDMa1</td>\n",
       "      <td>[#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-26 17:00:00</td>\n",
       "      <td>[going, crazy, minneapolis, rnüíØüëèüèæ, #icantbreat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1265313992546934784</td>\n",
       "      <td>2020-05-26 10:08:58</td>\n",
       "      <td>1328853859</td>\n",
       "      <td>Belive_Kinuthia</td>\n",
       "      <td>69824</td>\n",
       "      <td>26852</td>\n",
       "      <td>Son of a Peasant.Father.Murang'a Senatorial As...</td>\n",
       "      <td>A Minneapolis police officer killed this Black...</td>\n",
       "      <td>502</td>\n",
       "      <td>https://t.co/sMYoh1VLcc</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/fJLRXgK3Vb]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-26 10:00:00</td>\n",
       "      <td>[minneapolis, police, officer, kill, black, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1276868178161872896</td>\n",
       "      <td>2020-06-27 07:21:11</td>\n",
       "      <td>21149655</td>\n",
       "      <td>ArthurSchwartz</td>\n",
       "      <td>95478</td>\n",
       "      <td>167</td>\n",
       "      <td>None</td>\n",
       "      <td>They don‚Äôt want you calling anyone for help wh...</td>\n",
       "      <td>178</td>\n",
       "      <td>https://t.co/vYIJegmGlX</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/tZFmsDvLrS]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-27 07:00:00</td>\n",
       "      <td>[don‚Äôt, want, call, anyone, help, terrorists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1266490213255217152</td>\n",
       "      <td>2020-05-29 16:02:51</td>\n",
       "      <td>1221434521</td>\n",
       "      <td>Athenselder</td>\n",
       "      <td>2159</td>\n",
       "      <td>1724</td>\n",
       "      <td>IG:CNCCMI \\nArtist/Producer\\n\\n„ÅÆÂ≠¶Áîü ÂπªË°ì</td>\n",
       "      <td>\"A Mirror to our Times\"\\nA freestyle about the...</td>\n",
       "      <td>246</td>\n",
       "      <td>https://t.co/OfkOyx9a0h</td>\n",
       "      <td>[#BlackLivesMatter, #JusticeForGeorgeFlyod, #G...</td>\n",
       "      <td>[https://t.co/L6cWmrt4fe]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-29 16:00:00</td>\n",
       "      <td>[\"a, mirror, times\", freestyle, situation, ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1276627295071989760</td>\n",
       "      <td>2020-06-26 15:24:00</td>\n",
       "      <td>187429137</td>\n",
       "      <td>minhtngo</td>\n",
       "      <td>41526</td>\n",
       "      <td>395</td>\n",
       "      <td>Aquila non capit muscas. | Usual caveats apply...</td>\n",
       "      <td>The Minneapolis City Council unanimously voted...</td>\n",
       "      <td>124</td>\n",
       "      <td>https://t.co/yCoS9XfQnb</td>\n",
       "      <td>[#GeorgeFloyd., #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/c3d25ohK7t]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 15:00:00</td>\n",
       "      <td>[minneapolis, city, council, unanimously, vote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1265909367351599104</td>\n",
       "      <td>2020-05-28 01:34:47</td>\n",
       "      <td>3023037872</td>\n",
       "      <td>TruthRaiderHQ</td>\n",
       "      <td>80646</td>\n",
       "      <td>5442</td>\n",
       "      <td>#bitcoin Veteran. Libertarian. üáÆüá±üè≥Ô∏è‚Äçüåàüá∫üá≤</td>\n",
       "      <td>Minneapolis is burning down. No law enforcemen...</td>\n",
       "      <td>125</td>\n",
       "      <td>https://t.co/WzRTSKOxAx</td>\n",
       "      <td>[#Minneapolis, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/6zWvmDBpiU]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-28 01:00:00</td>\n",
       "      <td>[minneapolis, burn, down., law, enforcement, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1270061804886974464</td>\n",
       "      <td>2020-06-08 12:35:05</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6521097</td>\n",
       "      <td>833</td>\n",
       "      <td>We support the weak against the powerful. Resi...</td>\n",
       "      <td>Derek Chauvin, the former Minneapolis police o...</td>\n",
       "      <td>4880</td>\n",
       "      <td>https://t.co/k03OZgI5Px</td>\n",
       "      <td>[#GeorgeFloyd,, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/ncgBUgP5Rg]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-08 12:00:00</td>\n",
       "      <td>[derek, chauvin,, former, minneapolis, police,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1266788641269047296</td>\n",
       "      <td>2020-05-30 11:48:42</td>\n",
       "      <td>148137271</td>\n",
       "      <td>rickastley</td>\n",
       "      <td>148566</td>\n",
       "      <td>1767</td>\n",
       "      <td>My new album The Best Of Me is out now! It‚Äôs b...</td>\n",
       "      <td>I‚Äôve been wanting to post something about the ...</td>\n",
       "      <td>757</td>\n",
       "      <td>https://t.co/IZsrRw4mA4</td>\n",
       "      <td>[#equality, #georgefloyd, #blacklivesmatter]</td>\n",
       "      <td>[https://t.co/BPwbKYYRtY]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-30 11:00:00</td>\n",
       "      <td>[i‚Äôve, want, post, something, terrible, event,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1267982520911527936</td>\n",
       "      <td>2020-06-02 18:52:45</td>\n",
       "      <td>31108138</td>\n",
       "      <td>RaquelWillis_</td>\n",
       "      <td>66670</td>\n",
       "      <td>6770</td>\n",
       "      <td>director of comms, @msfoundation ‚ú¶ writer, act...</td>\n",
       "      <td>A young Black trans woman named #IyannaDior wa...</td>\n",
       "      <td>11671</td>\n",
       "      <td>https://t.co/hRTHlLINLq</td>\n",
       "      <td>[#IyannaDior, #BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 18:00:00</td>\n",
       "      <td>[young, black, trans, woman, name, #iyannadior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1268243960004132864</td>\n",
       "      <td>2020-06-03 12:11:37</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6488044</td>\n",
       "      <td>827</td>\n",
       "      <td>We support the weak against the powerful. #Bla...</td>\n",
       "      <td>Under massive public pressure, Minnesota Attor...</td>\n",
       "      <td>16580</td>\n",
       "      <td>https://t.co/ii1es7eaSK</td>\n",
       "      <td>[#GeorgeFloyd,, #ICantBreathe, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/dGkLEiiryr]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-03 12:00:00</td>\n",
       "      <td>[massive, public, pressure,, minnesota, attorn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RT_id          created_at              user_id  \\\n",
       "0   1271228625933619200 2020-06-11 17:51:37           2835451658   \n",
       "1   1277286903641866240 2020-06-28 11:05:03             98956941   \n",
       "2   1266515656037588992 2020-05-29 17:43:57  1258993079287197696   \n",
       "3   1266752338221506560 2020-05-30 09:24:27            175065805   \n",
       "4   1266782245869805568 2020-05-30 11:23:17   743998433455808512   \n",
       "5   1267058623911428096 2020-05-31 05:41:31  1219534043210973184   \n",
       "6   1267218415736872960 2020-05-31 16:16:28            195271137   \n",
       "7   1267001484387840000 2020-05-31 01:54:28           1538581122   \n",
       "8   1265744876823609344 2020-05-27 14:41:09  1187684601315115008   \n",
       "9   1266286100743520256 2020-05-29 02:31:47           2835451658   \n",
       "10  1276695049628155904 2020-06-26 19:53:14  1090715513586679808   \n",
       "11  1266224353420759040 2020-05-28 22:26:25   793282577733971968   \n",
       "12  1267249755949658112 2020-05-31 18:21:00            373157754   \n",
       "13  1265324197846437888 2020-05-26 10:49:32  1237424166439211008   \n",
       "14  1267294687657816064 2020-05-31 21:19:33             46764346   \n",
       "15  1266232670423375872 2020-05-28 22:59:28           2835451658   \n",
       "16  1280325917571678208 2020-07-06 20:21:00  1090715513586679808   \n",
       "17  1280644907267502080 2020-07-07 17:28:33  1268182793441468416   \n",
       "18  1270601548851081216 2020-06-10 00:19:50           2835451658   \n",
       "19  1276627066889179136 2020-06-26 15:23:05            279390084   \n",
       "20  1267818307358306304 2020-06-02 08:00:14  1260614797307109376   \n",
       "21  1274765258578628608 2020-06-21 12:04:56            422798683   \n",
       "22  1279928744342433792 2020-07-05 18:02:47   815977295575912448   \n",
       "23  1276892357858865152 2020-06-27 08:57:16  1146645420099215360   \n",
       "24  1276991586581319680 2020-06-27 15:31:34            422798683   \n",
       "25  1267975822310207488 2020-06-02 18:26:08            328167568   \n",
       "26  1265430916769501184 2020-05-26 17:53:35            476478812   \n",
       "27  1265313992546934784 2020-05-26 10:08:58           1328853859   \n",
       "28  1276868178161872896 2020-06-27 07:21:11             21149655   \n",
       "29  1266490213255217152 2020-05-29 16:02:51           1221434521   \n",
       "30  1276627295071989760 2020-06-26 15:24:00            187429137   \n",
       "31  1265909367351599104 2020-05-28 01:34:47           3023037872   \n",
       "32  1270061804886974464 2020-06-08 12:35:05            373157754   \n",
       "33  1266788641269047296 2020-05-30 11:48:42            148137271   \n",
       "34  1267982520911527936 2020-06-02 18:52:45             31108138   \n",
       "35  1268243960004132864 2020-06-03 12:11:37            373157754   \n",
       "\n",
       "          user_name  followers_count  following_count  \\\n",
       "0         MrAndyNgo           457035              667   \n",
       "1          afbranco            44179             2197   \n",
       "2           NedWhat              825              203   \n",
       "3            dviyer            14843             6822   \n",
       "4      JoeyMillsXXX           273650              474   \n",
       "5       ilcanhavhav             1570              276   \n",
       "6        larryelder           796374               98   \n",
       "7        Zionocracy            19074              290   \n",
       "8        selenesrat              532              434   \n",
       "9         MrAndyNgo           462908              665   \n",
       "10     JoshuaPotash            99403              595   \n",
       "11  BrittaneyCheers              157              126   \n",
       "12  YourAnonCentral          6473187              828   \n",
       "13   ProBlacktivist             1477               87   \n",
       "14      MisterPreda           244684              523   \n",
       "15        MrAndyNgo           467735              667   \n",
       "16     JoshuaPotash           101233              605   \n",
       "17    Eric6H6rtm6nn              268              174   \n",
       "18        MrAndyNgo           467652              666   \n",
       "19     YourAnonNews          7528103              817   \n",
       "20     AOC_movement              852               90   \n",
       "21   LatestAnonNews           347388              186   \n",
       "22       herwithluv             3415              281   \n",
       "23       PeopleMvmt            11277              570   \n",
       "24   LatestAnonNews           347521              187   \n",
       "25       MsIsisKing            44956              619   \n",
       "26      SollyBandz_             3551                0   \n",
       "27  Belive_Kinuthia            69824            26852   \n",
       "28   ArthurSchwartz            95478              167   \n",
       "29      Athenselder             2159             1724   \n",
       "30         minhtngo            41526              395   \n",
       "31    TruthRaiderHQ            80646             5442   \n",
       "32  YourAnonCentral          6521097              833   \n",
       "33       rickastley           148566             1767   \n",
       "34    RaquelWillis_            66670             6770   \n",
       "35  YourAnonCentral          6488044              827   \n",
       "\n",
       "                                     user_description  \\\n",
       "0   Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "1   Nationally syndicated Political Cartoonist (Cr...   \n",
       "2   #GLROfficial\\nGreat Lakes Region \\nContent of ...   \n",
       "3   South Asian American activist, lawyer. Senior ...   \n",
       "4   14x award winning pornstar‚Äî Your mothers worst...   \n",
       "5                              fƒ±rat aydƒ±nus fan club   \n",
       "6   Sage from South Central; Larry Elder Show; Sal...   \n",
       "7   Founder of #PalestineRemainsForEver & #Palesti...   \n",
       "8   Ôº©ÔΩçÔΩçÔΩÅ Ôº≥ÔΩÖÔΩåÔΩÖÔΩéÔΩÅ Ôº≥ÔΩîÔΩÅÔΩé ÔΩâÔΩé ÔΩîÔΩàÔΩÖ ÔΩêÔΩïÔΩíÔΩÖÔΩìÔΩî ÔΩÜÔΩèÔΩíÔΩçüíñ\\n\\nùìò ùì™ùìµùìºùì∏...   \n",
       "9   Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "10  Trump is the biggest threat to Democracy that ...   \n",
       "11  God is everythingüôèüèæBorn and Raised Georgia Pea...   \n",
       "12  We support the weak against the powerful. #Bla...   \n",
       "13               Unapologetically Black. she/her/hers   \n",
       "14  a little bit of everything | producer ‚Ä¢ creato...   \n",
       "15  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "16  Trump is the biggest threat to Democracy that ...   \n",
       "17                                                  ìÇÄ   \n",
       "18  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "19  We are Anonymous, we are legion, we do not for...   \n",
       "20  We are a student-led independent network that ...   \n",
       "21  Multiple Anons reporting Anonymous intel, worl...   \n",
       "22  #VMINKOOK: on god if you pay hyung line dust w...   \n",
       "23  Wellesley üìö ‚Ä¢ Progressive Cat Mom ‚Ä¢ Justice an...   \n",
       "24  Multiple Anons reporting Anonymous intel, worl...   \n",
       "25  Actress & Top Model - MGMT: BGolden@PinkHammer...   \n",
       "26  SollyBandz || HMU FOR FEATURES, SEND BEATS, ET...   \n",
       "27  Son of a Peasant.Father.Murang'a Senatorial As...   \n",
       "28                                               None   \n",
       "29              IG:CNCCMI \\nArtist/Producer\\n\\n„ÅÆÂ≠¶Áîü ÂπªË°ì   \n",
       "30  Aquila non capit muscas. | Usual caveats apply...   \n",
       "31            #bitcoin Veteran. Libertarian. üáÆüá±üè≥Ô∏è‚Äçüåàüá∫üá≤   \n",
       "32  We support the weak against the powerful. Resi...   \n",
       "33  My new album The Best Of Me is out now! It‚Äôs b...   \n",
       "34  director of comms, @msfoundation ‚ú¶ writer, act...   \n",
       "35  We support the weak against the powerful. #Bla...   \n",
       "\n",
       "                                                 text  retweet_count  \\\n",
       "0   This is what rioters did to the Minneapolis Sh...          21050   \n",
       "1   A.F. Branco Cartoon - Alpha News: Welcome to M...            207   \n",
       "2   Support from the #Amish community in Minneapol...         100842   \n",
       "3   The story of the #GandhiMahal restaurant in Mi...            198   \n",
       "4   All proceeds for the next 48 hours that I rece...            406   \n",
       "5   A man shoots a black protester with a shotgun ...           1783   \n",
       "6   Black lives matter. Black businesses, not so m...            435   \n",
       "7   Dear America\\nWhat Happened to #GeorgeFloyd in...           2568   \n",
       "8   Please call either (612) 348-5550 or (844) 278...            135   \n",
       "9   Person at Minneapolis BLM race riot makes it c...           3140   \n",
       "10  Don‚Äôt let the #BlackLivesMatter¬† protests disa...         112504   \n",
       "11  When people ask you why the people in Minneapo...           1593   \n",
       "12  Here‚Äôs a template to use when emailing the Min...           6988   \n",
       "13  A Black man was murdered last night by the Min...           9795   \n",
       "14  NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...           2501   \n",
       "15  Looters are ransacking the third police precin...           1669   \n",
       "16  It‚Äôs crazy how when the fires died down Minnea...           1227   \n",
       "17  They still haven't arrested or even looked har...            283   \n",
       "18  The DOJ has charged Branden Michael Wolfe, 23,...           4825   \n",
       "19  Law Enforcement Scoured Protester Communicatio...            371   \n",
       "20  From London to Minneapolis and Jerusalem we ha...            105   \n",
       "21  A woman spots and confronts one of the officer...            837   \n",
       "22  daniel nelson. works at blue plate &amp; co in...            100   \n",
       "23  BREAKING: Minneapolis yesterday. Protests have...            290   \n",
       "24  The FBI is investigating after a piece of rope...            141   \n",
       "25  This black trans woman was beating in Minneapo...            334   \n",
       "26  They Going Crazy In Minneapolis RnüíØüëèüèæ #ICantBr...          39746   \n",
       "27  A Minneapolis police officer killed this Black...            502   \n",
       "28  They don‚Äôt want you calling anyone for help wh...            178   \n",
       "29  \"A Mirror to our Times\"\\nA freestyle about the...            246   \n",
       "30  The Minneapolis City Council unanimously voted...            124   \n",
       "31  Minneapolis is burning down. No law enforcemen...            125   \n",
       "32  Derek Chauvin, the former Minneapolis police o...           4880   \n",
       "33  I‚Äôve been wanting to post something about the ...            757   \n",
       "34  A young Black trans woman named #IyannaDior wa...          11671   \n",
       "35  Under massive public pressure, Minnesota Attor...          16580   \n",
       "\n",
       "                       t_co  \\\n",
       "0   https://t.co/GTAGV805i6   \n",
       "1   https://t.co/Web3mRCuEP   \n",
       "2   https://t.co/IBcGGubFAo   \n",
       "3   https://t.co/cHGBMwtDRh   \n",
       "4   https://t.co/c0EzZoJYvE   \n",
       "5   https://t.co/7qU01ryYV0   \n",
       "6   https://t.co/aZPPHBLtSZ   \n",
       "7   https://t.co/T9y8UT4btT   \n",
       "8   https://t.co/t2pBxgo176   \n",
       "9   https://t.co/XL6Dil4vX1   \n",
       "10  https://t.co/uTcDbAWOnu   \n",
       "11  https://t.co/BzTJ6E1IgF   \n",
       "12  https://t.co/1FizCM94lu   \n",
       "13  https://t.co/CBmzhz7MPq   \n",
       "14  https://t.co/SqKVx7ezfP   \n",
       "15  https://t.co/mbhS1qyZum   \n",
       "16  https://t.co/UJdJikVhdR   \n",
       "17  https://t.co/RQGZ7BvKYI   \n",
       "18  https://t.co/REQsiVCDaD   \n",
       "19  https://t.co/dSp76LYFoG   \n",
       "20  https://t.co/EW2gH1yn0h   \n",
       "21  https://t.co/0ZlqsBtIKj   \n",
       "22  https://t.co/kVlhqeOM2z   \n",
       "23  https://t.co/MwMZ8BpJy7   \n",
       "24  https://t.co/sI6VlOcleT   \n",
       "25  https://t.co/3DV8I1aC3H   \n",
       "26  https://t.co/6efmPeDMa1   \n",
       "27  https://t.co/sMYoh1VLcc   \n",
       "28  https://t.co/vYIJegmGlX   \n",
       "29  https://t.co/OfkOyx9a0h   \n",
       "30  https://t.co/yCoS9XfQnb   \n",
       "31  https://t.co/WzRTSKOxAx   \n",
       "32  https://t.co/k03OZgI5Px   \n",
       "33  https://t.co/IZsrRw4mA4   \n",
       "34  https://t.co/hRTHlLINLq   \n",
       "35  https://t.co/ii1es7eaSK   \n",
       "\n",
       "                                                 tags  \\\n",
       "0                                 [#BlackLivesMatter]   \n",
       "1   [#DefundThePolice, #AntifaTerrorist, #Democrat...   \n",
       "2   [#Amish, #AllLivesMatter, #BlackLivesMatter, #...   \n",
       "3      [#GandhiMahal, #solidarity, #BlackLivesMatter]   \n",
       "4   [#BlackLivesMatter, #JusticeForGeorgeFlyod, #J...   \n",
       "5                                 [#BlackLivesMatter]   \n",
       "6   [#BlackLivesMatter, #BlackBusinessMatters, #Ge...   \n",
       "7   [#GeorgeFloyd, #BlackLivesMatter, #Palestinian...   \n",
       "8   [#1087), #7162), #GeorgeFloyd, #BlackLivesMatter]   \n",
       "9          [#BlackLivesMatter, #GeorgeFloyd, #antifa]   \n",
       "10                                [#BlackLivesMatter]   \n",
       "11  [#3rdprecinct, #minneapolisriots, #Minneapolis...   \n",
       "12  [#BlackLivesMater, #BlackLivesMatter, #GeorgeF...   \n",
       "13                                [#BlackLivesMatter]   \n",
       "14                                [#BlackLivesMatter]   \n",
       "15         [#BlackLivesMatter, #Antifa, #GeorgeFloyd]   \n",
       "16                                [#BlackLivesMatter]   \n",
       "17                                                 []   \n",
       "18                                [#BlackLivesMatter]   \n",
       "19                                [#BlackLivesMatter]   \n",
       "20                                [#BlackLivesMatter]   \n",
       "21                  [#GeorgeFloyd, #BlackLivesMatter]   \n",
       "22                                [#BlackLivesMatter]   \n",
       "23                                [#BlackLivesMatter]   \n",
       "24                                [#BlackLivesMatter]   \n",
       "25                         [#BlackLivesMatter....ALL]   \n",
       "26   [#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]   \n",
       "27                                [#BlackLivesMatter]   \n",
       "28                                [#BlackLivesMatter]   \n",
       "29  [#BlackLivesMatter, #JusticeForGeorgeFlyod, #G...   \n",
       "30                 [#GeorgeFloyd., #BlackLivesMatter]   \n",
       "31                  [#Minneapolis, #BlackLivesMatter]   \n",
       "32                 [#GeorgeFloyd,, #BlackLivesMatter]   \n",
       "33       [#equality, #georgefloyd, #blacklivesmatter]   \n",
       "34                   [#IyannaDior, #BlackLivesMatter]   \n",
       "35  [#GeorgeFloyd,, #ICantBreathe, #BlackLivesMatter]   \n",
       "\n",
       "                                                 urls lang  \\\n",
       "0                           [https://t.co/GDYvNRmYi2]   en   \n",
       "1                           [https://t.co/zqUYrv0CPE]   en   \n",
       "2                           [https://t.co/qEkVkmOhGA]   en   \n",
       "3                           [https://t.co/sseVxOiFCe]   en   \n",
       "4   [https://t.co/uqQog24F7V, https://t.co/4jXkhvd...   en   \n",
       "5                                                  []   en   \n",
       "6   [https://t.co/nl7Hzo919z, https://t.co/wtjSmVE...   en   \n",
       "7                           [https://t.co/a3Z50ffn1c]   en   \n",
       "8                           [https://t.co/0VFZORnGcf]   en   \n",
       "9                           [https://t.co/5JNhq0qags]   en   \n",
       "10                          [https://t.co/TqSMix6Mpx]   en   \n",
       "11                          [https://t.co/5zvfCePZ7D]   en   \n",
       "12                          [https://t.co/uKjVdjfqYD]   en   \n",
       "13                          [https://t.co/C85N7OTJhr]   en   \n",
       "14                                                 []   en   \n",
       "15                                                 []   en   \n",
       "16                          [https://t.co/zjw0puBPap]   en   \n",
       "17  [https://t.co/uvCPQ4IxoB, https://t.co/y0xbpxt...   en   \n",
       "18  [https://t.co/PGWCjn8yr7, https://t.co/3QX3e93...   en   \n",
       "19                          [https://t.co/bMfXd5GpdO]   en   \n",
       "20                          [https://t.co/BGIJdTa3pu]   en   \n",
       "21                          [https://t.co/flnJ6SaMxd]   en   \n",
       "22                          [https://t.co/MHakh4rCOp]   en   \n",
       "23                          [https://t.co/snsHAYrxhd]   en   \n",
       "24                          [https://t.co/9Rn8owvg9y]   en   \n",
       "25                          [https://t.co/trPGprwVrS]   en   \n",
       "26                                                 []   en   \n",
       "27                          [https://t.co/fJLRXgK3Vb]   en   \n",
       "28                          [https://t.co/tZFmsDvLrS]   en   \n",
       "29                          [https://t.co/L6cWmrt4fe]   en   \n",
       "30                          [https://t.co/c3d25ohK7t]   en   \n",
       "31                          [https://t.co/6zWvmDBpiU]   en   \n",
       "32                          [https://t.co/ncgBUgP5Rg]   en   \n",
       "33                          [https://t.co/BPwbKYYRtY]   en   \n",
       "34                                                 []   en   \n",
       "35                          [https://t.co/dGkLEiiryr]   en   \n",
       "\n",
       "           created_at_h                                             tokens  \n",
       "0   2020-06-11 17:00:00  [rioter, minneapolis, sheraton, take, riots., ...  \n",
       "1   2020-06-28 11:00:00  [a.f., branco, cartoon, alpha, news:, welcome,...  \n",
       "2   2020-05-29 17:00:00  [support, #amish, community, minneapolis, #all...  \n",
       "3   2020-05-30 09:00:00  [story, #gandhimahal, restaurant, minneapolis,...  \n",
       "4   2020-05-30 11:00:00  [proceeds, next, 48, hour, receive, onlyfans, ...  \n",
       "5   2020-05-31 05:00:00  [man, shoot, black, protester, shotgun, minnea...  \n",
       "6   2020-05-31 16:00:00  [black, live, matter., black, businesses,, muc...  \n",
       "7   2020-05-31 01:00:00  [dear, america, happened, #georgefloyd, minnea...  \n",
       "8   2020-05-27 14:00:00  [call, either, (612), 348-5550, (844), 278-283...  \n",
       "9   2020-05-29 02:00:00  [person, minneapolis, blm, race, riot, make, c...  \n",
       "10  2020-06-26 19:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
       "11  2020-05-28 22:00:00  [people, ask, people, minneapolis, act, out., ...  \n",
       "12  2020-05-31 18:00:00  [here‚Äôs, template, use, email, minneapolis, po...  \n",
       "13  2020-05-26 10:00:00  [black, man, murder, last, night, minneapolis,...  \n",
       "14  2020-05-31 21:00:00  [numbers, call, incase, unlawful, arrests, pro...  \n",
       "15  2020-05-28 22:00:00  [looters, ransack, third, police, precinct, mi...  \n",
       "16  2020-07-06 20:00:00  [it‚Äôs, crazy, fire, die, minneapolis, lose, sp...  \n",
       "17  2020-07-07 17:00:00  [still, arrest, even, look, hard, 3, black, gu...  \n",
       "18  2020-06-10 00:00:00  [doj, charge, branden, michael, wolfe,, 23,, s...  \n",
       "19  2020-06-26 15:00:00  [law, enforcement, scoured, protester, communi...  \n",
       "20  2020-06-02 08:00:00  [london, minneapolis, jerusalem, take, street,...  \n",
       "21  2020-06-21 12:00:00  [woman, spot, confronts, one, officers,, j., a...  \n",
       "22  2020-07-05 18:00:00  [daniel, nelson., work, blue, plate, co, minne...  \n",
       "23  2020-06-27 08:00:00  [breaking:, minneapolis, yesterday., protests,...  \n",
       "24  2020-06-27 15:00:00  [fbi, investigate, piece, rope, resemble, noos...  \n",
       "25  2020-06-02 18:00:00  [black, trans, woman, beat, minneapolis, hair,...  \n",
       "26  2020-05-26 17:00:00  [going, crazy, minneapolis, rnüíØüëèüèæ, #icantbreat...  \n",
       "27  2020-05-26 10:00:00  [minneapolis, police, officer, kill, black, ma...  \n",
       "28  2020-06-27 07:00:00  [don‚Äôt, want, call, anyone, help, terrorists, ...  \n",
       "29  2020-05-29 16:00:00  [\"a, mirror, times\", freestyle, situation, ame...  \n",
       "30  2020-06-26 15:00:00  [minneapolis, city, council, unanimously, vote...  \n",
       "31  2020-05-28 01:00:00  [minneapolis, burn, down., law, enforcement, a...  \n",
       "32  2020-06-08 12:00:00  [derek, chauvin,, former, minneapolis, police,...  \n",
       "33  2020-05-30 11:00:00  [i‚Äôve, want, post, something, terrible, event,...  \n",
       "34  2020-06-02 18:00:00  [young, black, trans, woman, name, #iyannadior...  \n",
       "35  2020-06-03 12:00:00  [massive, public, pressure,, minnesota, attorn...  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_retweet = tw_data_files_to_df_json_filter(files_retweet, ['Minneapolis'])\n",
    "filtered_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_retweet))\n",
    "#filtered_retweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1271228625933619200</td>\n",
       "      <td>2020-06-11 17:51:37</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>457035</td>\n",
       "      <td>667</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>This is what rioters did to the Minneapolis Sh...</td>\n",
       "      <td>21050</td>\n",
       "      <td>https://t.co/GTAGV805i6</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/GDYvNRmYi2]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-11 17:00:00</td>\n",
       "      <td>[rioter, minneapolis, sheraton, take, riots., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1277286903641866240</td>\n",
       "      <td>2020-06-28 11:05:03</td>\n",
       "      <td>98956941</td>\n",
       "      <td>afbranco</td>\n",
       "      <td>44179</td>\n",
       "      <td>2197</td>\n",
       "      <td>Nationally syndicated Political Cartoonist (Cr...</td>\n",
       "      <td>A.F. Branco Cartoon - Alpha News: Welcome to M...</td>\n",
       "      <td>207</td>\n",
       "      <td>https://t.co/Web3mRCuEP</td>\n",
       "      <td>[#DefundThePolice, #AntifaTerrorist, #Democrat...</td>\n",
       "      <td>[https://t.co/zqUYrv0CPE]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-28 11:00:00</td>\n",
       "      <td>[a.f., branco, cartoon, alpha, news:, welcome,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1266515656037588992</td>\n",
       "      <td>2020-05-29 17:43:57</td>\n",
       "      <td>1258993079287197696</td>\n",
       "      <td>NedWhat</td>\n",
       "      <td>825</td>\n",
       "      <td>203</td>\n",
       "      <td>#GLROfficial\\nGreat Lakes Region \\nContent of ...</td>\n",
       "      <td>Support from the #Amish community in Minneapol...</td>\n",
       "      <td>100842</td>\n",
       "      <td>https://t.co/IBcGGubFAo</td>\n",
       "      <td>[#Amish, #AllLivesMatter, #BlackLivesMatter, #...</td>\n",
       "      <td>[https://t.co/qEkVkmOhGA]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-29 17:00:00</td>\n",
       "      <td>[support, #amish, community, minneapolis, #all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1266752338221506560</td>\n",
       "      <td>2020-05-30 09:24:27</td>\n",
       "      <td>175065805</td>\n",
       "      <td>dviyer</td>\n",
       "      <td>14843</td>\n",
       "      <td>6822</td>\n",
       "      <td>South Asian American activist, lawyer. Senior ...</td>\n",
       "      <td>The story of the #GandhiMahal restaurant in Mi...</td>\n",
       "      <td>198</td>\n",
       "      <td>https://t.co/cHGBMwtDRh</td>\n",
       "      <td>[#GandhiMahal, #solidarity, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/sseVxOiFCe]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-30 09:00:00</td>\n",
       "      <td>[story, #gandhimahal, restaurant, minneapolis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1266782245869805568</td>\n",
       "      <td>2020-05-30 11:23:17</td>\n",
       "      <td>743998433455808512</td>\n",
       "      <td>JoeyMillsXXX</td>\n",
       "      <td>273650</td>\n",
       "      <td>474</td>\n",
       "      <td>14x award winning pornstar‚Äî Your mothers worst...</td>\n",
       "      <td>All proceeds for the next 48 hours that I rece...</td>\n",
       "      <td>406</td>\n",
       "      <td>https://t.co/c0EzZoJYvE</td>\n",
       "      <td>[#BlackLivesMatter, #JusticeForGeorgeFlyod, #J...</td>\n",
       "      <td>[https://t.co/uqQog24F7V, https://t.co/4jXkhvd...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-30 11:00:00</td>\n",
       "      <td>[proceeds, next, 48, hour, receive, onlyfans, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1267058623911428096</td>\n",
       "      <td>2020-05-31 05:41:31</td>\n",
       "      <td>1219534043210973184</td>\n",
       "      <td>ilcanhavhav</td>\n",
       "      <td>1570</td>\n",
       "      <td>276</td>\n",
       "      <td>fƒ±rat aydƒ±nus fan club</td>\n",
       "      <td>A man shoots a black protester with a shotgun ...</td>\n",
       "      <td>1783</td>\n",
       "      <td>https://t.co/7qU01ryYV0</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 05:00:00</td>\n",
       "      <td>[man, shoot, black, protester, shotgun, minnea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1267218415736872960</td>\n",
       "      <td>2020-05-31 16:16:28</td>\n",
       "      <td>195271137</td>\n",
       "      <td>larryelder</td>\n",
       "      <td>796374</td>\n",
       "      <td>98</td>\n",
       "      <td>Sage from South Central; Larry Elder Show; Sal...</td>\n",
       "      <td>Black lives matter. Black businesses, not so m...</td>\n",
       "      <td>435</td>\n",
       "      <td>https://t.co/aZPPHBLtSZ</td>\n",
       "      <td>[#BlackLivesMatter, #BlackBusinessMatters, #Ge...</td>\n",
       "      <td>[https://t.co/nl7Hzo919z, https://t.co/wtjSmVE...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 16:00:00</td>\n",
       "      <td>[black, live, matter., black, businesses,, muc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1267001484387840000</td>\n",
       "      <td>2020-05-31 01:54:28</td>\n",
       "      <td>1538581122</td>\n",
       "      <td>Zionocracy</td>\n",
       "      <td>19074</td>\n",
       "      <td>290</td>\n",
       "      <td>Founder of #PalestineRemainsForEver &amp; #Palesti...</td>\n",
       "      <td>Dear America\\nWhat Happened to #GeorgeFloyd in...</td>\n",
       "      <td>2568</td>\n",
       "      <td>https://t.co/T9y8UT4btT</td>\n",
       "      <td>[#GeorgeFloyd, #BlackLivesMatter, #Palestinian...</td>\n",
       "      <td>[https://t.co/a3Z50ffn1c]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 01:00:00</td>\n",
       "      <td>[dear, america, happened, #georgefloyd, minnea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1265744876823609344</td>\n",
       "      <td>2020-05-27 14:41:09</td>\n",
       "      <td>1187684601315115008</td>\n",
       "      <td>selenesrat</td>\n",
       "      <td>532</td>\n",
       "      <td>434</td>\n",
       "      <td>Ôº©ÔΩçÔΩçÔΩÅ Ôº≥ÔΩÖÔΩåÔΩÖÔΩéÔΩÅ Ôº≥ÔΩîÔΩÅÔΩé ÔΩâÔΩé ÔΩîÔΩàÔΩÖ ÔΩêÔΩïÔΩíÔΩÖÔΩìÔΩî ÔΩÜÔΩèÔΩíÔΩçüíñ\\n\\nùìò ùì™ùìµùìºùì∏...</td>\n",
       "      <td>Please call either (612) 348-5550 or (844) 278...</td>\n",
       "      <td>135</td>\n",
       "      <td>https://t.co/t2pBxgo176</td>\n",
       "      <td>[#1087), #7162), #GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/0VFZORnGcf]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-27 14:00:00</td>\n",
       "      <td>[call, either, (612), 348-5550, (844), 278-283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1266286100743520256</td>\n",
       "      <td>2020-05-29 02:31:47</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>462908</td>\n",
       "      <td>665</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>Person at Minneapolis BLM race riot makes it c...</td>\n",
       "      <td>3140</td>\n",
       "      <td>https://t.co/XL6Dil4vX1</td>\n",
       "      <td>[#BlackLivesMatter, #GeorgeFloyd, #antifa]</td>\n",
       "      <td>[https://t.co/5JNhq0qags]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-29 02:00:00</td>\n",
       "      <td>[person, minneapolis, blm, race, riot, make, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1276695049628155904</td>\n",
       "      <td>2020-06-26 19:53:14</td>\n",
       "      <td>1090715513586679808</td>\n",
       "      <td>JoshuaPotash</td>\n",
       "      <td>99403</td>\n",
       "      <td>595</td>\n",
       "      <td>Trump is the biggest threat to Democracy that ...</td>\n",
       "      <td>Don‚Äôt let the #BlackLivesMatter¬† protests disa...</td>\n",
       "      <td>112504</td>\n",
       "      <td>https://t.co/uTcDbAWOnu</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/TqSMix6Mpx]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 19:00:00</td>\n",
       "      <td>[don‚Äôt, let, protest, disappear, tls., minneap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1266224353420759040</td>\n",
       "      <td>2020-05-28 22:26:25</td>\n",
       "      <td>793282577733971968</td>\n",
       "      <td>BrittaneyCheers</td>\n",
       "      <td>157</td>\n",
       "      <td>126</td>\n",
       "      <td>God is everythingüôèüèæBorn and Raised Georgia Pea...</td>\n",
       "      <td>When people ask you why the people in Minneapo...</td>\n",
       "      <td>1593</td>\n",
       "      <td>https://t.co/BzTJ6E1IgF</td>\n",
       "      <td>[#3rdprecinct, #minneapolisriots, #Minneapolis...</td>\n",
       "      <td>[https://t.co/5zvfCePZ7D]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-28 22:00:00</td>\n",
       "      <td>[people, ask, people, minneapolis, act, out., ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1267249755949658112</td>\n",
       "      <td>2020-05-31 18:21:00</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6473187</td>\n",
       "      <td>828</td>\n",
       "      <td>We support the weak against the powerful. #Bla...</td>\n",
       "      <td>Here‚Äôs a template to use when emailing the Min...</td>\n",
       "      <td>6988</td>\n",
       "      <td>https://t.co/1FizCM94lu</td>\n",
       "      <td>[#BlackLivesMater, #BlackLivesMatter, #GeorgeF...</td>\n",
       "      <td>[https://t.co/uKjVdjfqYD]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 18:00:00</td>\n",
       "      <td>[here‚Äôs, template, use, email, minneapolis, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1265324197846437888</td>\n",
       "      <td>2020-05-26 10:49:32</td>\n",
       "      <td>1237424166439211008</td>\n",
       "      <td>ProBlacktivist</td>\n",
       "      <td>1477</td>\n",
       "      <td>87</td>\n",
       "      <td>Unapologetically Black. she/her/hers</td>\n",
       "      <td>A Black man was murdered last night by the Min...</td>\n",
       "      <td>9795</td>\n",
       "      <td>https://t.co/CBmzhz7MPq</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/C85N7OTJhr]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-26 10:00:00</td>\n",
       "      <td>[black, man, murder, last, night, minneapolis,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1267294687657816064</td>\n",
       "      <td>2020-05-31 21:19:33</td>\n",
       "      <td>46764346</td>\n",
       "      <td>MisterPreda</td>\n",
       "      <td>244684</td>\n",
       "      <td>523</td>\n",
       "      <td>a little bit of everything | producer ‚Ä¢ creato...</td>\n",
       "      <td>NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...</td>\n",
       "      <td>2501</td>\n",
       "      <td>https://t.co/SqKVx7ezfP</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 21:00:00</td>\n",
       "      <td>[numbers, call, incase, unlawful, arrests, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1266232670423375872</td>\n",
       "      <td>2020-05-28 22:59:28</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>467735</td>\n",
       "      <td>667</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>Looters are ransacking the third police precin...</td>\n",
       "      <td>1669</td>\n",
       "      <td>https://t.co/mbhS1qyZum</td>\n",
       "      <td>[#BlackLivesMatter, #Antifa, #GeorgeFloyd]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-28 22:00:00</td>\n",
       "      <td>[looters, ransack, third, police, precinct, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1280325917571678208</td>\n",
       "      <td>2020-07-06 20:21:00</td>\n",
       "      <td>1090715513586679808</td>\n",
       "      <td>JoshuaPotash</td>\n",
       "      <td>101233</td>\n",
       "      <td>605</td>\n",
       "      <td>Trump is the biggest threat to Democracy that ...</td>\n",
       "      <td>It‚Äôs crazy how when the fires died down Minnea...</td>\n",
       "      <td>1227</td>\n",
       "      <td>https://t.co/UJdJikVhdR</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/zjw0puBPap]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-06 20:00:00</td>\n",
       "      <td>[it‚Äôs, crazy, fire, die, minneapolis, lose, sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1280644907267502080</td>\n",
       "      <td>2020-07-07 17:28:33</td>\n",
       "      <td>1268182793441468416</td>\n",
       "      <td>Eric6H6rtm6nn</td>\n",
       "      <td>268</td>\n",
       "      <td>174</td>\n",
       "      <td>ìÇÄ</td>\n",
       "      <td>They still haven't arrested or even looked har...</td>\n",
       "      <td>283</td>\n",
       "      <td>https://t.co/RQGZ7BvKYI</td>\n",
       "      <td>[]</td>\n",
       "      <td>[https://t.co/uvCPQ4IxoB, https://t.co/y0xbpxt...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-07 17:00:00</td>\n",
       "      <td>[still, arrest, even, look, hard, 3, black, gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1270601548851081216</td>\n",
       "      <td>2020-06-10 00:19:50</td>\n",
       "      <td>2835451658</td>\n",
       "      <td>MrAndyNgo</td>\n",
       "      <td>467652</td>\n",
       "      <td>666</td>\n",
       "      <td>Editor-at-large - @TPostMillennial. \"Unmasked\"...</td>\n",
       "      <td>The DOJ has charged Branden Michael Wolfe, 23,...</td>\n",
       "      <td>4825</td>\n",
       "      <td>https://t.co/REQsiVCDaD</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/PGWCjn8yr7, https://t.co/3QX3e93...</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-10 00:00:00</td>\n",
       "      <td>[doj, charge, branden, michael, wolfe,, 23,, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1276627066889179136</td>\n",
       "      <td>2020-06-26 15:23:05</td>\n",
       "      <td>279390084</td>\n",
       "      <td>YourAnonNews</td>\n",
       "      <td>7528103</td>\n",
       "      <td>817</td>\n",
       "      <td>We are Anonymous, we are legion, we do not for...</td>\n",
       "      <td>Law Enforcement Scoured Protester Communicatio...</td>\n",
       "      <td>371</td>\n",
       "      <td>https://t.co/dSp76LYFoG</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/bMfXd5GpdO]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 15:00:00</td>\n",
       "      <td>[law, enforcement, scoured, protester, communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1267818307358306304</td>\n",
       "      <td>2020-06-02 08:00:14</td>\n",
       "      <td>1260614797307109376</td>\n",
       "      <td>AOC_movement</td>\n",
       "      <td>852</td>\n",
       "      <td>90</td>\n",
       "      <td>We are a student-led independent network that ...</td>\n",
       "      <td>From London to Minneapolis and Jerusalem we ha...</td>\n",
       "      <td>105</td>\n",
       "      <td>https://t.co/EW2gH1yn0h</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/BGIJdTa3pu]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 08:00:00</td>\n",
       "      <td>[london, minneapolis, jerusalem, take, street,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1274765258578628608</td>\n",
       "      <td>2020-06-21 12:04:56</td>\n",
       "      <td>422798683</td>\n",
       "      <td>LatestAnonNews</td>\n",
       "      <td>347388</td>\n",
       "      <td>186</td>\n",
       "      <td>Multiple Anons reporting Anonymous intel, worl...</td>\n",
       "      <td>A woman spots and confronts one of the officer...</td>\n",
       "      <td>837</td>\n",
       "      <td>https://t.co/0ZlqsBtIKj</td>\n",
       "      <td>[#GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/flnJ6SaMxd]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-21 12:00:00</td>\n",
       "      <td>[woman, spot, confronts, one, officers,, j., a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1279928744342433792</td>\n",
       "      <td>2020-07-05 18:02:47</td>\n",
       "      <td>815977295575912448</td>\n",
       "      <td>herwithluv</td>\n",
       "      <td>3415</td>\n",
       "      <td>281</td>\n",
       "      <td>#VMINKOOK: on god if you pay hyung line dust w...</td>\n",
       "      <td>daniel nelson. works at blue plate &amp;amp; co in...</td>\n",
       "      <td>100</td>\n",
       "      <td>https://t.co/kVlhqeOM2z</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/MHakh4rCOp]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-05 18:00:00</td>\n",
       "      <td>[daniel, nelson., work, blue, plate, co, minne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1276892357858865152</td>\n",
       "      <td>2020-06-27 08:57:16</td>\n",
       "      <td>1146645420099215360</td>\n",
       "      <td>PeopleMvmt</td>\n",
       "      <td>11277</td>\n",
       "      <td>570</td>\n",
       "      <td>Wellesley üìö ‚Ä¢ Progressive Cat Mom ‚Ä¢ Justice an...</td>\n",
       "      <td>BREAKING: Minneapolis yesterday. Protests have...</td>\n",
       "      <td>290</td>\n",
       "      <td>https://t.co/MwMZ8BpJy7</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/snsHAYrxhd]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-27 08:00:00</td>\n",
       "      <td>[breaking:, minneapolis, yesterday., protests,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1276991586581319680</td>\n",
       "      <td>2020-06-27 15:31:34</td>\n",
       "      <td>422798683</td>\n",
       "      <td>LatestAnonNews</td>\n",
       "      <td>347521</td>\n",
       "      <td>187</td>\n",
       "      <td>Multiple Anons reporting Anonymous intel, worl...</td>\n",
       "      <td>The FBI is investigating after a piece of rope...</td>\n",
       "      <td>141</td>\n",
       "      <td>https://t.co/sI6VlOcleT</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/9Rn8owvg9y]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-27 15:00:00</td>\n",
       "      <td>[fbi, investigate, piece, rope, resemble, noos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1267975822310207488</td>\n",
       "      <td>2020-06-02 18:26:08</td>\n",
       "      <td>328167568</td>\n",
       "      <td>MsIsisKing</td>\n",
       "      <td>44956</td>\n",
       "      <td>619</td>\n",
       "      <td>Actress &amp; Top Model - MGMT: BGolden@PinkHammer...</td>\n",
       "      <td>This black trans woman was beating in Minneapo...</td>\n",
       "      <td>334</td>\n",
       "      <td>https://t.co/3DV8I1aC3H</td>\n",
       "      <td>[#BlackLivesMatter....ALL]</td>\n",
       "      <td>[https://t.co/trPGprwVrS]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 18:00:00</td>\n",
       "      <td>[black, trans, woman, beat, minneapolis, hair,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1265430916769501184</td>\n",
       "      <td>2020-05-26 17:53:35</td>\n",
       "      <td>476478812</td>\n",
       "      <td>SollyBandz_</td>\n",
       "      <td>3551</td>\n",
       "      <td>0</td>\n",
       "      <td>SollyBandz || HMU FOR FEATURES, SEND BEATS, ET...</td>\n",
       "      <td>They Going Crazy In Minneapolis RnüíØüëèüèæ #ICantBr...</td>\n",
       "      <td>39746</td>\n",
       "      <td>https://t.co/6efmPeDMa1</td>\n",
       "      <td>[#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-26 17:00:00</td>\n",
       "      <td>[going, crazy, minneapolis, rnüíØüëèüèæ, #icantbreat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1265313992546934784</td>\n",
       "      <td>2020-05-26 10:08:58</td>\n",
       "      <td>1328853859</td>\n",
       "      <td>Belive_Kinuthia</td>\n",
       "      <td>69824</td>\n",
       "      <td>26852</td>\n",
       "      <td>Son of a Peasant.Father.Murang'a Senatorial As...</td>\n",
       "      <td>A Minneapolis police officer killed this Black...</td>\n",
       "      <td>502</td>\n",
       "      <td>https://t.co/sMYoh1VLcc</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/fJLRXgK3Vb]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-26 10:00:00</td>\n",
       "      <td>[minneapolis, police, officer, kill, black, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1276868178161872896</td>\n",
       "      <td>2020-06-27 07:21:11</td>\n",
       "      <td>21149655</td>\n",
       "      <td>ArthurSchwartz</td>\n",
       "      <td>95478</td>\n",
       "      <td>167</td>\n",
       "      <td>None</td>\n",
       "      <td>They don‚Äôt want you calling anyone for help wh...</td>\n",
       "      <td>178</td>\n",
       "      <td>https://t.co/vYIJegmGlX</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/tZFmsDvLrS]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-27 07:00:00</td>\n",
       "      <td>[don‚Äôt, want, call, anyone, help, terrorists, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1266490213255217152</td>\n",
       "      <td>2020-05-29 16:02:51</td>\n",
       "      <td>1221434521</td>\n",
       "      <td>Athenselder</td>\n",
       "      <td>2159</td>\n",
       "      <td>1724</td>\n",
       "      <td>IG:CNCCMI \\nArtist/Producer\\n\\n„ÅÆÂ≠¶Áîü ÂπªË°ì</td>\n",
       "      <td>\"A Mirror to our Times\"\\nA freestyle about the...</td>\n",
       "      <td>246</td>\n",
       "      <td>https://t.co/OfkOyx9a0h</td>\n",
       "      <td>[#BlackLivesMatter, #JusticeForGeorgeFlyod, #G...</td>\n",
       "      <td>[https://t.co/L6cWmrt4fe]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-29 16:00:00</td>\n",
       "      <td>[\"a, mirror, times\", freestyle, situation, ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1276627295071989760</td>\n",
       "      <td>2020-06-26 15:24:00</td>\n",
       "      <td>187429137</td>\n",
       "      <td>minhtngo</td>\n",
       "      <td>41526</td>\n",
       "      <td>395</td>\n",
       "      <td>Aquila non capit muscas. | Usual caveats apply...</td>\n",
       "      <td>The Minneapolis City Council unanimously voted...</td>\n",
       "      <td>124</td>\n",
       "      <td>https://t.co/yCoS9XfQnb</td>\n",
       "      <td>[#GeorgeFloyd., #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/c3d25ohK7t]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-26 15:00:00</td>\n",
       "      <td>[minneapolis, city, council, unanimously, vote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1265909367351599104</td>\n",
       "      <td>2020-05-28 01:34:47</td>\n",
       "      <td>3023037872</td>\n",
       "      <td>TruthRaiderHQ</td>\n",
       "      <td>80646</td>\n",
       "      <td>5442</td>\n",
       "      <td>#bitcoin Veteran. Libertarian. üáÆüá±üè≥Ô∏è‚Äçüåàüá∫üá≤</td>\n",
       "      <td>Minneapolis is burning down. No law enforcemen...</td>\n",
       "      <td>125</td>\n",
       "      <td>https://t.co/WzRTSKOxAx</td>\n",
       "      <td>[#Minneapolis, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/6zWvmDBpiU]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-28 01:00:00</td>\n",
       "      <td>[minneapolis, burn, down., law, enforcement, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1270061804886974464</td>\n",
       "      <td>2020-06-08 12:35:05</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6521097</td>\n",
       "      <td>833</td>\n",
       "      <td>We support the weak against the powerful. Resi...</td>\n",
       "      <td>Derek Chauvin, the former Minneapolis police o...</td>\n",
       "      <td>4880</td>\n",
       "      <td>https://t.co/k03OZgI5Px</td>\n",
       "      <td>[#GeorgeFloyd,, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/ncgBUgP5Rg]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-08 12:00:00</td>\n",
       "      <td>[derek, chauvin,, former, minneapolis, police,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1266788641269047296</td>\n",
       "      <td>2020-05-30 11:48:42</td>\n",
       "      <td>148137271</td>\n",
       "      <td>rickastley</td>\n",
       "      <td>148566</td>\n",
       "      <td>1767</td>\n",
       "      <td>My new album The Best Of Me is out now! It‚Äôs b...</td>\n",
       "      <td>I‚Äôve been wanting to post something about the ...</td>\n",
       "      <td>757</td>\n",
       "      <td>https://t.co/IZsrRw4mA4</td>\n",
       "      <td>[#equality, #georgefloyd, #blacklivesmatter]</td>\n",
       "      <td>[https://t.co/BPwbKYYRtY]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-30 11:00:00</td>\n",
       "      <td>[i‚Äôve, want, post, something, terrible, event,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1267982520911527936</td>\n",
       "      <td>2020-06-02 18:52:45</td>\n",
       "      <td>31108138</td>\n",
       "      <td>RaquelWillis_</td>\n",
       "      <td>66670</td>\n",
       "      <td>6770</td>\n",
       "      <td>director of comms, @msfoundation ‚ú¶ writer, act...</td>\n",
       "      <td>A young Black trans woman named #IyannaDior wa...</td>\n",
       "      <td>11671</td>\n",
       "      <td>https://t.co/hRTHlLINLq</td>\n",
       "      <td>[#IyannaDior, #BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 18:00:00</td>\n",
       "      <td>[young, black, trans, woman, name, #iyannadior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1268243960004132864</td>\n",
       "      <td>2020-06-03 12:11:37</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6488044</td>\n",
       "      <td>827</td>\n",
       "      <td>We support the weak against the powerful. #Bla...</td>\n",
       "      <td>Under massive public pressure, Minnesota Attor...</td>\n",
       "      <td>16580</td>\n",
       "      <td>https://t.co/ii1es7eaSK</td>\n",
       "      <td>[#GeorgeFloyd,, #ICantBreathe, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/dGkLEiiryr]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-03 12:00:00</td>\n",
       "      <td>[massive, public, pressure,, minnesota, attorn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  RT_id          created_at              user_id  \\\n",
       "0   1271228625933619200 2020-06-11 17:51:37           2835451658   \n",
       "1   1277286903641866240 2020-06-28 11:05:03             98956941   \n",
       "2   1266515656037588992 2020-05-29 17:43:57  1258993079287197696   \n",
       "3   1266752338221506560 2020-05-30 09:24:27            175065805   \n",
       "4   1266782245869805568 2020-05-30 11:23:17   743998433455808512   \n",
       "5   1267058623911428096 2020-05-31 05:41:31  1219534043210973184   \n",
       "6   1267218415736872960 2020-05-31 16:16:28            195271137   \n",
       "7   1267001484387840000 2020-05-31 01:54:28           1538581122   \n",
       "8   1265744876823609344 2020-05-27 14:41:09  1187684601315115008   \n",
       "9   1266286100743520256 2020-05-29 02:31:47           2835451658   \n",
       "10  1276695049628155904 2020-06-26 19:53:14  1090715513586679808   \n",
       "11  1266224353420759040 2020-05-28 22:26:25   793282577733971968   \n",
       "12  1267249755949658112 2020-05-31 18:21:00            373157754   \n",
       "13  1265324197846437888 2020-05-26 10:49:32  1237424166439211008   \n",
       "14  1267294687657816064 2020-05-31 21:19:33             46764346   \n",
       "15  1266232670423375872 2020-05-28 22:59:28           2835451658   \n",
       "16  1280325917571678208 2020-07-06 20:21:00  1090715513586679808   \n",
       "17  1280644907267502080 2020-07-07 17:28:33  1268182793441468416   \n",
       "18  1270601548851081216 2020-06-10 00:19:50           2835451658   \n",
       "19  1276627066889179136 2020-06-26 15:23:05            279390084   \n",
       "20  1267818307358306304 2020-06-02 08:00:14  1260614797307109376   \n",
       "21  1274765258578628608 2020-06-21 12:04:56            422798683   \n",
       "22  1279928744342433792 2020-07-05 18:02:47   815977295575912448   \n",
       "23  1276892357858865152 2020-06-27 08:57:16  1146645420099215360   \n",
       "24  1276991586581319680 2020-06-27 15:31:34            422798683   \n",
       "25  1267975822310207488 2020-06-02 18:26:08            328167568   \n",
       "26  1265430916769501184 2020-05-26 17:53:35            476478812   \n",
       "27  1265313992546934784 2020-05-26 10:08:58           1328853859   \n",
       "28  1276868178161872896 2020-06-27 07:21:11             21149655   \n",
       "29  1266490213255217152 2020-05-29 16:02:51           1221434521   \n",
       "30  1276627295071989760 2020-06-26 15:24:00            187429137   \n",
       "31  1265909367351599104 2020-05-28 01:34:47           3023037872   \n",
       "32  1270061804886974464 2020-06-08 12:35:05            373157754   \n",
       "33  1266788641269047296 2020-05-30 11:48:42            148137271   \n",
       "34  1267982520911527936 2020-06-02 18:52:45             31108138   \n",
       "35  1268243960004132864 2020-06-03 12:11:37            373157754   \n",
       "\n",
       "          user_name  followers_count  following_count  \\\n",
       "0         MrAndyNgo           457035              667   \n",
       "1          afbranco            44179             2197   \n",
       "2           NedWhat              825              203   \n",
       "3            dviyer            14843             6822   \n",
       "4      JoeyMillsXXX           273650              474   \n",
       "5       ilcanhavhav             1570              276   \n",
       "6        larryelder           796374               98   \n",
       "7        Zionocracy            19074              290   \n",
       "8        selenesrat              532              434   \n",
       "9         MrAndyNgo           462908              665   \n",
       "10     JoshuaPotash            99403              595   \n",
       "11  BrittaneyCheers              157              126   \n",
       "12  YourAnonCentral          6473187              828   \n",
       "13   ProBlacktivist             1477               87   \n",
       "14      MisterPreda           244684              523   \n",
       "15        MrAndyNgo           467735              667   \n",
       "16     JoshuaPotash           101233              605   \n",
       "17    Eric6H6rtm6nn              268              174   \n",
       "18        MrAndyNgo           467652              666   \n",
       "19     YourAnonNews          7528103              817   \n",
       "20     AOC_movement              852               90   \n",
       "21   LatestAnonNews           347388              186   \n",
       "22       herwithluv             3415              281   \n",
       "23       PeopleMvmt            11277              570   \n",
       "24   LatestAnonNews           347521              187   \n",
       "25       MsIsisKing            44956              619   \n",
       "26      SollyBandz_             3551                0   \n",
       "27  Belive_Kinuthia            69824            26852   \n",
       "28   ArthurSchwartz            95478              167   \n",
       "29      Athenselder             2159             1724   \n",
       "30         minhtngo            41526              395   \n",
       "31    TruthRaiderHQ            80646             5442   \n",
       "32  YourAnonCentral          6521097              833   \n",
       "33       rickastley           148566             1767   \n",
       "34    RaquelWillis_            66670             6770   \n",
       "35  YourAnonCentral          6488044              827   \n",
       "\n",
       "                                     user_description  \\\n",
       "0   Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "1   Nationally syndicated Political Cartoonist (Cr...   \n",
       "2   #GLROfficial\\nGreat Lakes Region \\nContent of ...   \n",
       "3   South Asian American activist, lawyer. Senior ...   \n",
       "4   14x award winning pornstar‚Äî Your mothers worst...   \n",
       "5                              fƒ±rat aydƒ±nus fan club   \n",
       "6   Sage from South Central; Larry Elder Show; Sal...   \n",
       "7   Founder of #PalestineRemainsForEver & #Palesti...   \n",
       "8   Ôº©ÔΩçÔΩçÔΩÅ Ôº≥ÔΩÖÔΩåÔΩÖÔΩéÔΩÅ Ôº≥ÔΩîÔΩÅÔΩé ÔΩâÔΩé ÔΩîÔΩàÔΩÖ ÔΩêÔΩïÔΩíÔΩÖÔΩìÔΩî ÔΩÜÔΩèÔΩíÔΩçüíñ\\n\\nùìò ùì™ùìµùìºùì∏...   \n",
       "9   Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "10  Trump is the biggest threat to Democracy that ...   \n",
       "11  God is everythingüôèüèæBorn and Raised Georgia Pea...   \n",
       "12  We support the weak against the powerful. #Bla...   \n",
       "13               Unapologetically Black. she/her/hers   \n",
       "14  a little bit of everything | producer ‚Ä¢ creato...   \n",
       "15  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "16  Trump is the biggest threat to Democracy that ...   \n",
       "17                                                  ìÇÄ   \n",
       "18  Editor-at-large - @TPostMillennial. \"Unmasked\"...   \n",
       "19  We are Anonymous, we are legion, we do not for...   \n",
       "20  We are a student-led independent network that ...   \n",
       "21  Multiple Anons reporting Anonymous intel, worl...   \n",
       "22  #VMINKOOK: on god if you pay hyung line dust w...   \n",
       "23  Wellesley üìö ‚Ä¢ Progressive Cat Mom ‚Ä¢ Justice an...   \n",
       "24  Multiple Anons reporting Anonymous intel, worl...   \n",
       "25  Actress & Top Model - MGMT: BGolden@PinkHammer...   \n",
       "26  SollyBandz || HMU FOR FEATURES, SEND BEATS, ET...   \n",
       "27  Son of a Peasant.Father.Murang'a Senatorial As...   \n",
       "28                                               None   \n",
       "29              IG:CNCCMI \\nArtist/Producer\\n\\n„ÅÆÂ≠¶Áîü ÂπªË°ì   \n",
       "30  Aquila non capit muscas. | Usual caveats apply...   \n",
       "31            #bitcoin Veteran. Libertarian. üáÆüá±üè≥Ô∏è‚Äçüåàüá∫üá≤   \n",
       "32  We support the weak against the powerful. Resi...   \n",
       "33  My new album The Best Of Me is out now! It‚Äôs b...   \n",
       "34  director of comms, @msfoundation ‚ú¶ writer, act...   \n",
       "35  We support the weak against the powerful. #Bla...   \n",
       "\n",
       "                                                 text  retweet_count  \\\n",
       "0   This is what rioters did to the Minneapolis Sh...          21050   \n",
       "1   A.F. Branco Cartoon - Alpha News: Welcome to M...            207   \n",
       "2   Support from the #Amish community in Minneapol...         100842   \n",
       "3   The story of the #GandhiMahal restaurant in Mi...            198   \n",
       "4   All proceeds for the next 48 hours that I rece...            406   \n",
       "5   A man shoots a black protester with a shotgun ...           1783   \n",
       "6   Black lives matter. Black businesses, not so m...            435   \n",
       "7   Dear America\\nWhat Happened to #GeorgeFloyd in...           2568   \n",
       "8   Please call either (612) 348-5550 or (844) 278...            135   \n",
       "9   Person at Minneapolis BLM race riot makes it c...           3140   \n",
       "10  Don‚Äôt let the #BlackLivesMatter¬† protests disa...         112504   \n",
       "11  When people ask you why the people in Minneapo...           1593   \n",
       "12  Here‚Äôs a template to use when emailing the Min...           6988   \n",
       "13  A Black man was murdered last night by the Min...           9795   \n",
       "14  NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...           2501   \n",
       "15  Looters are ransacking the third police precin...           1669   \n",
       "16  It‚Äôs crazy how when the fires died down Minnea...           1227   \n",
       "17  They still haven't arrested or even looked har...            283   \n",
       "18  The DOJ has charged Branden Michael Wolfe, 23,...           4825   \n",
       "19  Law Enforcement Scoured Protester Communicatio...            371   \n",
       "20  From London to Minneapolis and Jerusalem we ha...            105   \n",
       "21  A woman spots and confronts one of the officer...            837   \n",
       "22  daniel nelson. works at blue plate &amp; co in...            100   \n",
       "23  BREAKING: Minneapolis yesterday. Protests have...            290   \n",
       "24  The FBI is investigating after a piece of rope...            141   \n",
       "25  This black trans woman was beating in Minneapo...            334   \n",
       "26  They Going Crazy In Minneapolis RnüíØüëèüèæ #ICantBr...          39746   \n",
       "27  A Minneapolis police officer killed this Black...            502   \n",
       "28  They don‚Äôt want you calling anyone for help wh...            178   \n",
       "29  \"A Mirror to our Times\"\\nA freestyle about the...            246   \n",
       "30  The Minneapolis City Council unanimously voted...            124   \n",
       "31  Minneapolis is burning down. No law enforcemen...            125   \n",
       "32  Derek Chauvin, the former Minneapolis police o...           4880   \n",
       "33  I‚Äôve been wanting to post something about the ...            757   \n",
       "34  A young Black trans woman named #IyannaDior wa...          11671   \n",
       "35  Under massive public pressure, Minnesota Attor...          16580   \n",
       "\n",
       "                       t_co  \\\n",
       "0   https://t.co/GTAGV805i6   \n",
       "1   https://t.co/Web3mRCuEP   \n",
       "2   https://t.co/IBcGGubFAo   \n",
       "3   https://t.co/cHGBMwtDRh   \n",
       "4   https://t.co/c0EzZoJYvE   \n",
       "5   https://t.co/7qU01ryYV0   \n",
       "6   https://t.co/aZPPHBLtSZ   \n",
       "7   https://t.co/T9y8UT4btT   \n",
       "8   https://t.co/t2pBxgo176   \n",
       "9   https://t.co/XL6Dil4vX1   \n",
       "10  https://t.co/uTcDbAWOnu   \n",
       "11  https://t.co/BzTJ6E1IgF   \n",
       "12  https://t.co/1FizCM94lu   \n",
       "13  https://t.co/CBmzhz7MPq   \n",
       "14  https://t.co/SqKVx7ezfP   \n",
       "15  https://t.co/mbhS1qyZum   \n",
       "16  https://t.co/UJdJikVhdR   \n",
       "17  https://t.co/RQGZ7BvKYI   \n",
       "18  https://t.co/REQsiVCDaD   \n",
       "19  https://t.co/dSp76LYFoG   \n",
       "20  https://t.co/EW2gH1yn0h   \n",
       "21  https://t.co/0ZlqsBtIKj   \n",
       "22  https://t.co/kVlhqeOM2z   \n",
       "23  https://t.co/MwMZ8BpJy7   \n",
       "24  https://t.co/sI6VlOcleT   \n",
       "25  https://t.co/3DV8I1aC3H   \n",
       "26  https://t.co/6efmPeDMa1   \n",
       "27  https://t.co/sMYoh1VLcc   \n",
       "28  https://t.co/vYIJegmGlX   \n",
       "29  https://t.co/OfkOyx9a0h   \n",
       "30  https://t.co/yCoS9XfQnb   \n",
       "31  https://t.co/WzRTSKOxAx   \n",
       "32  https://t.co/k03OZgI5Px   \n",
       "33  https://t.co/IZsrRw4mA4   \n",
       "34  https://t.co/hRTHlLINLq   \n",
       "35  https://t.co/ii1es7eaSK   \n",
       "\n",
       "                                                 tags  \\\n",
       "0                                 [#BlackLivesMatter]   \n",
       "1   [#DefundThePolice, #AntifaTerrorist, #Democrat...   \n",
       "2   [#Amish, #AllLivesMatter, #BlackLivesMatter, #...   \n",
       "3      [#GandhiMahal, #solidarity, #BlackLivesMatter]   \n",
       "4   [#BlackLivesMatter, #JusticeForGeorgeFlyod, #J...   \n",
       "5                                 [#BlackLivesMatter]   \n",
       "6   [#BlackLivesMatter, #BlackBusinessMatters, #Ge...   \n",
       "7   [#GeorgeFloyd, #BlackLivesMatter, #Palestinian...   \n",
       "8   [#1087), #7162), #GeorgeFloyd, #BlackLivesMatter]   \n",
       "9          [#BlackLivesMatter, #GeorgeFloyd, #antifa]   \n",
       "10                                [#BlackLivesMatter]   \n",
       "11  [#3rdprecinct, #minneapolisriots, #Minneapolis...   \n",
       "12  [#BlackLivesMater, #BlackLivesMatter, #GeorgeF...   \n",
       "13                                [#BlackLivesMatter]   \n",
       "14                                [#BlackLivesMatter]   \n",
       "15         [#BlackLivesMatter, #Antifa, #GeorgeFloyd]   \n",
       "16                                [#BlackLivesMatter]   \n",
       "17                                                 []   \n",
       "18                                [#BlackLivesMatter]   \n",
       "19                                [#BlackLivesMatter]   \n",
       "20                                [#BlackLivesMatter]   \n",
       "21                  [#GeorgeFloyd, #BlackLivesMatter]   \n",
       "22                                [#BlackLivesMatter]   \n",
       "23                                [#BlackLivesMatter]   \n",
       "24                                [#BlackLivesMatter]   \n",
       "25                         [#BlackLivesMatter....ALL]   \n",
       "26   [#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]   \n",
       "27                                [#BlackLivesMatter]   \n",
       "28                                [#BlackLivesMatter]   \n",
       "29  [#BlackLivesMatter, #JusticeForGeorgeFlyod, #G...   \n",
       "30                 [#GeorgeFloyd., #BlackLivesMatter]   \n",
       "31                  [#Minneapolis, #BlackLivesMatter]   \n",
       "32                 [#GeorgeFloyd,, #BlackLivesMatter]   \n",
       "33       [#equality, #georgefloyd, #blacklivesmatter]   \n",
       "34                   [#IyannaDior, #BlackLivesMatter]   \n",
       "35  [#GeorgeFloyd,, #ICantBreathe, #BlackLivesMatter]   \n",
       "\n",
       "                                                 urls lang  \\\n",
       "0                           [https://t.co/GDYvNRmYi2]   en   \n",
       "1                           [https://t.co/zqUYrv0CPE]   en   \n",
       "2                           [https://t.co/qEkVkmOhGA]   en   \n",
       "3                           [https://t.co/sseVxOiFCe]   en   \n",
       "4   [https://t.co/uqQog24F7V, https://t.co/4jXkhvd...   en   \n",
       "5                                                  []   en   \n",
       "6   [https://t.co/nl7Hzo919z, https://t.co/wtjSmVE...   en   \n",
       "7                           [https://t.co/a3Z50ffn1c]   en   \n",
       "8                           [https://t.co/0VFZORnGcf]   en   \n",
       "9                           [https://t.co/5JNhq0qags]   en   \n",
       "10                          [https://t.co/TqSMix6Mpx]   en   \n",
       "11                          [https://t.co/5zvfCePZ7D]   en   \n",
       "12                          [https://t.co/uKjVdjfqYD]   en   \n",
       "13                          [https://t.co/C85N7OTJhr]   en   \n",
       "14                                                 []   en   \n",
       "15                                                 []   en   \n",
       "16                          [https://t.co/zjw0puBPap]   en   \n",
       "17  [https://t.co/uvCPQ4IxoB, https://t.co/y0xbpxt...   en   \n",
       "18  [https://t.co/PGWCjn8yr7, https://t.co/3QX3e93...   en   \n",
       "19                          [https://t.co/bMfXd5GpdO]   en   \n",
       "20                          [https://t.co/BGIJdTa3pu]   en   \n",
       "21                          [https://t.co/flnJ6SaMxd]   en   \n",
       "22                          [https://t.co/MHakh4rCOp]   en   \n",
       "23                          [https://t.co/snsHAYrxhd]   en   \n",
       "24                          [https://t.co/9Rn8owvg9y]   en   \n",
       "25                          [https://t.co/trPGprwVrS]   en   \n",
       "26                                                 []   en   \n",
       "27                          [https://t.co/fJLRXgK3Vb]   en   \n",
       "28                          [https://t.co/tZFmsDvLrS]   en   \n",
       "29                          [https://t.co/L6cWmrt4fe]   en   \n",
       "30                          [https://t.co/c3d25ohK7t]   en   \n",
       "31                          [https://t.co/6zWvmDBpiU]   en   \n",
       "32                          [https://t.co/ncgBUgP5Rg]   en   \n",
       "33                          [https://t.co/BPwbKYYRtY]   en   \n",
       "34                                                 []   en   \n",
       "35                          [https://t.co/dGkLEiiryr]   en   \n",
       "\n",
       "           created_at_h                                             tokens  \n",
       "0   2020-06-11 17:00:00  [rioter, minneapolis, sheraton, take, riots., ...  \n",
       "1   2020-06-28 11:00:00  [a.f., branco, cartoon, alpha, news:, welcome,...  \n",
       "2   2020-05-29 17:00:00  [support, #amish, community, minneapolis, #all...  \n",
       "3   2020-05-30 09:00:00  [story, #gandhimahal, restaurant, minneapolis,...  \n",
       "4   2020-05-30 11:00:00  [proceeds, next, 48, hour, receive, onlyfans, ...  \n",
       "5   2020-05-31 05:00:00  [man, shoot, black, protester, shotgun, minnea...  \n",
       "6   2020-05-31 16:00:00  [black, live, matter., black, businesses,, muc...  \n",
       "7   2020-05-31 01:00:00  [dear, america, happened, #georgefloyd, minnea...  \n",
       "8   2020-05-27 14:00:00  [call, either, (612), 348-5550, (844), 278-283...  \n",
       "9   2020-05-29 02:00:00  [person, minneapolis, blm, race, riot, make, c...  \n",
       "10  2020-06-26 19:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
       "11  2020-05-28 22:00:00  [people, ask, people, minneapolis, act, out., ...  \n",
       "12  2020-05-31 18:00:00  [here‚Äôs, template, use, email, minneapolis, po...  \n",
       "13  2020-05-26 10:00:00  [black, man, murder, last, night, minneapolis,...  \n",
       "14  2020-05-31 21:00:00  [numbers, call, incase, unlawful, arrests, pro...  \n",
       "15  2020-05-28 22:00:00  [looters, ransack, third, police, precinct, mi...  \n",
       "16  2020-07-06 20:00:00  [it‚Äôs, crazy, fire, die, minneapolis, lose, sp...  \n",
       "17  2020-07-07 17:00:00  [still, arrest, even, look, hard, 3, black, gu...  \n",
       "18  2020-06-10 00:00:00  [doj, charge, branden, michael, wolfe,, 23,, s...  \n",
       "19  2020-06-26 15:00:00  [law, enforcement, scoured, protester, communi...  \n",
       "20  2020-06-02 08:00:00  [london, minneapolis, jerusalem, take, street,...  \n",
       "21  2020-06-21 12:00:00  [woman, spot, confronts, one, officers,, j., a...  \n",
       "22  2020-07-05 18:00:00  [daniel, nelson., work, blue, plate, co, minne...  \n",
       "23  2020-06-27 08:00:00  [breaking:, minneapolis, yesterday., protests,...  \n",
       "24  2020-06-27 15:00:00  [fbi, investigate, piece, rope, resemble, noos...  \n",
       "25  2020-06-02 18:00:00  [black, trans, woman, beat, minneapolis, hair,...  \n",
       "26  2020-05-26 17:00:00  [going, crazy, minneapolis, rnüíØüëèüèæ, #icantbreat...  \n",
       "27  2020-05-26 10:00:00  [minneapolis, police, officer, kill, black, ma...  \n",
       "28  2020-06-27 07:00:00  [don‚Äôt, want, call, anyone, help, terrorists, ...  \n",
       "29  2020-05-29 16:00:00  [\"a, mirror, times\", freestyle, situation, ame...  \n",
       "30  2020-06-26 15:00:00  [minneapolis, city, council, unanimously, vote...  \n",
       "31  2020-05-28 01:00:00  [minneapolis, burn, down., law, enforcement, a...  \n",
       "32  2020-06-08 12:00:00  [derek, chauvin,, former, minneapolis, police,...  \n",
       "33  2020-05-30 11:00:00  [i‚Äôve, want, post, something, terrible, event,...  \n",
       "34  2020-06-02 18:00:00  [young, black, trans, woman, name, #iyannadior...  \n",
       "35  2020-06-03 12:00:00  [massive, public, pressure,, minnesota, attorn...  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#filtered_retweet2 = tw_data_files_to_df_json_filter(files_retweet, 'sometown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RT_id, created_at, user_id, user_name, followers_count, following_count, user_description, text, retweet_count, t_co, tags, urls, lang, created_at_h, tokens, token_counter]\n",
       "Index: []"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(len(filtered_retweet2))\n",
    "#filtered_retweet2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "filtered_retweet3 = tw_data_files_to_df_json_filter(files_retweet, ['L.A.', 'Los Angeles','LA'])\n",
    "print(len(filtered_retweet3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1267294687657816064</td>\n",
       "      <td>2020-05-31 21:19:33</td>\n",
       "      <td>46764346</td>\n",
       "      <td>MisterPreda</td>\n",
       "      <td>245059</td>\n",
       "      <td>522</td>\n",
       "      <td>a little bit of everything | producer ‚Ä¢ creato...</td>\n",
       "      <td>NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...</td>\n",
       "      <td>2505</td>\n",
       "      <td>https://t.co/SqKVx7ezfP</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-05-31 21:00:00</td>\n",
       "      <td>[numbers, call, incase, unlawful, arrests, pro...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1279931800828227584</td>\n",
       "      <td>2020-07-05 18:14:55</td>\n",
       "      <td>38354090</td>\n",
       "      <td>ScottHech</td>\n",
       "      <td>86230</td>\n",
       "      <td>4474</td>\n",
       "      <td>Public defender. Imagining new ways to amplify...</td>\n",
       "      <td>609. LA District Attorney has declined to pros...</td>\n",
       "      <td>100</td>\n",
       "      <td>https://t.co/3SKkYWRbAl</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-05 18:00:00</td>\n",
       "      <td>[609., la, district, attorney, decline, prosec...</td>\n",
       "      <td>{'609.': 1, 'la': 1, 'district': 1, 'attorney'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279850015477776384</td>\n",
       "      <td>2020-07-05 12:49:56</td>\n",
       "      <td>23402579</td>\n",
       "      <td>CristineDeBerry</td>\n",
       "      <td>748</td>\n",
       "      <td>526</td>\n",
       "      <td>Mom. Immigrant. Wife. Lawyer. Chief of Staff @...</td>\n",
       "      <td>609 cases of police killing civilians and not ...</td>\n",
       "      <td>222</td>\n",
       "      <td>https://t.co/Y1oPM8mu2I</td>\n",
       "      <td>[#BlackLivesMatter, #LADA2020, #PoliceBrutality]</td>\n",
       "      <td>[https://t.co/gP6H58FV1J]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-05 12:00:00</td>\n",
       "      <td>[609, case, police, kill, civilian, 1, warrant...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1271797825412702208</td>\n",
       "      <td>2020-06-13 07:33:25</td>\n",
       "      <td>91597950</td>\n",
       "      <td>zoeyy227</td>\n",
       "      <td>13823</td>\n",
       "      <td>1173</td>\n",
       "      <td>part-time beauty enthusiast, part-time nerd, p...</td>\n",
       "      <td>She also owns La Face products, if anyone know...</td>\n",
       "      <td>2765</td>\n",
       "      <td>https://t.co/cSPBdXCDV7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-13 07:00:00</td>\n",
       "      <td>[also, la, face, products,, anyone, know, them...</td>\n",
       "      <td>{'also': 1, 'la': 1, 'face': 1, 'products,': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1268052021069807616</td>\n",
       "      <td>2020-06-02 23:28:55</td>\n",
       "      <td>373157754</td>\n",
       "      <td>YourAnonCentral</td>\n",
       "      <td>6459014</td>\n",
       "      <td>725</td>\n",
       "      <td>We support the weak against the powerful. #Bla...</td>\n",
       "      <td>LA Sheriff Villanueva admitting that curfews a...</td>\n",
       "      <td>6705</td>\n",
       "      <td>https://t.co/6gmVPHEQXs</td>\n",
       "      <td>[#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]</td>\n",
       "      <td>[https://t.co/GrFs301mtU]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-06-02 23:00:00</td>\n",
       "      <td>[la, sheriff, villanueva, admit, curfew, use, ...</td>\n",
       "      <td>{'la': 1, 'sheriff': 1, 'villanueva': 1, 'admi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RT_id          created_at    user_id        user_name  \\\n",
       "0  1267294687657816064 2020-05-31 21:19:33   46764346      MisterPreda   \n",
       "1  1279931800828227584 2020-07-05 18:14:55   38354090        ScottHech   \n",
       "2  1279850015477776384 2020-07-05 12:49:56   23402579  CristineDeBerry   \n",
       "3  1271797825412702208 2020-06-13 07:33:25   91597950         zoeyy227   \n",
       "4  1268052021069807616 2020-06-02 23:28:55  373157754  YourAnonCentral   \n",
       "\n",
       "   followers_count  following_count  \\\n",
       "0           245059              522   \n",
       "1            86230             4474   \n",
       "2              748              526   \n",
       "3            13823             1173   \n",
       "4          6459014              725   \n",
       "\n",
       "                                    user_description  \\\n",
       "0  a little bit of everything | producer ‚Ä¢ creato...   \n",
       "1  Public defender. Imagining new ways to amplify...   \n",
       "2  Mom. Immigrant. Wife. Lawyer. Chief of Staff @...   \n",
       "3  part-time beauty enthusiast, part-time nerd, p...   \n",
       "4  We support the weak against the powerful. #Bla...   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  NUMBERS TO CALL INCASE OF UNLAWFUL ARRESTS AT ...           2505   \n",
       "1  609. LA District Attorney has declined to pros...            100   \n",
       "2  609 cases of police killing civilians and not ...            222   \n",
       "3  She also owns La Face products, if anyone know...           2765   \n",
       "4  LA Sheriff Villanueva admitting that curfews a...           6705   \n",
       "\n",
       "                      t_co                                              tags  \\\n",
       "0  https://t.co/SqKVx7ezfP                               [#BlackLivesMatter]   \n",
       "1  https://t.co/3SKkYWRbAl                                                []   \n",
       "2  https://t.co/Y1oPM8mu2I  [#BlackLivesMatter, #LADA2020, #PoliceBrutality]   \n",
       "3  https://t.co/cSPBdXCDV7                                                []   \n",
       "4  https://t.co/6gmVPHEQXs  [#ICantBreathe, #GeorgeFloyd, #BlackLivesMatter]   \n",
       "\n",
       "                        urls lang         created_at_h  \\\n",
       "0                         []   en  2020-05-31 21:00:00   \n",
       "1                         []   en  2020-07-05 18:00:00   \n",
       "2  [https://t.co/gP6H58FV1J]   en  2020-07-05 12:00:00   \n",
       "3                         []   en  2020-06-13 07:00:00   \n",
       "4  [https://t.co/GrFs301mtU]   en  2020-06-02 23:00:00   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [numbers, call, incase, unlawful, arrests, pro...   \n",
       "1  [609., la, district, attorney, decline, prosec...   \n",
       "2  [609, case, police, kill, civilian, 1, warrant...   \n",
       "3  [also, la, face, products,, anyone, know, them...   \n",
       "4  [la, sheriff, villanueva, admit, curfew, use, ...   \n",
       "\n",
       "                                       token_counter  \n",
       "0                                                NaN  \n",
       "1  {'609.': 1, 'la': 1, 'district': 1, 'attorney'...  \n",
       "2                                                NaN  \n",
       "3  {'also': 1, 'la': 1, 'face': 1, 'products,': 1...  \n",
       "4  {'la': 1, 'sheriff': 1, 'villanueva': 1, 'admi...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_retweet3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_original = keep_recent_files(glob.glob(data_path + \"data_cumulative/original/*\"),\n",
    "        base_timestamp = process_datatime_d, days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tw_data_files_to_df_json_filter(files, filter_word, lines=True, float_dtype=None, verbose=False):\n",
    "    '''append and concat filtered data into a pandas.DataFrame'''\n",
    "    if type(filter_word) != list: raise ValueError(\"filter_word must be a list\")\n",
    "\n",
    "    df = []\n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files[0]:\n",
    "            columns = get_columns_json(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            \n",
    "        df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        if (len(filter_word) >1): idx = mark_tokens_contain_keywords(df_file, filter_word)\n",
    "        else: idx = mark_tokens_contain_keyword(df_file, filter_word[0])\n",
    "        df_file_filtered = df_file[idx]\n",
    "        print(df_file_filtered)\n",
    "        if len(df_file_filtered)>0:\n",
    "            df.append(df_file_filtered)\n",
    "    \n",
    "    if len(df)==0: return df_null\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    if float_dtype is None: return df\n",
    "    return convert_floats(df, float_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(['abc']) == list\n",
    "['abc'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = pd.read_json(files_original[10],\n",
    "         lines=True, orient='records')\n",
    "\n",
    "tmp_idx = mark_tokens_contain_keyword(tmp_data, 'Minneapolis')\n",
    "\n",
    "#tmp_filtered_original = tw_data_files_to_df_json_filter(files_original[:30], 'Minneapolis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tmp_idx)\n",
    "tmp_filtered_original = tmp_data[tmp_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       id          created_at  is_retweet  \\\n",
      "6291  1281278415501512704 2020-07-09 11:25:53       False   \n",
      "8052  1281274310817087488 2020-07-09 11:09:35        True   \n",
      "8953  1281273077410566144 2020-07-09 11:04:41        True   \n",
      "\n",
      "                    RT_id  RT_retweet_count              user_id  \\\n",
      "6291                                      0  1182301315738882048   \n",
      "8052  1277269898494914560            258299           2844074260   \n",
      "8953  1277269898494914560            258299           4489866973   \n",
      "\n",
      "         user_name  followers_count  following_count  \\\n",
      "6291   _gHOST3301_             2938                8   \n",
      "8052  GracieJazmin             1399              944   \n",
      "8953       ha_jpeg              134              316   \n",
      "\n",
      "                                                   text  \\\n",
      "6291  Minneapolis Police Department Officer Thomas L...   \n",
      "8052                                                      \n",
      "8953                                                      \n",
      "\n",
      "                                            quoted_text RT_text  \\\n",
      "6291                                                              \n",
      "8052  Don‚Äôt let the #BlackLivesMatter¬† protests disa...           \n",
      "8953  Don‚Äôt let the #BlackLivesMatter¬† protests disa...           \n",
      "\n",
      "                           t_co  \\\n",
      "6291  [https://t.co/gWH1SsAec5]   \n",
      "8052  [https://t.co/TqSMix6Mpx]   \n",
      "8953  [https://t.co/TqSMix6Mpx]   \n",
      "\n",
      "                                                   tags urls lang  \\\n",
      "6291  [#GeorgeFloyd, #GhostSec, #Anonymous, #GhostsI...   []   en   \n",
      "8052                                [#BlackLivesMatter]   []   en   \n",
      "8953                                [#BlackLivesMatter]   []   en   \n",
      "\n",
      "             created_at_h                                             tokens  \n",
      "6291  2020-07-09 11:00:00  [minneapolis, police, department, officer, tho...  \n",
      "8052  2020-07-09 11:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "8953  2020-07-09 11:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "                       id          created_at  is_retweet  \\\n",
      "2878  1281978012880171008 2020-07-11 09:45:50       False   \n",
      "5824  1281980549599551488 2020-07-11 09:55:55        True   \n",
      "\n",
      "                    RT_id  RT_retweet_count     user_id        user_name  \\\n",
      "2878                                      0  2439158484  FairTax4America   \n",
      "5824  1281778843611693058                 3   284198929       BernadeiaJ   \n",
      "\n",
      "      followers_count  following_count  \\\n",
      "2878            16514            14818   \n",
      "5824             3781              437   \n",
      "\n",
      "                                                   text  \\\n",
      "2878  If you believe #BlackLivesMatter, support more...   \n",
      "5824                                                      \n",
      "\n",
      "                                            quoted_text  \\\n",
      "2878  The Minneapolis police officers' claims come a...   \n",
      "5824  150 Minneapolis officers engage in a sick-out ...   \n",
      "\n",
      "                              RT_text  \\\n",
      "2878                                    \n",
      "5824  Now that‚Äôs the headline Javier!   \n",
      "\n",
      "                                                   t_co  \\\n",
      "2878  [https://t.co/jQM34Nne6G, https://t.co/xMmEJWQ...   \n",
      "5824                                                 []   \n",
      "\n",
      "                                                   tags urls lang  \\\n",
      "2878  [#BlackLivesMatter,, #GOP, #KAG2020, #MAGA, #M...   []   en   \n",
      "5824                                [#BlackLivesMatter]   []   en   \n",
      "\n",
      "             created_at_h                                             tokens  \n",
      "2878  2020-07-11 09:00:00  [believe, #blacklivesmatter,, support, funding...  \n",
      "5824  2020-07-11 09:00:00  [150, minneapolis, officer, engage, sick-out, ...  \n",
      "                        id          created_at  is_retweet  \\\n",
      "2592   1280167156844560384 2020-07-06 09:50:09        True   \n",
      "5410   1280168730069254144 2020-07-06 09:56:24        True   \n",
      "9114   1280161762633900032 2020-07-06 09:28:43        True   \n",
      "11135  1280164271914127360 2020-07-06 09:38:41        True   \n",
      "11184  1280164341086654464 2020-07-06 09:38:57       False   \n",
      "11697  1280165011084607488 2020-07-06 09:41:37        True   \n",
      "\n",
      "                     RT_id  RT_retweet_count              user_id  \\\n",
      "2592   1277269898494914560            258192            393857983   \n",
      "5410   1266611517304328192            183380   734564974341808128   \n",
      "9114   1277269898494914560            258192           3282267788   \n",
      "11135  1277269898494914560            258193            177034255   \n",
      "11184                                      0  1008799915244490752   \n",
      "11697  1277269898494914560            258193           3098052026   \n",
      "\n",
      "             user_name  followers_count  following_count  \\\n",
      "2592           jeyckah              222              282   \n",
      "5410    90s_Plain_Jane               60              104   \n",
      "9114     MeganSheyenne               28               62   \n",
      "11135   Anissa_Marie12               33               79   \n",
      "11184  Dunigan88791694             3463             4788   \n",
      "11697          jessGSG              256              203   \n",
      "\n",
      "                                                    text  \\\n",
      "2592                                                       \n",
      "5410                                                       \n",
      "9114                                                       \n",
      "11135                                                      \n",
      "11184  George Floyd: Former officer Tou Thao posts bo...   \n",
      "11697                                                      \n",
      "\n",
      "                                             quoted_text RT_text  \\\n",
      "2592   Don‚Äôt let the #BlackLivesMatter¬† protests disa...           \n",
      "5410   Support from the #Amish community in Minneapol...           \n",
      "9114   Don‚Äôt let the #BlackLivesMatter¬† protests disa...           \n",
      "11135  Don‚Äôt let the #BlackLivesMatter¬† protests disa...           \n",
      "11184                                                              \n",
      "11697  Don‚Äôt let the #BlackLivesMatter¬† protests disa...           \n",
      "\n",
      "                            t_co  \\\n",
      "2592   [https://t.co/TqSMix6Mpx]   \n",
      "5410   [https://t.co/qEkVkmOhGA]   \n",
      "9114   [https://t.co/TqSMix6Mpx]   \n",
      "11135  [https://t.co/TqSMix6Mpx]   \n",
      "11184  [https://t.co/2tmkZ5st04]   \n",
      "11697  [https://t.co/TqSMix6Mpx]   \n",
      "\n",
      "                                                    tags urls lang  \\\n",
      "2592                                 [#BlackLivesMatter]   []   en   \n",
      "5410   [#Amish, #AllLivesMatter, #BlackLivesMatter, #...   []   en   \n",
      "9114                                 [#BlackLivesMatter]   []   en   \n",
      "11135                                [#BlackLivesMatter]   []   en   \n",
      "11184           [#EndPoliceBrutality, #BlackLivesMatter]   []   en   \n",
      "11697                                [#BlackLivesMatter]   []   en   \n",
      "\n",
      "              created_at_h                                             tokens  \n",
      "2592   2020-07-06 09:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "5410   2020-07-06 09:00:00  [support, #amish, community, minneapolis, #all...  \n",
      "9114   2020-07-06 09:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "11135  2020-07-06 09:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "11184  2020-07-06 09:00:00  [george, floyd:, former, officer, tou, thao, p...  \n",
      "11697  2020-07-06 09:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "                       id          created_at  is_retweet  \\\n",
      "485   1282358746908372992 2020-07-12 10:58:44        True   \n",
      "566   1282358908930215936 2020-07-12 10:59:23       False   \n",
      "1744  1282348506284535808 2020-07-12 10:18:03        True   \n",
      "6039  1282344371610947584 2020-07-12 10:01:37        True   \n",
      "8284  1282354242465009664 2020-07-12 10:40:51       False   \n",
      "\n",
      "                    RT_id  RT_retweet_count     user_id     user_name  \\\n",
      "485   1281717490117115905                47   307605091  andywpearson   \n",
      "566                                       0  2841714842       BKaysac   \n",
      "1744  1277269898494914560            258187   200363404  gabinanigans   \n",
      "6039  1282341748044263424                 1   709560893      dahart66   \n",
      "8284                                      0  3800203769   backendknox   \n",
      "\n",
      "      followers_count  following_count  \\\n",
      "485               341              341   \n",
      "566             11804            12515   \n",
      "1744              821              629   \n",
      "6039              786              525   \n",
      "8284             1019              619   \n",
      "\n",
      "                                                   text  \\\n",
      "485                                                       \n",
      "566   The racial riots, initiated by the movement #B...   \n",
      "1744                                                      \n",
      "6039                                                      \n",
      "8284                              Wat block was dis on?   \n",
      "\n",
      "                                            quoted_text  \\\n",
      "485   Over 150 Minneapolis officers file disability ...   \n",
      "566                                                       \n",
      "1744  Don‚Äôt let the #BlackLivesMatter¬† protests disa...   \n",
      "6039  Minnesota Dems willfully allowed Minneapolis t...   \n",
      "8284  This black trans woman was beating in Minneapo...   \n",
      "\n",
      "                                                RT_text  \\\n",
      "485   Over 150 Minneapolis officers engage in a sick...   \n",
      "566                                                       \n",
      "1744                                                      \n",
      "6039  Both Local Govt AND #BlackLivesMatter Organiza...   \n",
      "8284                                                      \n",
      "\n",
      "                                                   t_co  \\\n",
      "485   [https://t.co/WThey333hG, https://t.co/hJ3VvjO...   \n",
      "566                                                  []   \n",
      "1744                          [https://t.co/TqSMix6Mpx]   \n",
      "6039                                                 []   \n",
      "8284                          [https://t.co/trPGprwVrS]   \n",
      "\n",
      "                                                   tags urls lang  \\\n",
      "485                                                  []   []   en   \n",
      "566   [#BlackLivesMatter, #FordFoundation, #SorosOpe...   []   en   \n",
      "1744                                [#BlackLivesMatter]   []   en   \n",
      "6039                                                 []   []   en   \n",
      "8284                         [#BlackLivesMatter....ALL]   []   en   \n",
      "\n",
      "             created_at_h                                             tokens  \n",
      "485   2020-07-12 10:00:00  [150, minneapolis, officer, file, disability, ...  \n",
      "566   2020-07-12 10:00:00  [racial, riots,, initiate, movement, (funded, ...  \n",
      "1744  2020-07-12 10:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "6039  2020-07-12 10:00:00  [minnesota, dems, willfully, allow, minneapoli...  \n",
      "8284  2020-07-12 10:00:00  [wat, block, dis, on?this, black, trans, woman...  \n",
      "                       id          created_at  is_retweet  \\\n",
      "648   1282061287606882304 2020-07-11 15:16:45        True   \n",
      "3877  1282071565157498880 2020-07-11 15:57:35        True   \n",
      "\n",
      "                    RT_id  RT_retweet_count             user_id     user_name  \\\n",
      "648   1277269898494914560            258214           488750881       __dlocc   \n",
      "3877  1281717490117115905                43  856668514299543552  LynnRankinen   \n",
      "\n",
      "      followers_count  following_count text  \\\n",
      "648              2688             1810        \n",
      "3877               79               87        \n",
      "\n",
      "                                            quoted_text  \\\n",
      "648   Don‚Äôt let the #BlackLivesMatter¬† protests disa...   \n",
      "3877  Over 150 Minneapolis officers file disability ...   \n",
      "\n",
      "                                                RT_text  \\\n",
      "648                                                       \n",
      "3877  Over 150 Minneapolis officers engage in a sick...   \n",
      "\n",
      "                                                   t_co                 tags  \\\n",
      "648                           [https://t.co/TqSMix6Mpx]  [#BlackLivesMatter]   \n",
      "3877  [https://t.co/WThey333hG, https://t.co/hJ3VvjO...                   []   \n",
      "\n",
      "     urls lang         created_at_h  \\\n",
      "648    []   en  2020-07-11 15:00:00   \n",
      "3877   []   en  2020-07-11 15:00:00   \n",
      "\n",
      "                                                 tokens  \n",
      "648   [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
      "3877  [150, minneapolis, officer, file, disability, ...  \n"
     ]
    }
   ],
   "source": [
    "tmp_filtered_original = tw_data_files_to_df_json_filter(files_original[:5], ['Minneapolis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_filtered_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp_filtered_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>RT_id</th>\n",
       "      <th>RT_retweet_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>text</th>\n",
       "      <th>quoted_text</th>\n",
       "      <th>RT_text</th>\n",
       "      <th>t_co</th>\n",
       "      <th>tags</th>\n",
       "      <th>urls</th>\n",
       "      <th>lang</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1281278415501512704</td>\n",
       "      <td>2020-07-09 11:25:53</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1182301315738882048</td>\n",
       "      <td>_gHOST3301_</td>\n",
       "      <td>2938</td>\n",
       "      <td>8</td>\n",
       "      <td>Minneapolis Police Department Officer Thomas L...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[https://t.co/gWH1SsAec5]</td>\n",
       "      <td>[#GeorgeFloyd, #GhostSec, #Anonymous, #GhostsI...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>[minneapolis, police, department, officer, tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1281274310817087488</td>\n",
       "      <td>2020-07-09 11:09:35</td>\n",
       "      <td>True</td>\n",
       "      <td>1277269898494914560</td>\n",
       "      <td>258299</td>\n",
       "      <td>2844074260</td>\n",
       "      <td>GracieJazmin</td>\n",
       "      <td>1399</td>\n",
       "      <td>944</td>\n",
       "      <td></td>\n",
       "      <td>Don‚Äôt let the #BlackLivesMatter¬† protests disa...</td>\n",
       "      <td></td>\n",
       "      <td>[https://t.co/TqSMix6Mpx]</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>[don‚Äôt, let, protest, disappear, tls., minneap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1281273077410566144</td>\n",
       "      <td>2020-07-09 11:04:41</td>\n",
       "      <td>True</td>\n",
       "      <td>1277269898494914560</td>\n",
       "      <td>258299</td>\n",
       "      <td>4489866973</td>\n",
       "      <td>ha_jpeg</td>\n",
       "      <td>134</td>\n",
       "      <td>316</td>\n",
       "      <td></td>\n",
       "      <td>Don‚Äôt let the #BlackLivesMatter¬† protests disa...</td>\n",
       "      <td></td>\n",
       "      <td>[https://t.co/TqSMix6Mpx]</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>[don‚Äôt, let, protest, disappear, tls., minneap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1281978012880171008</td>\n",
       "      <td>2020-07-11 09:45:50</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2439158484</td>\n",
       "      <td>FairTax4America</td>\n",
       "      <td>16514</td>\n",
       "      <td>14818</td>\n",
       "      <td>If you believe #BlackLivesMatter, support more...</td>\n",
       "      <td>The Minneapolis police officers' claims come a...</td>\n",
       "      <td></td>\n",
       "      <td>[https://t.co/jQM34Nne6G, https://t.co/xMmEJWQ...</td>\n",
       "      <td>[#BlackLivesMatter,, #GOP, #KAG2020, #MAGA, #M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-11 09:00:00</td>\n",
       "      <td>[believe, #blacklivesmatter,, support, funding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1281980549599551488</td>\n",
       "      <td>2020-07-11 09:55:55</td>\n",
       "      <td>True</td>\n",
       "      <td>1281778843611693058</td>\n",
       "      <td>3</td>\n",
       "      <td>284198929</td>\n",
       "      <td>BernadeiaJ</td>\n",
       "      <td>3781</td>\n",
       "      <td>437</td>\n",
       "      <td></td>\n",
       "      <td>150 Minneapolis officers engage in a sick-out ...</td>\n",
       "      <td>Now that‚Äôs the headline Javier!</td>\n",
       "      <td>[]</td>\n",
       "      <td>[#BlackLivesMatter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "      <td>2020-07-11 09:00:00</td>\n",
       "      <td>[150, minneapolis, officer, engage, sick-out, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id          created_at  is_retweet                RT_id  \\\n",
       "0  1281278415501512704 2020-07-09 11:25:53       False                        \n",
       "1  1281274310817087488 2020-07-09 11:09:35        True  1277269898494914560   \n",
       "2  1281273077410566144 2020-07-09 11:04:41        True  1277269898494914560   \n",
       "3  1281978012880171008 2020-07-11 09:45:50       False                        \n",
       "4  1281980549599551488 2020-07-11 09:55:55        True  1281778843611693058   \n",
       "\n",
       "   RT_retweet_count              user_id        user_name  followers_count  \\\n",
       "0                 0  1182301315738882048      _gHOST3301_             2938   \n",
       "1            258299           2844074260     GracieJazmin             1399   \n",
       "2            258299           4489866973          ha_jpeg              134   \n",
       "3                 0           2439158484  FairTax4America            16514   \n",
       "4                 3            284198929       BernadeiaJ             3781   \n",
       "\n",
       "   following_count                                               text  \\\n",
       "0                8  Minneapolis Police Department Officer Thomas L...   \n",
       "1              944                                                      \n",
       "2              316                                                      \n",
       "3            14818  If you believe #BlackLivesMatter, support more...   \n",
       "4              437                                                      \n",
       "\n",
       "                                         quoted_text  \\\n",
       "0                                                      \n",
       "1  Don‚Äôt let the #BlackLivesMatter¬† protests disa...   \n",
       "2  Don‚Äôt let the #BlackLivesMatter¬† protests disa...   \n",
       "3  The Minneapolis police officers' claims come a...   \n",
       "4  150 Minneapolis officers engage in a sick-out ...   \n",
       "\n",
       "                           RT_text  \\\n",
       "0                                    \n",
       "1                                    \n",
       "2                                    \n",
       "3                                    \n",
       "4  Now that‚Äôs the headline Javier!   \n",
       "\n",
       "                                                t_co  \\\n",
       "0                          [https://t.co/gWH1SsAec5]   \n",
       "1                          [https://t.co/TqSMix6Mpx]   \n",
       "2                          [https://t.co/TqSMix6Mpx]   \n",
       "3  [https://t.co/jQM34Nne6G, https://t.co/xMmEJWQ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                                tags urls lang  \\\n",
       "0  [#GeorgeFloyd, #GhostSec, #Anonymous, #GhostsI...   []   en   \n",
       "1                                [#BlackLivesMatter]   []   en   \n",
       "2                                [#BlackLivesMatter]   []   en   \n",
       "3  [#BlackLivesMatter,, #GOP, #KAG2020, #MAGA, #M...   []   en   \n",
       "4                                [#BlackLivesMatter]   []   en   \n",
       "\n",
       "          created_at_h                                             tokens  \n",
       "0  2020-07-09 11:00:00  [minneapolis, police, department, officer, tho...  \n",
       "1  2020-07-09 11:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
       "2  2020-07-09 11:00:00  [don‚Äôt, let, protest, disappear, tls., minneap...  \n",
       "3  2020-07-11 09:00:00  [believe, #blacklivesmatter,, support, funding...  \n",
       "4  2020-07-11 09:00:00  [150, minneapolis, officer, engage, sick-out, ...  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_filtered_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Minneapolis Police Department Officer Thomas Lane, Implicated In The Killing Of George Floyd , Attorney, Seeks Dismissal Of Charges In #GeorgeFloyd Killing. Has Filed A Motion To Dismiss. #GhostSec #Anonymous #GhostsInYourWires #protests #BlackLivesMatter #BlackLivesMattters https://t.co/gWH1SsAec5'"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_filtered_original.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_filtered_original.quoted_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'minneapolis' in tmp_filtered_original.tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_var_in_valuelist(df, var, valuelist):\n",
    "    # returns an index indicating whether variable var is in valuelist\n",
    "    return df[var].apply(lambda x: x in valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 =  pd.read_json(files_original[], orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = mark_var_in_valuelist(tmp1, 'RT_id', filtered_retweet.RT_id.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tmp2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tw_data_files_to_df_json_match_id(files, varname_id, list_ids,\n",
    "                                      lines=True, float_dtype=None, verbose=False):\n",
    "    '''append and concat filtered data into a pandas.DataFrame'''\n",
    "    if type(list_ids) != list: raise ValueError(\"list_ids must be a list\")\n",
    "\n",
    "    df = []\n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files[0]:\n",
    "            columns = get_columns_json(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            \n",
    "        df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        idx = mark_var_in_valuelist(df_file, varname_id, list_ids)\n",
    "        df_file_filtered = df_file[idx]\n",
    "        if len(df_file_filtered)>0:\n",
    "            df.append(df_file_filtered)\n",
    "    \n",
    "    if len(df)==0: return df_null\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    if float_dtype is None: return df\n",
    "    return convert_floats(df, float_dtype)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_matched_original = tw_data_files_to_df_json_match_id(files_original[:20], \n",
    "                                  'RT_id', list(filtered_retweet.RT_id.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_matched_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ['Minneapolis','LosAngeles','Denver']\n",
    "city_filterwords = {'Minneapolis': ['Minneapolis', '#Minneapolis','mlps', ['St.', 'Paul']],\n",
    "                    'LosAngeles':['LosAngeles','LA', 'L.A.', '#LA', ['Los', 'Angeles']],\n",
    "                    'Denver': ['Denver', '#Denver']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(city_filterwords['Minneapolis'][0])\n",
    "type(city_filterwords['LosAngeles'][3])\n",
    "idx ={}\n",
    "idx[str('a')] = [True,False,True]\n",
    "idx[str(['a','b'])] = [False,False,True]\n",
    "\n",
    "pd.DataFrame(idx).agg(max, axis=1).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_var_contain_filterwords(df, varname, filterwords):\n",
    "    if type(filterwords) != list: raise ValueError(\"filterwords must be a list\")\n",
    "    idx = {}\n",
    "    for word in filterwords:\n",
    "        if type(word)==str:\n",
    "            idx[str(word)] = df[varname].apply(lambda x: word.lower() in x)\n",
    "        elif type(word)==list:\n",
    "            # assess whether all components of 'word' are jointly present \n",
    "            loc_idx = [df[varname].apply(lambda x: w.lower() in x) for w in word]\n",
    "            idx[str(word)] = pd.DataFrame(loc_idx).agg(min).astype(bool)\n",
    "        else: raise ValueError('each item in filterwords must be str or list')\n",
    "        # assess whether any component of 'filterwords' are present \n",
    "    return pd.DataFrame(idx).agg(max, axis=1).astype(bool)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "43\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "idx1 = mark_var_contain_filterwords(cum_retweet, 'tokens', city_filterwords['Minneapolis'])\n",
    "print(sum(idx1))\n",
    "\n",
    "idx2 = mark_var_contain_filterwords(cum_retweet, 'tokens', city_filterwords['LosAngeles'])\n",
    "print(sum(idx2))\n",
    "\n",
    "idx3 = mark_var_contain_filterwords(cum_retweet, 'tokens', city_filterwords['Denver'])\n",
    "print(sum(idx3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retweet_files_by_city_json(files, cities, city_filterwords, data_path,\n",
    "                               lines=True, float_dtype='float16', verbose=False):\n",
    "    city_df = {}\n",
    "\n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files[0]:\n",
    "            columns = get_columns_json(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            for city in cities:\n",
    "                city_df[city] = []\n",
    "        \n",
    "        df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        df_vars_convert_to_str(df_file, ['RT_id','user_id','created_at','created_at_h'])\n",
    "        convert_floats(df_file, float_dtype)\n",
    "        \n",
    "        for city in cities:\n",
    "            filter_word = city_filterwords[city]    \n",
    "            idx = mark_var_contain_filterwords(df_file, 'tokens', filter_word)\n",
    "            if sum(idx)>0: city_df[city].append(df_file[idx])\n",
    "    \n",
    "    for city in cities:\n",
    "        if len(city_df[city])==0: city_data = df_null\n",
    "        else: city_data = pd.concat(city_df[city], ignore_index=True)\n",
    "        filename = 'data_cumulative/city_date/' + city + '/retweet/2020_all_retweets' + '.json'\n",
    "        city_data.to_json(data_path + filename, \n",
    "                          orient='records', lines=lines)\n",
    "        print('updated: ', filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated:  data_cumulative/city_date/Minneapolis/2020_all_retweets.json\n",
      "updated:  data_cumulative/city_date/LosAngeles/2020_all_retweets.json\n",
      "updated:  data_cumulative/city_date/Denver/2020_all_retweets.json\n"
     ]
    }
   ],
   "source": [
    "retweet_files_by_city_json(files_retweet, cities, city_filterwords, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = 'Minneapolis'\n",
    "filename = 'data_cumulative/city_date/' + city + '/retweet/2020_all_retweets' + '.json'\n",
    "RT_id = pd.read_json(data_path + filename, orient='records', lines=True).RT_id.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_dates(df, varname):\n",
    "    tmp = pd.to_datetime(df[varname]).dt.floor('d')\n",
    "    dates = tmp.unique()\n",
    "    dates_str = [str(date)[:10] for date in dates]\n",
    "    return dates, dates_str\n",
    "\n",
    "def filter_df_by_date(df, varname, date, var_as_string=True):\n",
    "    tmp_df = df\n",
    "    varname_d = varname + '_d'\n",
    "    tmp_df[varname_d] = pd.to_datetime(tmp_df[varname]).dt.floor('d')\n",
    "    filtered_df = tmp_df[tmp_df[varname_d] == pd.to_datetime(date)].drop(columns = [varname_d])\n",
    "    if var_as_string: filtered_df[varname] = filtered_df[varname].astype(str)\n",
    "    return filtered_df\n",
    "\n",
    "def append_to_json(filename, df, lines=True):\n",
    "    df0 = pd.read_json(filename, orient='records', lines=lines)\n",
    "    return df0.append(df)\n",
    "\n",
    "\n",
    "def original_files_by_city_date_json(files, cities, city_filterwords, data_path,\n",
    "                               lines=True, float_dtype='float16', verbose=False):\n",
    "    city_df = {}\n",
    "    city_RT_ids = {}\n",
    "    \n",
    "    for city in cities:\n",
    "        # retrieve relevant RT_id to match \n",
    "        filename = 'data_cumulative/city_date/' + city + '/retweet/2020_all_retweets' + '.json'\n",
    "        RT_id = pd.read_json(data_path + filename, \n",
    "                             orient='records', lines=True).RT_id.astype(str)\n",
    "        city_RT_ids[city] = list(RT_id)\n",
    "    \n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files[0]:\n",
    "            columns = get_columns_json(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            for city in cities:\n",
    "                city_df[city] = []\n",
    "        \n",
    "        df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        df_vars_convert_to_str(df_file, ['id','RT_id','created_at','created_at_h'])\n",
    "        convert_floats(df_file, float_dtype)\n",
    "        \n",
    "        for city in cities:\n",
    "            if verbose: print('processing data for ' + city)  \n",
    "            filter_word = city_filterwords[city]\n",
    "            # idx1: 'tokens' containing filter_word\n",
    "            idx1 = mark_var_contain_filterwords(df_file, 'tokens', filter_word)\n",
    "            # idx2: relevant retweet's that are matched  \n",
    "            idx2 = mark_var_in_valuelist(df_file, 'RT_id', city_RT_ids[city])\n",
    "            # idx: either idx1 or idx2 being True\n",
    "            idx = pd.DataFrame(data={'idx1':idx1, 'idx2': idx2}).agg(max, axis=1)\n",
    "            print(sum(idx1),sum(idx2), sum(idx))\n",
    "            if sum(idx)>0: city_df[city].append(df_file[idx])\n",
    "    \n",
    "    for city in cities:\n",
    "        if len(city_df[city])==0: city_data = df_null\n",
    "        else: city_data = pd.concat(city_df[city], ignore_index=True)\n",
    "        dates, dates_str = get_unique_dates(city_data,'created_at_h')\n",
    "        for date in dates_str:\n",
    "            if verbose: print('processing date of ' + date)  \n",
    "            df_date = filter_df_by_date(city_data, 'created_at_h', date)\n",
    "            filename = 'data_cumulative/city_date/' + city + '/original/records_'+ date + '.json'\n",
    "            new_file = glob.glob(data_path + filename)==[]\n",
    "            if new_file:\n",
    "                df_date.to_json(data_path + filename, \n",
    "                              orient='records', lines=lines)\n",
    "                print('created: ', filename)\n",
    "            else:\n",
    "                df_date = append_to_json(data_path + filename, df_date)\n",
    "                df_date.to_json(data_path + filename, \n",
    "                              orient='records', lines=lines)\n",
    "                print('appended: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/original/created_at_2020-07-09_11:00:00.json\n",
      "processing data for Minneapolis\n",
      "3 11 14\n",
      "processing data for LosAngeles\n",
      "35 0 35\n",
      "processing data for Denver\n",
      "0 0 0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/original/created_at_2020-07-11_09:00:00.json\n",
      "processing data for Minneapolis\n",
      "3 0 3\n",
      "processing data for LosAngeles\n",
      "4 0 4\n",
      "processing data for Denver\n",
      "0 0 0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/original/created_at_2020-07-06_09:00:00.json\n",
      "processing data for Minneapolis\n",
      "7 1 8\n",
      "processing data for LosAngeles\n",
      "192 3 195\n",
      "processing data for Denver\n",
      "1 0 1\n",
      "processing date of 2020-07-09\n",
      "created:  data_cumulative/city_date/Minneapolis/original/records_2020-07-09.json\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/Minneapolis/original/records_2020-07-11.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/Minneapolis/original/records_2020-07-06.json\n",
      "processing date of 2020-07-09\n",
      "created:  data_cumulative/city_date/LosAngeles/original/records_2020-07-09.json\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/LosAngeles/original/records_2020-07-11.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/LosAngeles/original/records_2020-07-06.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/Denver/original/records_2020-07-06.json\n"
     ]
    }
   ],
   "source": [
    "original_files_by_city_date_json(files_original[:3], cities, city_filterwords, data_path, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_words = keep_recent_files(glob.glob(data_path + \"data_cumulative/words/*\"),\n",
    "        base_timestamp = process_datatime_d, days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-09_11:00:00.json',\n",
       " '/Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-11_09:00:00.json',\n",
       " '/Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-06_09:00:00.json']"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_words[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_recent_files(files, base_timestamp, file_type= '.json', days = 14,\n",
    "                      prefix = 'created_at_'):\n",
    "    timestamps = [pd.Timestamp(file.split(prefix,1)[1]\n",
    "                               .replace(file_type,'').replace('_',' ')) for file in files ]\n",
    "    keep_idx1 = [(base_timestamp - timestamp) <= pd.Timedelta(days, unit='d') for timestamp in timestamps]\n",
    "    return(list(itertools.compress(files,keep_idx1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1281271899784228864</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>{'peggy': 1, 'shepard,': 1, 'shed': 1, 'light'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1281271900015071232</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1281271899985793024</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1281271900291776512</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1281271900593938432</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>{'yet': 1, 'countless': 1, 'black': 1, 'baby':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21630</th>\n",
       "      <td>1281285912421261312</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21631</th>\n",
       "      <td>1281285913792913408</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21632</th>\n",
       "      <td>1281285915944640512</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21633</th>\n",
       "      <td>1281285916091461632</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21634</th>\n",
       "      <td>1281285918146641920</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21635 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id         created_at_h  \\\n",
       "0      1281271899784228864  2020-07-09 11:00:00   \n",
       "1      1281271900015071232  2020-07-09 11:00:00   \n",
       "2      1281271899985793024  2020-07-09 11:00:00   \n",
       "3      1281271900291776512  2020-07-09 11:00:00   \n",
       "4      1281271900593938432  2020-07-09 11:00:00   \n",
       "...                    ...                  ...   \n",
       "21630  1281285912421261312  2020-07-09 11:00:00   \n",
       "21631  1281285913792913408  2020-07-09 11:00:00   \n",
       "21632  1281285915944640512  2020-07-09 11:00:00   \n",
       "21633  1281285916091461632  2020-07-09 11:00:00   \n",
       "21634  1281285918146641920  2020-07-09 11:00:00   \n",
       "\n",
       "                                           token_counter  \n",
       "0      {'peggy': 1, 'shepard,': 1, 'shed': 1, 'light'...  \n",
       "1                                                     {}  \n",
       "2                                                     {}  \n",
       "3                                                     {}  \n",
       "4      {'yet': 1, 'countless': 1, 'black': 1, 'baby':...  \n",
       "...                                                  ...  \n",
       "21630                                               None  \n",
       "21631                                               None  \n",
       "21632                                               None  \n",
       "21633                                               None  \n",
       "21634                                               None  \n",
       "\n",
       "[21635 rows x 3 columns]"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2 = pd.read_json(files_words[0], orient='records', lines=True)\n",
    "tmp2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def words_files_by_city_date_json(files_words, cities, data_path,\n",
    "                                  process_datetime, process_days = 14,\n",
    "                                  lines=True, verbose=False):\n",
    "    city_df = {}\n",
    "    city_ids = {}\n",
    "    for city in cities:\n",
    "        files_city_original = keep_recent_files(\n",
    "            glob.glob(data_path + \"data_cumulative/city_date/\" + city  + \"/original/*\"),\n",
    "            prefix = 'records_', base_timestamp = process_datatime, days=7)\n",
    "        tmp_ids = []\n",
    "        for file in files_city_original:\n",
    "            # retrieve relevant id to match\n",
    "            if verbose: print('reading ids from ' + file)\n",
    "            ids = pd.read_json(file, orient='records', lines=True).id.astype(str)\n",
    "            tmp_ids.append(ids)\n",
    "        city_ids[city] = list(pd.concat(tmp_ids, ignore_index=True))\n",
    "    \n",
    "    for file in files_words:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files_words[0]:\n",
    "            columns = get_columns_json(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            for city in cities:\n",
    "                city_df[city] = []\n",
    "        \n",
    "        df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        df_vars_convert_to_str(df_file, ['id','created_at_h'])\n",
    "        \n",
    "        for city in cities:\n",
    "            if verbose: print('processing data for ' + city)  \n",
    "            # idx: relevant original tweet's that are matched  \n",
    "            idx = mark_var_in_valuelist(df_file, 'id', city_ids[city])\n",
    "            print(sum(idx))\n",
    "            if sum(idx)>0: city_df[city].append(df_file[idx])\n",
    "    \n",
    "    for city in cities:\n",
    "        if len(city_df[city])==0: city_data = df_null\n",
    "        else: city_data = pd.concat(city_df[city], ignore_index=True)\n",
    "        dates, dates_str = get_unique_dates(city_data, 'created_at_h')\n",
    "        for date in dates_str:\n",
    "            if verbose: print('processing date of ' + date)  \n",
    "            df_date = filter_df_by_date(city_data, 'created_at_h', date)\n",
    "            filename = 'data_cumulative/city_date/' + city + '/words/records_'+ date + '.json'\n",
    "            new_file = glob.glob(data_path + filename)==[]\n",
    "            if new_file:\n",
    "                df_date.to_json(data_path + filename, \n",
    "                              orient='records', lines=lines)\n",
    "                print('created: ', filename)\n",
    "            else:\n",
    "                df_date = append_to_json(data_path + filename, df_date)\n",
    "                df_date.to_json(data_path + filename, \n",
    "                              orient='records', lines=lines)\n",
    "                print('appended: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Denver/original/records_2020-07-06.json\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-09_11:00:00.json\n",
      "processing data for Minneapolis\n",
      "27\n",
      "processing data for LosAngeles\n",
      "55\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-11_09:00:00.json\n",
      "processing data for Minneapolis\n",
      "4\n",
      "processing data for LosAngeles\n",
      "5\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-06_09:00:00.json\n",
      "processing data for Minneapolis\n",
      "14\n",
      "processing data for LosAngeles\n",
      "394\n",
      "processing data for Denver\n",
      "1\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-12_10:00:00.json\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-11_15:00:00.json\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "processing date of 2020-07-09\n",
      "created:  data_cumulative/city_date/Minneapolis/words/records_2020-07-09.json\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/Minneapolis/words/records_2020-07-11.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/Minneapolis/words/records_2020-07-06.json\n",
      "processing date of 2020-07-09\n",
      "created:  data_cumulative/city_date/LosAngeles/words/records_2020-07-09.json\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/LosAngeles/words/records_2020-07-11.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/LosAngeles/words/records_2020-07-06.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/Denver/words/records_2020-07-06.json\n"
     ]
    }
   ],
   "source": [
    "words_files_by_city_date_json(files_words[:5], cities, data_path,\n",
    "                                  process_datetime, process_days = 14,\n",
    "                                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278538162915037184</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1278538167474442240</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>0.347</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.069</td>\n",
       "      <td>-0.8750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1278538169319936000</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278538170456473600</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1278538183693795328</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214321</th>\n",
       "      <td>1278815756894035968</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-0.7269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214322</th>\n",
       "      <td>1278815757963591680</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214323</th>\n",
       "      <td>1278815761662988288</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214324</th>\n",
       "      <td>1278815761855844352</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214325</th>\n",
       "      <td>1278815762933784576</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.8176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214326 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id         created_at_h    neg    neu    pos  \\\n",
       "0       1278538162915037184  2020-07-01 21:00:00  0.000  0.909  0.091   \n",
       "1       1278538167474442240  2020-07-01 21:00:00  0.347  0.583  0.069   \n",
       "2       1278538169319936000  2020-07-01 21:00:00  0.527  0.473  0.000   \n",
       "3       1278538170456473600  2020-07-01 21:00:00  0.000  0.901  0.099   \n",
       "4       1278538183693795328  2020-07-01 21:00:00  0.000  1.000  0.000   \n",
       "...                     ...                  ...    ...    ...    ...   \n",
       "214321  1278815756894035968  2020-07-02 16:00:00  0.389  0.491  0.121   \n",
       "214322  1278815757963591680  2020-07-02 16:00:00    NaN    NaN    NaN   \n",
       "214323  1278815761662988288  2020-07-02 16:00:00    NaN    NaN    NaN   \n",
       "214324  1278815761855844352  2020-07-02 16:00:00    NaN    NaN    NaN   \n",
       "214325  1278815762933784576  2020-07-02 16:00:00  0.306  0.694  0.000   \n",
       "\n",
       "        compound  \n",
       "0         0.0258  \n",
       "1        -0.8750  \n",
       "2        -0.7003  \n",
       "3         0.0258  \n",
       "4         0.0000  \n",
       "...          ...  \n",
       "214321   -0.7269  \n",
       "214322       NaN  \n",
       "214323       NaN  \n",
       "214324       NaN  \n",
       "214325   -0.8176  \n",
       "\n",
       "[214326 rows x 6 columns]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_sentiments = keep_recent_files(glob.glob(data_path + \"data_cumulative/sentiments/*\"),\n",
    "        base_timestamp = process_datetime,  file_type= '.csv', days=7)\n",
    "\n",
    "tmp2 = pd.read_csv(files_sentiments[0])\n",
    "tmp2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1278538162915037184\n",
       "1         1278538167474442240\n",
       "2         1278538169319936000\n",
       "3         1278538170456473600\n",
       "4         1278538183693795328\n",
       "                 ...         \n",
       "214321    1278815756894035968\n",
       "214322    1278815757963591680\n",
       "214323    1278815761662988288\n",
       "214324    1278815761855844352\n",
       "214325    1278815762933784576\n",
       "Name: id, Length: 214326, dtype: int64"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp2.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def files_id_matched_by_city_date_json(\n",
    "    files, cities, data_path, folder, process_datetime, process_days = 14,\n",
    "    file_type ='.json', float_dtype='float16', lines=True, verbose=False):\n",
    "\n",
    "    '''\n",
    "    Looks for recent files in /city_date/[city]/original/*, extract relevant ids,\n",
    "    generate data matched with those ids by city, and create data files  \n",
    "    '''\n",
    "    if file_type not in ['.json', '.csv'] :\n",
    "        raise ValueError('file_type must be either json or csv')\n",
    "            \n",
    "    city_df = {}\n",
    "    city_ids = {}\n",
    "    for city in cities:\n",
    "        files_city_original = keep_recent_files(\n",
    "            glob.glob(data_path + \"data_cumulative/city_date/\" + city  + \"/original/*\"),\n",
    "            prefix = 'records_', file_type= '.json', \n",
    "            base_timestamp = process_datetime, days=7)\n",
    "        tmp_ids = []\n",
    "        for file in files_city_original:\n",
    "            # retrieve relevant id to match\n",
    "            if verbose: print('reading ids from ' + file)\n",
    "            ids = pd.read_json(file, orient='records', lines=True).id.astype(str)\n",
    "            tmp_ids.append(ids)\n",
    "        city_ids[city] = list(pd.concat(tmp_ids, ignore_index=True))\n",
    "    \n",
    "    for file in files:\n",
    "        if verbose: print('loading ' + file)  \n",
    "        if file==files[0]:\n",
    "            columns = get_columns_json(file) if file_type =='.json' else get_columns_csv(file)\n",
    "            df_null = pd.DataFrame(columns=columns)\n",
    "            for city in cities:\n",
    "                city_df[city] = []\n",
    "        \n",
    "        if file_type =='.json': \n",
    "            df_file = pd.read_json(file, orient='records', lines=lines)\n",
    "        elif file_type =='.csv': \n",
    "            df_file = pd.read_csv(file)\n",
    "\n",
    "        df_vars_convert_to_str(df_file, ['id','created_at_h'])\n",
    "        convert_floats(df_file, float_dtype)\n",
    "\n",
    "        for city in cities:\n",
    "            if verbose: print('processing data for ' + city)  \n",
    "            # idx: relevant original tweet's that are matched  \n",
    "            idx = mark_var_in_valuelist(df_file, 'id', city_ids[city])\n",
    "            print(sum(idx))\n",
    "            if sum(idx)>0: city_df[city].append(df_file[idx])\n",
    "    \n",
    "    for city in cities:\n",
    "        if len(city_df[city])==0: city_data = df_null\n",
    "        else: city_data = pd.concat(city_df[city], ignore_index=True)\n",
    "        dates, dates_str = get_unique_dates(city_data, 'created_at_h')\n",
    "        for date in dates_str:\n",
    "            if verbose: print('processing date of ' + date)  \n",
    "            df_date = filter_df_by_date(city_data, 'created_at_h', date)\n",
    "            filename = 'data_cumulative/city_date/' + city + '/' + folder + '/records_'+ date + file_type\n",
    "            new_file = glob.glob(data_path + filename)==[]\n",
    "            if file_type =='.json': \n",
    "                if not new_file:\n",
    "                    df_date = append_to_json(data_path + filename, df_date)\n",
    "                df_date.to_json(data_path + filename, \n",
    "                              orient='records', lines=lines)\n",
    "            if file_type =='.csv':\n",
    "                mode = 'a' if new_file else 'w'\n",
    "                df_date.to_csv(data_path + filename, index=False, mode=mode)\n",
    "            if new_file: print('created: ', filename)\n",
    "            else: print('appended: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Denver/original/records_2020-07-06.json\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-07_15:17:58.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-12_09:41:01.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-07_15:02:42.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-11_10:19:49.csv\n",
      "processing data for Minneapolis\n",
      "4\n",
      "processing data for LosAngeles\n",
      "5\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-08_13:24:14.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-08_16:25:28.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-11_09:52:39.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-07_17:04:05.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-12_10:23:22.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/sentiments/created_at_2020-07-10_15:15:37.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/Minneapolis/sentiments/records_2020-07-11.csv\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/LosAngeles/sentiments/records_2020-07-11.csv\n"
     ]
    }
   ],
   "source": [
    "files_id_matched_by_city_date_json(\n",
    "    files_sentiments[:10], cities, data_path, 'sentiments', \n",
    "    process_datetime, process_days = 14,\n",
    "    file_type='.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticip</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278538162915037184</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1278538167474442240</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1278538169319936000</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278538170456473600</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1278538183693795328</td>\n",
       "      <td>2020-07-01 21:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214321</th>\n",
       "      <td>1278815756894035968</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214322</th>\n",
       "      <td>1278815757963591680</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214323</th>\n",
       "      <td>1278815761662988288</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214324</th>\n",
       "      <td>1278815761855844352</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214325</th>\n",
       "      <td>1278815762933784576</td>\n",
       "      <td>2020-07-02 16:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214326 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id         created_at_h   fear  anger anticip  trust  \\\n",
       "0       1278538162915037184  2020-07-01 21:00:00  False   True    True   True   \n",
       "1       1278538167474442240  2020-07-01 21:00:00  False  False   False  False   \n",
       "2       1278538169319936000  2020-07-01 21:00:00  False  False    True  False   \n",
       "3       1278538170456473600  2020-07-01 21:00:00  False  False    True   True   \n",
       "4       1278538183693795328  2020-07-01 21:00:00   True   True    True  False   \n",
       "...                     ...                  ...    ...    ...     ...    ...   \n",
       "214321  1278815756894035968  2020-07-02 16:00:00   True   True   False  False   \n",
       "214322  1278815757963591680  2020-07-02 16:00:00    NaN    NaN     NaN    NaN   \n",
       "214323  1278815761662988288  2020-07-02 16:00:00    NaN    NaN     NaN    NaN   \n",
       "214324  1278815761855844352  2020-07-02 16:00:00    NaN    NaN     NaN    NaN   \n",
       "214325  1278815762933784576  2020-07-02 16:00:00  False  False   False  False   \n",
       "\n",
       "       surprise positive negative sadness disgust    joy  \n",
       "0          True     True     True   False    True   True  \n",
       "1         False    False     True   False   False  False  \n",
       "2         False     True     True   False   False  False  \n",
       "3          True     True     True   False   False  False  \n",
       "4          True     True    False   False   False   True  \n",
       "...         ...      ...      ...     ...     ...    ...  \n",
       "214321    False    False     True   False   False  False  \n",
       "214322      NaN      NaN      NaN     NaN     NaN    NaN  \n",
       "214323      NaN      NaN      NaN     NaN     NaN    NaN  \n",
       "214324      NaN      NaN      NaN     NaN     NaN    NaN  \n",
       "214325    False    False     True   False   False  False  \n",
       "\n",
       "[214326 rows x 12 columns]"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_emotions = keep_recent_files(glob.glob(data_path + \"data_cumulative/emotions/*\"),\n",
    "        base_timestamp = process_datetime,  file_type= '.csv', days=7)\n",
    "\n",
    "tmp2 = pd.read_csv(files_emotions[0])\n",
    "tmp2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Denver/original/records_2020-07-06.json\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-07_15:17:58.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3254: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-12_09:41:01.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-07_15:02:42.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-11_10:19:49.csv\n",
      "processing data for Minneapolis\n",
      "4\n",
      "processing data for LosAngeles\n",
      "5\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-08_13:24:14.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-08_16:25:28.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-11_09:52:39.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-07_17:04:05.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-12_10:23:22.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/emotions/created_at_2020-07-10_15:15:37.csv\n",
      "processing data for Minneapolis\n",
      "0\n",
      "processing data for LosAngeles\n",
      "0\n",
      "processing data for Denver\n",
      "0\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/Minneapolis/emotions/records_2020-07-11.csv\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/LosAngeles/emotions/records_2020-07-11.csv\n"
     ]
    }
   ],
   "source": [
    "files_id_matched_by_city_date_json(\n",
    "    files_emotions[:10], cities, data_path, 'emotions', \n",
    "    process_datetime, process_days = 14,\n",
    "    file_type='.csv', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Minneapolis/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-11.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-06.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/LosAngeles/original/records_2020-07-09.json\n",
      "reading ids from /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/city_date/Denver/original/records_2020-07-06.json\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-09_11:00:00.json\n",
      "processing data for Minneapolis\n",
      "27\n",
      "processing data for LosAngeles\n",
      "55\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-11_09:00:00.json\n",
      "processing data for Minneapolis\n",
      "4\n",
      "processing data for LosAngeles\n",
      "5\n",
      "processing data for Denver\n",
      "0\n",
      "loading /Users/kotaminegishi/big_data_training/python/dash_demo1/data_cumulative/words/created_at_2020-07-06_09:00:00.json\n",
      "processing data for Minneapolis\n",
      "14\n",
      "processing data for LosAngeles\n",
      "394\n",
      "processing data for Denver\n",
      "1\n",
      "processing date of 2020-07-09\n",
      "created:  data_cumulative/city_date/Minneapolis/words/records_2020-07-09.json\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/Minneapolis/words/records_2020-07-11.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/Minneapolis/words/records_2020-07-06.json\n",
      "processing date of 2020-07-09\n",
      "created:  data_cumulative/city_date/LosAngeles/words/records_2020-07-09.json\n",
      "processing date of 2020-07-11\n",
      "created:  data_cumulative/city_date/LosAngeles/words/records_2020-07-11.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/LosAngeles/words/records_2020-07-06.json\n",
      "processing date of 2020-07-06\n",
      "created:  data_cumulative/city_date/Denver/words/records_2020-07-06.json\n"
     ]
    }
   ],
   "source": [
    "files_id_matched_by_city_date_json(\n",
    "    files_words[:3], cities, data_path, 'words', \n",
    "    process_datetime, process_days = 14,\n",
    "    file_type='.json', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(data_dest + \"data_cumulative/city_date/Minneapolis/retweet/*\")[:3]\n",
    "cum_data_path = data_dest + \"data_cumulative/city_date/\" + 'Denver'\n",
    "tmp4= keep_recent_files(glob.glob(cum_data_path + \"/sentiments/*\"),\n",
    "                            base_timestamp=process_datatime, prefix='records_',\n",
    "                            file_type = '.csv', days=14) \n",
    "\n",
    "len(tmp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tw_data_files_to_df_csv(files):\n",
    "    '''append and concat data files into a pandas.DataFrame'''\n",
    "    df = []\n",
    "    [ df.append(pd.read_csv(file)) for file in files ]\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def tw_data_files_to_df_json(files, lines=False):\n",
    "    '''append and concat data files into a pandas.DataFrame'''\n",
    "    df = []\n",
    "    [ df.append(pd.read_json(file, orient='records', lines=lines)) for file in files ]\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarizing_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_json(file):\n",
    "    chunk1 = pd.read_json(file, chunksize=1, orient='records', lines=True)\n",
    "    for d in chunk1:\n",
    "        data1 = d.iloc[0]\n",
    "        break\n",
    "    return list(data1.keys())\n",
    "\n",
    "def get_columns_csv(file):\n",
    "    chunk1 = pd.read_csv(file, chunksize=1)\n",
    "    return list(chunk1.read(1).keys())\n",
    "\n",
    "\n",
    "def load_null_df(data_path):\n",
    "    \n",
    "    null_stat_sentiments = pd.DataFrame(columns = get_columns_csv(\n",
    "                     glob(data_path + 'data_cumulative/sentiments/*')[0]))\n",
    "    \n",
    "    null_stat_emotions = pd.DataFrame(columns = get_columns_csv(\n",
    "                     glob(data_path + 'data_cumulative/emotions/*')[0]))\n",
    "    \n",
    "    null_cum_words = pd.DataFrame(columns = get_columns_json(\n",
    "                     glob(data_path + 'data_cumulative/words/*')[0]))\n",
    "    \n",
    "    null_cum_original = pd.DataFrame(columns = get_columns_json(\n",
    "                     glob(data_path + 'data_cumulative/original/*')[0]))\n",
    "    \n",
    "    null_cum_retweet = pd.DataFrame(columns = get_columns_json(\n",
    "                     glob(data_path + 'data_cumulative/retweet/*')[0]))\n",
    "    \n",
    "    return null_stat_sentiments, null_stat_emotions, null_cum_words, null_cum_original, null_cum_retweet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_stat_sentiments, null_stat_emotions, null_cum_words, null_cum_original, null_cum_retweet = load_null_df(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datetime(df, timevar='created_at_h'):\n",
    "    df[timevar] = pd.to_datetime(df[timevar])\n",
    "\n",
    "def fix_token_counter(df):\n",
    "    df.token_counter = df.token_counter.apply(lambda x: Counter(x))  \n",
    "\n",
    "def fix_RT_id(df):\n",
    "    df.RT_id = df.RT_id.astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, created_at_h, neg, neu, pos, compound]\n",
       "Index: []"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get_columns_json(glob.glob(data_path + 'data_cumulative/original/*'))\n",
    "from glob import glob \n",
    "glob(data_path + 'data_cumulative/original/*')[0]\n",
    "glob(data_path + 'data_cumulative/retweet/*')[0]\n",
    "glob(data_path + 'data_cumulative/words/*')[0]\n",
    "\n",
    "pd.DataFrame(columns = get_columns_csv(glob(data_path + 'data_cumulative/sentiments/*')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_city_data(city, data_path, base_timestamp):\n",
    "\n",
    "        # load recent cumulative data\n",
    "        print('  Loading cumulative data: sentiments and emotions...')\n",
    "        cum_data_path = data_path + \"data_cumulative/city_date/\" + city\n",
    "        curr_data_path = data_path + \"data_current/city/\" + city\n",
    "\n",
    "        files_sentiments = keep_recent_files(glob(cum_data_path + \"/sentiments/*\"),\n",
    "                            base_timestamp=base_timestamp, prefix='records_',\n",
    "                            file_type = '.csv', days=14) \n",
    "        if len(files_sentiments)>0: \n",
    "            cum_sentiments = tw_data_files_to_df_csv(files_sentiments)\n",
    "            cum_sentiments = cum_sentiments.drop_duplicates(subset = 'id')\n",
    "            fix_datetime(cum_sentiments)\n",
    "            stat_sentiments = calc_stat_sentiments(cum_sentiments)\n",
    "        else:\n",
    "            stat_sentiments = null_stat_sentiments\n",
    "            \n",
    "        files_emotions = keep_recent_files(glob(cum_data_path + \"/emotions/*\"),\n",
    "                            base_timestamp=base_timestamp, prefix='records_',\n",
    "                            file_type = '.csv', days=14)\n",
    "        if len(files_emotions)>0:\n",
    "            cum_emotions = tw_data_files_to_df_csv(files_emotions)\n",
    "            cum_emotions = cum_emotions.drop_duplicates(subset = 'id')\n",
    "            fix_datetime(cum_emotions)    \n",
    "            stat_emotions = calc_stat_emotions(cum_emotions)\n",
    "        else:\n",
    "            stat_emotions = null_stat_emotions\n",
    "\n",
    "        print('  Loading cumulative data: words...')\n",
    "        files_words = keep_recent_files(glob(cum_data_path + \"/words/*\"),\n",
    "                                        base_timestamp=base_timestamp, prefix='records_',\n",
    "                                        file_type = '.json', days=7) \n",
    "        \n",
    "        if len(files_words)>0:\n",
    "            cum_words = tw_data_files_to_df_json(files_words, lines=True)\n",
    "            fix_datetime(cum_words)\n",
    "            fix_token_counter(cum_words)\n",
    "        else:\n",
    "            cum_words = null_cum_words\n",
    "\n",
    "        print('  Loading cumulative data: original tweets and retweets...')   \n",
    "        # load recent cumulative data     \n",
    "        files_original = keep_recent_files(glob(cum_data_path + \"/original/*\"),\n",
    "            base_timestamp = base_timestamp, days=7,\n",
    "            prefix='records_', file_type = '.json')\n",
    "        if len(files_original)>0:\n",
    "            cum_original = tw_data_files_to_df_json(files_original, lines=True)\n",
    "            fix_datetime(cum_original)        \n",
    "            fix_RT_id(cum_original)\n",
    "        else:\n",
    "            cum_original = null_cum_original\n",
    "\n",
    "        files_retweet = cum_data_path + \"/retweet/2020_all_retweets.json\"\n",
    "        try: \n",
    "            cum_retweet = pd.read_json(files_retweet, orient='records', lines=True)\n",
    "            fix_datetime(cum_retweet)\n",
    "            fix_RT_id(cum_retweet)\n",
    "        except:\n",
    "            cum_retweet = null_cum_retweet\n",
    "\n",
    "\n",
    "        latest_datatime = cum_original.created_at_h.max()\n",
    "        time_now =  min([latest_datatime, base_timestamp])\n",
    "\n",
    "        cum_data = cumulative_data(cum_ori = cum_original, \n",
    "                                  cum_rt = cum_retweet,\n",
    "                                  cum_words = cum_words,\n",
    "                                  now = time_now\n",
    "                                  )\n",
    "\n",
    "        cum_data.add_words_subsets()\n",
    "        cum_data.add_tweet_subsets()\n",
    "        cum_data.add_user_subsets()\n",
    "\n",
    "        return stat_sentiments, stat_emotions, cum_data.stat_words, cum_data.top_tweets, cum_data.top_users\n",
    "        \n",
    "\n",
    "\n",
    "def update_current_data_city(cities, data_path, base_timestamp):\n",
    "    for city in cities:\n",
    "        print('\\nUpdating current city data files for ' + city)\n",
    "\n",
    "        stat_sentiments, stat_emotions, stat_words, top_tweets, top_users = get_city_data(city, data_path, base_timestamp)\n",
    "        \n",
    "        curr_data_path = data_path + \"data_current/city/\" + city\n",
    "\n",
    "        # update current data: recent cumulative files\n",
    "        stat_sentiments.to_csv(curr_data_path + '/stat_sentiments.csv', index = False)\n",
    "        stat_emotions.to_csv(curr_data_path +  '/stat_emotions.csv', index = False)\n",
    "        print('  Updated current data: stat_sentiments and stat_emotions.')\n",
    "\n",
    "        stat_words.to_json(curr_data_path + '/stat_words.json', orient='records', lines=True)\n",
    "        top_users.to_csv(curr_data_path + '/top_users.csv', index=False)\n",
    "        top_tweets.to_csv(curr_data_path + '/top_tweets.csv', index=False)\n",
    "        print('  Updated current city data: stat_words, top_users, and top_tweets.')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updating current city data files for Minneapolis\n",
      "  Loading cumulative data: sentiments and emotions...\n",
      "  Loading cumulative data: words...\n",
      "  Loading cumulative data: original tweets and retweets...\n",
      "IN time_subsets():\n",
      "IN time_subsets():\n",
      "IN add_words_subsets():\n",
      "Empty DataFrame\n",
      "Columns: [id, created_at_h, token_counter, created_at_d]\n",
      "Index: []\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "                                         token_counter  count\n",
      "0                                                   {}      0\n",
      "sum  {'police': 3, 'minneapolis': 2, 'believe': 1, ...      4\n",
      "0                                                   {}      0\n",
      "sum  {'painting': 33, 'hate': 33, 'minneapolis': 25...     45\n",
      "IN add_tweet_subsets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "       subset                RT_id      user_name followers_count  \\\n",
      "0      now_1h                                                       \n",
      "0       today                                                       \n",
      "0   yesterday                                                       \n",
      "0  seven_days  1280644907267502080  Eric6H6rtm6nn             268   \n",
      "1  seven_days  1279928744342433792     herwithluv            3415   \n",
      "\n",
      "                                                text                     t_co  \\\n",
      "0                                                                               \n",
      "0                                                                               \n",
      "0                                                                               \n",
      "0  They still haven't arrested or even looked har...  https://t.co/RQGZ7BvKYI   \n",
      "1  daniel nelson. works at blue plate &amp; co in...  https://t.co/kVlhqeOM2z   \n",
      "\n",
      "                  tags retweet_timespan retweet_total  \n",
      "0                                                      \n",
      "0                                                      \n",
      "0                                                      \n",
      "0                   []               11           332  \n",
      "1  [#BlackLivesMatter]                1            90  \n",
      "IN add_user_subsets():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "       subset              user_id index                RT_id      user_name  \\\n",
      "0      now_1h                                                                  \n",
      "0       today                                                                  \n",
      "0   yesterday                                                                  \n",
      "1  seven_days  1268182793441468416     1  1280644907267502080  Eric6H6rtm6nn   \n",
      "0  seven_days   815977295575912448     0  1279928744342433792     herwithluv   \n",
      "\n",
      "                                    user_description followers_count  \\\n",
      "0                                                                      \n",
      "0                                                                      \n",
      "0                                                                      \n",
      "1                                                  ìÇÄ             268   \n",
      "0  #VMINKOOK: on god if you pay hyung line dust w...            3415   \n",
      "\n",
      "  following_count retweeted  \n",
      "0                            \n",
      "0                            \n",
      "0                            \n",
      "1             174        11  \n",
      "0             281         1  \n",
      "  Updated current data: stat_sentiments and stat_emotions.\n",
      "  Updated current city data: stat_words, top_users, and top_tweets.\n",
      "\n",
      "Updating current city data files for LosAngeles\n",
      "  Loading cumulative data: sentiments and emotions...\n",
      "  Loading cumulative data: words...\n",
      "  Loading cumulative data: original tweets and retweets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN time_subsets():\n",
      "IN time_subsets():\n",
      "IN add_words_subsets():\n",
      "Empty DataFrame\n",
      "Columns: [id, created_at_h, token_counter, created_at_d]\n",
      "Index: []\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "                                         token_counter  count\n",
      "0                                                   {}      0\n",
      "sum  {'racist': 4, 'join': 2, 'us': 2, 'rest': 2, '...      5\n",
      "0                                                   {}      0\n",
      "sum  {'la': 205, 'police': 192, '#policebrutality':...    408\n",
      "IN add_tweet_subsets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "       subset                RT_id user_name followers_count  \\\n",
      "0      now_1h                                                  \n",
      "0       today                                                  \n",
      "0   yesterday                                                  \n",
      "0  seven_days  1279846328621690880     BLMLA          132113   \n",
      "\n",
      "                                                text                     t_co  \\\n",
      "0                                                                               \n",
      "0                                                                               \n",
      "0                                                                               \n",
      "0  Today‚Äôs @latimes thanks to @couragecampaign......  https://t.co/BqxbJntJou   \n",
      "\n",
      "                                                tags retweet_timespan  \\\n",
      "0                                                                       \n",
      "0                                                                       \n",
      "0                                                                       \n",
      "0  [#JackieLaceyMustGo, #ByeJackie2020, #BlackLiv...                3   \n",
      "\n",
      "  retweet_total  \n",
      "0                \n",
      "0                \n",
      "0                \n",
      "0           277  \n",
      "IN add_user_subsets():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "       subset     user_id index                RT_id user_name  \\\n",
      "0      now_1h                                                    \n",
      "0       today                                                    \n",
      "0   yesterday                                                    \n",
      "0  seven_days  2940882906     0  1279846328621690880     BLMLA   \n",
      "\n",
      "                                    user_description followers_count  \\\n",
      "0                                                                      \n",
      "0                                                                      \n",
      "0                                                                      \n",
      "0  Official Twitter for #BlackLivesMatter-Los Ang...          132113   \n",
      "\n",
      "  following_count retweeted  \n",
      "0                            \n",
      "0                            \n",
      "0                            \n",
      "0             436         3  \n",
      "  Updated current data: stat_sentiments and stat_emotions.\n",
      "  Updated current city data: stat_words, top_users, and top_tweets.\n",
      "\n",
      "Updating current city data files for Denver\n",
      "  Loading cumulative data: sentiments and emotions...\n",
      "  Loading cumulative data: words...\n",
      "  Loading cumulative data: original tweets and retweets...\n",
      "IN time_subsets():\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN time_subsets():\n",
      "IN add_words_subsets():\n",
      "Empty DataFrame\n",
      "Columns: [id, created_at_h, token_counter, created_at_d]\n",
      "Index: []\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "IN calc_stat_words():\n",
      "                                         token_counter  count\n",
      "0                                                   {}      0\n",
      "sum  {'look': 2, 'i'm': 1, 'support': 1, 'st.': 1, ...      1\n",
      "0                                                   {}      0\n",
      "sum  {'look': 2, 'i'm': 1, 'support': 1, 'st.': 1, ...      1\n",
      "IN add_tweet_subsets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "IN get_top_tweets():\n",
      "       subset RT_id user_name followers_count text t_co tags retweet_timespan  \\\n",
      "0      now_1h                                                                   \n",
      "0       today                                                                   \n",
      "0   yesterday                                                                   \n",
      "0  seven_days                                                                   \n",
      "\n",
      "  retweet_total  \n",
      "0                \n",
      "0                \n",
      "0                \n",
      "0                \n",
      "IN add_user_subsets():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "IN get_top_users():\n",
      "       subset user_id index RT_id user_name user_description followers_count  \\\n",
      "0      now_1h                                                                  \n",
      "0       today                                                                  \n",
      "0   yesterday                                                                  \n",
      "0  seven_days                                                                  \n",
      "\n",
      "  following_count retweeted  \n",
      "0                            \n",
      "0                            \n",
      "0                            \n",
      "0                            \n",
      "  Updated current data: stat_sentiments and stat_emotions.\n",
      "  Updated current city data: stat_words, top_users, and top_tweets.\n"
     ]
    }
   ],
   "source": [
    "update_current_data_city(cities, data_dest, process_datatime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_json(filename, df, lines=True):\n",
    "    df0 = pd.read_json(filename, orient='records', lines=lines)\n",
    "    return df0.append(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the following was used to retroactively change retweet data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_retweet = pd.read_json(data_dest + \"data_cumulative/retweet/2020_all_retweets.json\",\n",
    "         lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon') \n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('punkt')\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import sys\n",
    "from nrclex import NRCLex\n",
    "from collections import Counter\n",
    "import itertools \n",
    "\n",
    "\n",
    "\n",
    "def tw_data_format_created_at(df):\n",
    "    # assumes variable 'created_at' exists\n",
    "    # uses CST as timestamp\n",
    "    df['created_at'] = pd.to_datetime(df.created_at, unit='s') + pd.DateOffset(hours=-6) # CST\n",
    "    df['created_at_h'] =  df['created_at'].dt.floor(\"h\")\n",
    "    return df\n",
    "\n",
    "def lemmatize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "def remove_noise(tweet_tokens, stop_words = ()):\n",
    "\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    for token, tag in pos_tag(tweet_tokens):\n",
    "        token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token)\n",
    "        token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "\n",
    "        if tag.startswith(\"NN\"):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        token = lemmatizer.lemmatize(token, pos)\n",
    "\n",
    "        if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
    "            cleaned_tokens.append(token.lower())\n",
    "    return cleaned_tokens\n",
    "\n",
    "def clean_tokens(tweet_texts):\n",
    "    mytokens = [tw.split() for tw in tweet_texts]\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stopwords.extend(['#blacklivesmatter', '&amp;', 'please','retweet'])\n",
    "\n",
    "    cleaned_tokens_list = []\n",
    "\n",
    "    for tokens in mytokens:\n",
    "        cleaned_tokens_list.append(remove_noise(tokens, stopwords))\n",
    "    return cleaned_tokens_list\n",
    "\n",
    "\n",
    "def join_token(token):\n",
    "    return \" \".join(str(word) for word in token)\n",
    "\n",
    "\n",
    "\n",
    "def get_df_and_ids(self):\n",
    "    '''used in assign_sentiments() and assign_emotions'''\n",
    "    if (self.type=='original'):\n",
    "        df = self.df[[ len(token) > 0 for token in self.df.tokens] ].reset_index() \n",
    "        ids = df.id\n",
    "    elif (self.type=='retweet'):\n",
    "        df = self.df\n",
    "        ids = df.RT_id\n",
    "    return df, ids\n",
    "\n",
    "\n",
    "class tmp_new_tw_data():\n",
    "    \n",
    "    def __init__(self, df, type='retweet'):\n",
    "        if (type in ['original', 'retweet']):\n",
    "            self.type = type \n",
    "            if self.type=='original': self.id = 'id'\n",
    "            else: self.id = 'RT_id'\n",
    "        \n",
    "        else:\n",
    "            print('value error: type must be either \"original\" or \"retweet\".')\n",
    "            sys.exit()\n",
    "            \n",
    "        df = tw_data_format_created_at(df)\n",
    "        if hasattr(df, 'quoted_text'):\n",
    "            df['tokens'] = clean_tokens(df.text + df.quoted_text)\n",
    "        else:\n",
    "            df['tokens'] = clean_tokens(df.text)\n",
    "        self.df = df\n",
    "\n",
    "            \n",
    "    def assign_sentiments(self):\n",
    "        if self.df is None:\n",
    "            self.df_sentiments = None\n",
    "            return\n",
    "        \n",
    "        df, ids = get_df_and_ids(self)\n",
    "        if len(df)==0: \n",
    "            self.df_sentiments = None\n",
    "            return\n",
    "    \n",
    "        idx_ini = 0\n",
    "        idx_end = len(ids) # 50\n",
    "        try:\n",
    "            tweets = df.tokens[idx_ini:idx_end]\n",
    "            ids = ids[idx_ini:idx_end]\n",
    "            created_at_h = df.created_at_h[idx_ini:idx_end]\n",
    "\n",
    "            sid = SentimentIntensityAnalyzer()\n",
    "            score_1 = sid.polarity_scores(join_token(tweets[0]))\n",
    "\n",
    "            sentiments = []\n",
    "\n",
    "            for i, tweet in enumerate(tweets):\n",
    "                    score = sid.polarity_scores(join_token(tweet))\n",
    "                    sentiments.append([score[key] for key in score])\n",
    "\n",
    "            df_sentiments = pd.DataFrame(data = sentiments, columns=score_1.keys())\n",
    "            df_sentiments = df_sentiments.set_index([pd.Index(ids), pd.Index(created_at_h)])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e.__doc__)\n",
    "            \n",
    "        self.df_sentiments = df_sentiments\n",
    "        \n",
    "        \n",
    "    def assign_emotions(self):\n",
    "        if self.df is None: \n",
    "            self.df_emotions = None\n",
    "            return\n",
    "        df, ids = get_df_and_ids(self)\n",
    "        if len(df)==0: \n",
    "            self.df_emotions = None\n",
    "            return\n",
    "\n",
    "        idx_ini = 0\n",
    "        idx_end = len(ids) # 50\n",
    "        try:\n",
    "            tweets = df.tokens[idx_ini:idx_end]\n",
    "            ids = ids[idx_ini:idx_end]\n",
    "            created_at_h = df.created_at_h[idx_ini:idx_end]\n",
    "\n",
    "            nrc_1 = NRCLex(join_token(tweets[0]))\n",
    "            emo_labels = nrc_1.affect_frequencies.keys()\n",
    "            top_emotions = []\n",
    "\n",
    "            for i, tweet in enumerate(tweets):\n",
    "                nrc = NRCLex(join_token(tweet))\n",
    "                emos = [ i[0] for i in nrc.top_emotions]\n",
    "                top_emotions.append([ i in emos for i in emo_labels])\n",
    "\n",
    "            df_top_emotions = pd.DataFrame(data = top_emotions, \n",
    "             columns = emo_labels)\n",
    "\n",
    "            df_top_emotions = df_top_emotions.set_index([pd.Index(ids), pd.Index(created_at_h)])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e.__doc__)\n",
    "        \n",
    "        self.df_top_emotions = df_top_emotions\n",
    "\n",
    "\n",
    "    def count_words(self):\n",
    "        if self.df is None: \n",
    "            self.df_words = None\n",
    "            return\n",
    "        df = self.df\n",
    "        try:\n",
    "            df['token_counter'] = [ Counter(token) for token in df['tokens'] ]\n",
    "            if self.type == 'original':\n",
    "                df = df.set_index(['id', 'created_at_h'])\n",
    "            elif self.type == 'retweet':\n",
    "                df = df.set_index(['RT_id', 'created_at_h'])\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e.__doc__)\n",
    "        \n",
    "        self.df_words = df[['token_counter']]\n",
    "        self.df = self.df.drop(columns = ['token_counter']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = tmp_new_tw_data(cum_retweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.assign_sentiments()\n",
    "rt.assign_emotions()\n",
    "rt.count_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = 'data_cumulative/retweet/'\n",
    "\n",
    "rt.df_words = rt.df_words.reset_index()\n",
    "rt.df_words.created_at_h = rt.df_words.created_at_h.astype(str)\n",
    "\n",
    "rt.df_sentiments = rt.df_sentiments.reset_index()\n",
    "rt.df_top_emotions = rt.df_top_emotions.reset_index()\n",
    "\n",
    "rt.df_words.to_json(data_dest + file_loc + '2020_all_words.json', orient='records', lines=True)\n",
    "rt.df_sentiments.to_csv(data_dest + file_loc + '2020_all_sentiments.csv', index=False)\n",
    "rt.df_top_emotions.to_csv(data_dest + file_loc + '2020_all_emotions.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_loc = 'data_cumulative/'\n",
    "#tmp2 = pd.read_json()\n",
    "file1 = 'created_at_2020-07-09_11:00:00'\n",
    "\n",
    "ori_df = pd.read_json(data_path + 'data_cumulative/original/' + file1 + '.json', \n",
    "                     orient = 'records', lines=True)\n",
    "ori_df_words = pd.read_json(data_path + 'data_cumulative/words/' + file1 + '.json', \n",
    "                     orient = 'records', lines=True)\n",
    "\n",
    "file2 = 'created_at_2020-07-09_13:55:53'\n",
    "ori_df_sentiments = pd.read_csv(data_path + 'data_cumulative/sentiments/' + file2 + '.csv')\n",
    "ori_df_emotions = pd.read_csv(data_path + 'data_cumulative/emotions/' + file2 + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_datetime(df, timevar='created_at_h'):\n",
    "    df[timevar] = pd.to_datetime(df[timevar])\n",
    "    return df\n",
    "\n",
    "fix_datetime(ori_df_sentiments)\n",
    "fix_datetime(ori_df_emotions)\n",
    "fix_datetime(ori_df_words)\n",
    "fix_token_counter(ori_df_words)\n",
    "fix_datetime(ori_df)\n",
    "fix_RT_id(ori_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278053836381392896</td>\n",
       "      <td>2020-06-29 07:00:00</td>\n",
       "      <td>{'sit': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1274106956609777664</td>\n",
       "      <td>2020-06-18 10:00:00</td>\n",
       "      <td>{'liberate': 1, 'washington': 1, 'state!': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1277830992473047040</td>\n",
       "      <td>2020-06-28 17:00:00</td>\n",
       "      <td>{'breaking:': 1, 'three': 1, 'aurora': 1, 'pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1266604715355312128</td>\n",
       "      <td>2020-05-28 17:00:00</td>\n",
       "      <td>{'oh': 1, 'bitch': 1, 'got': 1, 'amish': 1, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1268070997321814016</td>\n",
       "      <td>2020-06-01 18:00:00</td>\n",
       "      <td>{'end': 1, 'stream!': 1, 'raise': 1, '$14,871....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8316</th>\n",
       "      <td>1265870261699534848</td>\n",
       "      <td>2020-05-26 16:00:00</td>\n",
       "      <td>{'\"feeling': 1, 'uncomfortable\"': 1, 'show': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8317</th>\n",
       "      <td>1267569674012651520</td>\n",
       "      <td>2020-05-31 09:00:00</td>\n",
       "      <td>{'must.': 1, 'sign.': 1, 'petition.': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>1268990386447532032</td>\n",
       "      <td>2020-06-04 07:00:00</td>\n",
       "      <td>{'blm': 1, 'feel': 1, 'free': 1, '#blm': 1, '#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>1267971682440019968</td>\n",
       "      <td>2020-06-01 12:00:00</td>\n",
       "      <td>{'üéâmy': 1, 'shop': 1, 'open!': 1, 'üéâ': 1, 'rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320</th>\n",
       "      <td>1270228596687339520</td>\n",
       "      <td>2020-06-07 17:00:00</td>\n",
       "      <td>{'average': 1, 'life': 1, 'expectancy': 1, 'bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8321 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RT_id        created_at_h  \\\n",
       "0     1278053836381392896 2020-06-29 07:00:00   \n",
       "1     1274106956609777664 2020-06-18 10:00:00   \n",
       "2     1277830992473047040 2020-06-28 17:00:00   \n",
       "3     1266604715355312128 2020-05-28 17:00:00   \n",
       "4     1268070997321814016 2020-06-01 18:00:00   \n",
       "...                   ...                 ...   \n",
       "8316  1265870261699534848 2020-05-26 16:00:00   \n",
       "8317  1267569674012651520 2020-05-31 09:00:00   \n",
       "8318  1268990386447532032 2020-06-04 07:00:00   \n",
       "8319  1267971682440019968 2020-06-01 12:00:00   \n",
       "8320  1270228596687339520 2020-06-07 17:00:00   \n",
       "\n",
       "                                          token_counter  \n",
       "0                                            {'sit': 1}  \n",
       "1     {'liberate': 1, 'washington': 1, 'state!': 1, ...  \n",
       "2     {'breaking:': 1, 'three': 1, 'aurora': 1, 'pol...  \n",
       "3     {'oh': 1, 'bitch': 1, 'got': 1, 'amish': 1, 'c...  \n",
       "4     {'end': 1, 'stream!': 1, 'raise': 1, '$14,871....  \n",
       "...                                                 ...  \n",
       "8316  {'\"feeling': 1, 'uncomfortable\"': 1, 'show': 1...  \n",
       "8317           {'must.': 1, 'sign.': 1, 'petition.': 1}  \n",
       "8318  {'blm': 1, 'feel': 1, 'free': 1, '#blm': 1, '#...  \n",
       "8319  {'üéâmy': 1, 'shop': 1, 'open!': 1, 'üéâ': 1, 'rem...  \n",
       "8320  {'average': 1, 'life': 1, 'expectancy': 1, 'bl...  \n",
       "\n",
       "[8321 rows x 3 columns]"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows = 21635 + 9658 = 31293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref_words = rt.df_words\n",
    "fix_RT_id(ref_words)\n",
    "fix_datetime(ref_words)\n",
    "fix_token_counter(ref_words)\n",
    "\n",
    "\n",
    "def merge_datasets(or_df, or_data, ref_data):\n",
    "    if or_data is None: return()\n",
    "    \n",
    "    col_data = [*or_data.columns]\n",
    "    \n",
    "    ref_data['RT_id'] = ref_data['RT_id'].astype(str) \n",
    "    \n",
    "    or_non_empty = or_df[or_df.RT_id != '']\n",
    "    \n",
    "    if len(or_non_empty)>0:\n",
    "        retweeted_data = (or_non_empty[['id','RT_id','created_at_h']]\n",
    "             .join(ref_data.set_index('RT_id'), \n",
    "                   on='RT_id', rsuffix='_rt')\n",
    "            )\n",
    "\n",
    "        df_merged = (\n",
    "            or_data.reset_index()[['id','created_at_h', *col_data]] \n",
    "            .append(retweeted_data[['id','created_at_h', *col_data]])\n",
    "            )\n",
    "        \n",
    "        print('Num rows = {} + {} = {}'\n",
    "          .format(len(or_data), len(retweeted_data), len(df_merged)))\n",
    "        return df_merged\n",
    "   \n",
    "    else: \n",
    "        print('Num rows = {}'.format(len(or_data)))\n",
    "        return or_data.reset_index()[['id','created_at_h', *col_data]] \n",
    "\n",
    "\n",
    "new_words = merge_datasets(or_df = ori_df, \n",
    "                           or_data = ori_df_words, \n",
    "                           ref_data = ref_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278053836381392896</td>\n",
       "      <td>2020-06-29 07:00:00</td>\n",
       "      <td>{'sit': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1274106956609777664</td>\n",
       "      <td>2020-06-18 10:00:00</td>\n",
       "      <td>{'liberate': 1, 'washington': 1, 'state!': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1277830992473047040</td>\n",
       "      <td>2020-06-28 17:00:00</td>\n",
       "      <td>{'breaking:': 1, 'three': 1, 'aurora': 1, 'pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1266604715355312128</td>\n",
       "      <td>2020-05-28 17:00:00</td>\n",
       "      <td>{'oh': 1, 'bitch': 1, 'got': 1, 'amish': 1, 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1268070997321814016</td>\n",
       "      <td>2020-06-01 18:00:00</td>\n",
       "      <td>{'end': 1, 'stream!': 1, 'raise': 1, '$14,871....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RT_id        created_at_h  \\\n",
       "0  1278053836381392896 2020-06-29 07:00:00   \n",
       "1  1274106956609777664 2020-06-18 10:00:00   \n",
       "2  1277830992473047040 2020-06-28 17:00:00   \n",
       "3  1266604715355312128 2020-05-28 17:00:00   \n",
       "4  1268070997321814016 2020-06-01 18:00:00   \n",
       "\n",
       "                                       token_counter  \n",
       "0                                         {'sit': 1}  \n",
       "1  {'liberate': 1, 'washington': 1, 'state!': 1, ...  \n",
       "2  {'breaking:': 1, 'three': 1, 'aurora': 1, 'pol...  \n",
       "3  {'oh': 1, 'bitch': 1, 'got': 1, 'amish': 1, 'c...  \n",
       "4  {'end': 1, 'stream!': 1, 'raise': 1, '$14,871....  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_words.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1278053836381392896</th>\n",
       "      <th>2020-06-29 07:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274106956609777664</th>\n",
       "      <th>2020-06-18 10:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.4738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277830992473047040</th>\n",
       "      <th>2020-06-28 17:00:00</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266604715355312128</th>\n",
       "      <th>2020-05-28 17:00:00</th>\n",
       "      <td>0.487</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268070997321814016</th>\n",
       "      <th>2020-06-01 18:00:00</th>\n",
       "      <td>0.232</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.186</td>\n",
       "      <td>-0.1756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265870261699534848</th>\n",
       "      <th>2020-05-26 16:00:00</th>\n",
       "      <td>0.221</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.173</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267569674012651520</th>\n",
       "      <th>2020-05-31 09:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268990386447532032</th>\n",
       "      <th>2020-06-04 07:00:00</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.5106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267971682440019968</th>\n",
       "      <th>2020-06-01 12:00:00</th>\n",
       "      <td>0.154</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.3147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270228596687339520</th>\n",
       "      <th>2020-06-07 17:00:00</th>\n",
       "      <td>0.284</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.119</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8321 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           neg    neu    pos  compound\n",
       "RT_id               created_at_h                                      \n",
       "1278053836381392896 2020-06-29 07:00:00  0.000  1.000  0.000    0.0000\n",
       "1274106956609777664 2020-06-18 10:00:00  0.000  0.860  0.140    0.4738\n",
       "1277830992473047040 2020-06-28 17:00:00  0.079  0.921  0.000   -0.0516\n",
       "1266604715355312128 2020-05-28 17:00:00  0.487  0.513  0.000   -0.5859\n",
       "1268070997321814016 2020-06-01 18:00:00  0.232  0.582  0.186   -0.1756\n",
       "...                                        ...    ...    ...       ...\n",
       "1265870261699534848 2020-05-26 16:00:00  0.221  0.606  0.173   -0.2732\n",
       "1267569674012651520 2020-05-31 09:00:00  0.000  1.000  0.000    0.0000\n",
       "1268990386447532032 2020-06-04 07:00:00  0.000  0.548  0.452    0.5106\n",
       "1267971682440019968 2020-06-01 12:00:00  0.154  0.614  0.232    0.3147\n",
       "1270228596687339520 2020-06-07 17:00:00  0.284  0.596  0.119   -0.5574\n",
       "\n",
       "[8321 rows x 4 columns]"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows = 4247 + 9658 = 13905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1280987491906932736</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987491906932736</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280987496403341312</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987496403341312</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.6458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1280987497871421440</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987497871421440</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.6369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280987504821272576</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987504821272576</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.5707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280987507480551424</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987507480551424</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>1281285912421261312</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285912421261312</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>1281285913792913408</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285913792913408</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>1281285915944640512</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285915944640512</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>1281285916091461632</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285916091461632</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>1281285918146641920</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285918146641920</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13905 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id        created_at_h                   id  \\\n",
       "0      1280987491906932736 2020-07-08 16:00:00  1280987491906932736   \n",
       "1      1280987496403341312 2020-07-08 16:00:00  1280987496403341312   \n",
       "2      1280987497871421440 2020-07-08 16:00:00  1280987497871421440   \n",
       "3      1280987504821272576 2020-07-08 16:00:00  1280987504821272576   \n",
       "4      1280987507480551424 2020-07-08 16:00:00  1280987507480551424   \n",
       "...                    ...                 ...                  ...   \n",
       "11972  1281285912421261312 2020-07-09 11:00:00  1281285912421261312   \n",
       "11973  1281285913792913408 2020-07-09 11:00:00  1281285913792913408   \n",
       "11974  1281285915944640512 2020-07-09 11:00:00  1281285915944640512   \n",
       "11975  1281285916091461632 2020-07-09 11:00:00  1281285916091461632   \n",
       "11976  1281285918146641920 2020-07-09 11:00:00  1281285918146641920   \n",
       "\n",
       "             created_at_h    neg    neu    pos  compound  \n",
       "0     2020-07-08 16:00:00  0.072  0.833  0.094    0.1531  \n",
       "1     2020-07-08 16:00:00  0.000  0.778  0.222    0.6458  \n",
       "2     2020-07-08 16:00:00  0.000  0.488  0.512    0.6369  \n",
       "3     2020-07-08 16:00:00  0.130  0.582  0.288    0.5707  \n",
       "4     2020-07-08 16:00:00  0.000  0.748  0.252    0.4660  \n",
       "...                   ...    ...    ...    ...       ...  \n",
       "11972 2020-07-09 11:00:00    NaN    NaN    NaN       NaN  \n",
       "11973 2020-07-09 11:00:00    NaN    NaN    NaN       NaN  \n",
       "11974 2020-07-09 11:00:00    NaN    NaN    NaN       NaN  \n",
       "11975 2020-07-09 11:00:00    NaN    NaN    NaN       NaN  \n",
       "11976 2020-07-09 11:00:00    NaN    NaN    NaN       NaN  \n",
       "\n",
       "[13905 rows x 8 columns]"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_sentiments = rt.df_sentiments\n",
    "\n",
    "new_sentiments = merge_datasets(or_df = ori_df, \n",
    "                           or_data = ori_df_sentiments, \n",
    "                           ref_data = ref_sentiments)\n",
    "\n",
    "new_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows = 4247 + 9658 = 13905\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticip</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1280987491906932736</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987491906932736</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280987496403341312</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987496403341312</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1280987497871421440</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987497871421440</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1280987504821272576</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987504821272576</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280987507480551424</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>1280987507480551424</td>\n",
       "      <td>2020-07-08 16:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11972</th>\n",
       "      <td>1281285912421261312</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285912421261312</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>1281285913792913408</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285913792913408</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11974</th>\n",
       "      <td>1281285915944640512</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285915944640512</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>1281285916091461632</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285916091461632</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>1281285918146641920</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>1281285918146641920</td>\n",
       "      <td>2020-07-09 11:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13905 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id        created_at_h                   id  \\\n",
       "0      1280987491906932736 2020-07-08 16:00:00  1280987491906932736   \n",
       "1      1280987496403341312 2020-07-08 16:00:00  1280987496403341312   \n",
       "2      1280987497871421440 2020-07-08 16:00:00  1280987497871421440   \n",
       "3      1280987504821272576 2020-07-08 16:00:00  1280987504821272576   \n",
       "4      1280987507480551424 2020-07-08 16:00:00  1280987507480551424   \n",
       "...                    ...                 ...                  ...   \n",
       "11972  1281285912421261312 2020-07-09 11:00:00  1281285912421261312   \n",
       "11973  1281285913792913408 2020-07-09 11:00:00  1281285913792913408   \n",
       "11974  1281285915944640512 2020-07-09 11:00:00  1281285915944640512   \n",
       "11975  1281285916091461632 2020-07-09 11:00:00  1281285916091461632   \n",
       "11976  1281285918146641920 2020-07-09 11:00:00  1281285918146641920   \n",
       "\n",
       "             created_at_h   fear  anger anticip  trust surprise positive  \\\n",
       "0     2020-07-08 16:00:00  False  False   False  False    False     True   \n",
       "1     2020-07-08 16:00:00  False  False   False   True    False    False   \n",
       "2     2020-07-08 16:00:00   True  False    True  False     True     True   \n",
       "3     2020-07-08 16:00:00  False  False   False   True    False    False   \n",
       "4     2020-07-08 16:00:00  False  False   False  False    False     True   \n",
       "...                   ...    ...    ...     ...    ...      ...      ...   \n",
       "11972 2020-07-09 11:00:00    NaN    NaN     NaN    NaN      NaN      NaN   \n",
       "11973 2020-07-09 11:00:00    NaN    NaN     NaN    NaN      NaN      NaN   \n",
       "11974 2020-07-09 11:00:00    NaN    NaN     NaN    NaN      NaN      NaN   \n",
       "11975 2020-07-09 11:00:00    NaN    NaN     NaN    NaN      NaN      NaN   \n",
       "11976 2020-07-09 11:00:00    NaN    NaN     NaN    NaN      NaN      NaN   \n",
       "\n",
       "      negative sadness disgust    joy  \n",
       "0        False   False   False  False  \n",
       "1        False   False   False  False  \n",
       "2         True    True    True   True  \n",
       "3        False   False   False  False  \n",
       "4        False   False   False  False  \n",
       "...        ...     ...     ...    ...  \n",
       "11972      NaN     NaN     NaN    NaN  \n",
       "11973      NaN     NaN     NaN    NaN  \n",
       "11974      NaN     NaN     NaN    NaN  \n",
       "11975      NaN     NaN     NaN    NaN  \n",
       "11976      NaN     NaN     NaN    NaN  \n",
       "\n",
       "[13905 rows x 14 columns]"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_emotions = rt.df_top_emotions\n",
    "\n",
    "new_emotions = merge_datasets(or_df = ori_df, \n",
    "                           or_data = ori_df_emotions, \n",
    "                           ref_data = ref_emotions)\n",
    "\n",
    "new_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
