{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('python')\n",
    "\n",
    "from localDataAccess import *\n",
    "from datedFiles import *\n",
    "from dataLoaderMethods import *\n",
    "from dataLoader import DataLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'python/tests/unit/'\n",
    "\n",
    "class TestDataLoader(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        files_original = glob(f'{path}fixtures/lambda_func/original/*')\n",
    "        files_wordindex = glob(f'{path}fixtures/lambda_func/wordindex/*')\n",
    "        localdata = LocalDataAccess(f'{path}fixtures/lambda_func/original')\n",
    "        cls.data1 =  pd.read_json(files_original[0], orient='records', lines=True)\n",
    "        cls.dateddatafiles = DatedDataFiles(files_original, id_varname = 'id', date_prefix='records_')\n",
    "        base_timestamp = pd.Timestamp('2020-08-25')\n",
    "        cls.datedfilenamefilter = DatedFilenameFilter(base_timestamp, days=2, no_newer=True)\n",
    "        cls.datedwordindexfilter = DatedWordindexFilter(files_wordindex, 'protest')\n",
    "        cls.dataloader = DataLoader(localdata)\n",
    "        cls.df = cls.dataloader.load(cls.dateddatafiles, cls.datedfilenamefilter, cls.datedwordindexfilter,\n",
    "            orient='records', lines=True, float_dtype='float64')\n",
    "\n",
    "    def test_DataLoader_dtypes(self):\n",
    "        dtypes = self.data1.dtypes\n",
    "        self.assertTrue(\n",
    "            all([self.df.dtypes[var] == dtypes[var] for var in self.data1.columns]),\n",
    "            'data types should be:' + str(dtypes))\n",
    "\n",
    "    def test_DataLoader_len(self):\n",
    "        self.assertEqual(len(self.df), 94220, 'len() should be' + str(94220))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = TestDataLoader()\n",
    "test1.setUpClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.test_DataLoader_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python/tests/unit/fixtures/lambda_func/original/records_2020-08-23.json',\n",
       " 'python/tests/unit/fixtures/lambda_func/original/records_2020-08-24.json',\n",
       " 'python/tests/unit/fixtures/lambda_func/original/records_2020-08-25.json']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.dateddatafiles.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1.test_DataLoader_len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140078"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataLoaderMethods(unittest.TestCase):\n",
    "    \n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        files_original = glob(f'{path}fixtures/lambda_func/original/*')\n",
    "        files_wordindex = glob(f'{path}fixtures/lambda_func/wordindex/*')\n",
    "        cls.localdata = LocalDataAccess('python/tests/unit/fixtures/lambda_func/original')\n",
    "        cls.data1 =  pd.read_json(files_original[0], orient='records', lines=True)\n",
    "        cls.dateddatafiles = DatedDataFiles(files_original, id_varname = 'id', date_prefix='records_')\n",
    "        cls.datedwordindexfilter = DatedWordindexFilter(files_wordindex, 'protest')\n",
    "        cls.dateddatafiles.apply_id_filter(cls.datedwordindexfilter)\n",
    "        cls.dataloaderjson = DataLoaderJson(orient='records', lines=True, float_dtype='float64')\n",
    "        cls.dataloaderjson.load_data(cls.dateddatafiles, cls.localdata)\n",
    "        cls.dataloadercsv = DataLoaderCSV(float_dtype='float64')\n",
    "\n",
    "        files_sentiments = glob(f'{path}fixtures/lambda_func/sentiments/*')\n",
    "        cls.localdata2 = LocalDataAccess('python/tests/unit/fixtures/lambda_func/sentiments')\n",
    "        cls.data2 =  pd.read_csv(files_sentiments[0])\n",
    "        cls.dateddatafiles2 = DatedDataFiles(files_sentiments, id_varname = 'id', date_prefix='records_')\n",
    "        cls.dateddatafiles2.apply_id_filter(cls.datedwordindexfilter)\n",
    "        cls.dataloadercsv.load_data(cls.dateddatafiles2, cls.localdata2)\n",
    "\n",
    "    def test_DataLoaderJson_dtypes(self):\n",
    "        dtypes = self.data1.dtypes\n",
    "        self.assertTrue(\n",
    "            all([self.dataloaderjson.df.dtypes[var] == dtypes[var] for var in self.data1.columns]),\n",
    "            'data types should be:' + str(dtypes))\n",
    "\n",
    "    def test_DataLoaderJson_len(self):\n",
    "        self.assertEqual(len(self.dataloaderjson.df), 210122, 'len() should be' + str(210122))\n",
    "\n",
    "\n",
    "    def test_DataLoaderCSV_dtypes(self):\n",
    "        dtypes = self.data2.dtypes\n",
    "        self.assertTrue(\n",
    "            all([self.dataloadercsv.df.dtypes[var] == dtypes[var] for var in self.data2.columns]),\n",
    "            'data types should be:' + str(dtypes))\n",
    "\n",
    "    def test_DataLoaderCSV_len(self):\n",
    "        self.assertEqual(len(self.dataloadercsv.df), 309546, 'len() should be' + str(309546))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=TestDataLoaderMethods()\n",
    "test2.setUpClass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.test_DataLoaderCSV_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "created_at_h     object\n",
       "neg             float64\n",
       "neu             float64\n",
       "pos             float64\n",
       "compound        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.data2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "created_at_h     object\n",
       "neg             float32\n",
       "neu             float32\n",
       "pos             float32\n",
       "compound        float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.dataloadercsv.df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utilities import *\n",
    "from tweetRetweetData import *\n",
    "\n",
    "path_root = 'python/tests/unit/'\n",
    "\n",
    "\n",
    "class TestTweetRetweetStats(unittest.TestCase):\n",
    "    \n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        print('setting up TestTweetRetweetStats')\n",
    "        path = f'{path_root}fixtures/lambda_func/'\n",
    "        cls.path = path\n",
    "        df_sentiments1 = pd.read_csv(glob(path + 'sentiments/*')[0])\n",
    "        df_emotions1 = pd.read_csv(glob(path + 'emotions/*')[0])\n",
    "        df_original1 = pd.read_json(glob(path + 'original/*')[0], orient='records', lines=True)\n",
    "        df_retweet1 = pd.read_json(glob(path + 'retweet/*')[0], orient='records', lines=True)\n",
    "        df_words1 = pd.read_json(glob(path + 'words/*')[0], orient='records', lines=True)\n",
    "        base_timestamp = pd.Timestamp('2020-08-24-22')\n",
    "        cls.stat_sentiments1 = calc_stat_sentiments(df_sentiments1)\n",
    "        cls.stat_emotions1 = calc_stat_emotions(df_emotions1)\n",
    "        tweet_retweet_data = TweetRetweetData(df_original1, df_retweet1, df_words1, now=base_timestamp)\n",
    "        cls.stat_words1 = tweet_retweet_data.stat_words\n",
    "        cls.top_tweets1 = tweet_retweet_data.top_tweets\n",
    "        cls.top_users1 = tweet_retweet_data.top_users\n",
    "\n",
    "    def test_stat_sentiments(self):\n",
    "        expected = pd.read_csv(self.path + 'validation_objects/' + 'stat_sentiments1.csv')\n",
    "        assert_frame_equal(self.stat_sentiments1, expected)\n",
    "\n",
    "    def test_stat_sentiments(self):\n",
    "        expected = pd.read_csv(self.path + 'validation_objects/' + 'stat_emotions1.csv')\n",
    "        assert_frame_equal(self.stat_emotions1, expected)\n",
    "\n",
    "    def test_stat_words(self):\n",
    "        expected = pd.read_json(self.path + 'validation_objects/' + 'stat_words1.json', orient='records',lines=True)\n",
    "        self.assertTrue(\n",
    "            all(list(self.stat_words1.columns == expected.columns) + \\\n",
    "                [len(self.stat_words1) == len(expected)]), 'should be' + str(len(expected)))\n",
    "\n",
    "    def test_top_tweets(self):\n",
    "        expected = pd.read_json(self.path + 'validation_objects/' + 'top_tweets1.json', orient='records',lines=True)\n",
    "        expected['RT_id'] = expected['RT_id'].astype(str)\n",
    "        self.top_tweets1['followers_count'] = self.top_tweets1['followers_count'].astype(int)\n",
    "        self.top_tweets1['retweet_timespan'] = self.top_tweets1['retweet_timespan'].astype(int)\n",
    "        self.top_tweets1['retweet_total'] = self.top_tweets1['retweet_total'].astype(int)\n",
    "        assert_frame_equal(self.top_tweets1, expected)\n",
    "\n",
    "    def test_top_users(self):\n",
    "        expected = pd.read_json(self.path + 'validation_objects/' + 'top_users1.json', orient='records',lines=True)\n",
    "        expected['user_id'] = expected['user_id'].astype(str)\n",
    "        expected['RT_id'] = expected['RT_id'].astype(str)\n",
    "        self.top_users1['followers_count'] = self.top_users1['followers_count'].astype(int)\n",
    "        self.top_users1['following_count'] = self.top_users1['following_count'].astype(int)\n",
    "        self.top_users1['retweeted'] = self.top_users1['retweeted'].astype(int)\n",
    "        assert_frame_equal(self.top_users1, expected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up TestTweetRetweetStats\n"
     ]
    }
   ],
   "source": [
    "test3 = TestTweetRetweetStats()\n",
    "test3.setUpClass()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3.test_stat_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_counter    {'black': 1840, 'say': 1851, 'man': 1641, 'bre...\n",
       "count                                                        10000\n",
       "Name: today, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.stat_words1.set_index('subset').loc['today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = pd.read_json(test3.path + 'validation_objects/' + 'stat_words1.json', orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_counter    {'say': 1937, 'car': 1660, 'get': 1609, 'break...\n",
       "count                                                        10000\n",
       "Name: today, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected.set_index('subset').loc['today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_counter    {'black': 1840, 'say': 1851, 'man': 1641, 'bre...\n",
       "count                                                        10000\n",
       "Name: today, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3.stat_words1.set_index('subset').loc['today']\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_counter    {'say': 1937, 'car': 1660, 'get': 1609, 'break...\n",
       "count                                                        10000\n",
       "Name: today, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected.set_index('subset').loc['today']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
