{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-09-21 15:56:51'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(time_now_pandas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python/tests/unit/fixtures/BLM_tweet_retweet_2020',\n",
       " 'python/tests/unit/fixtures/BLM_tweet_original_2020',\n",
       " 'python/tests/unit/fixtures/lambda_func',\n",
       " 'python/tests/unit/fixtures/data_filenames:',\n",
       " 'python/tests/unit/fixtures/data_processing_log']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob('python/tests/unit/fixtures/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class FilenameGatherer:\n",
    "    def __init__(self, new_file_location, new_file_prefix, \n",
    "                 existing_file_location, existing_filenames_file, \n",
    "                 varname='name'):\n",
    "        self.new_file_location = path_ends_with_slash(new_file_location)\n",
    "        self.new_file_prefix = new_file_prefix\n",
    "        self.existing_file_location = path_ends_with_slash(existing_file_location)\n",
    "        self.existing_filenames_file = existing_filenames_file\n",
    "        self.varname=varname\n",
    "\n",
    "    def read_all_filenames_glob(self):\n",
    "        self.all_filenames = glob(self.new_file_location + self.new_file_prefix)\n",
    "    \n",
    "    def register_filename_reader(self, filename_reader):\n",
    "        self.filename_reader = filename_reader\n",
    "\n",
    "    def read_existing_filenames(self):\n",
    "        if not hasattr(self, 'filename_reader'): raise ValueError('Please register filename reader.')\n",
    "        self.existing_filenames = self.filename_reader(self)\n",
    "\n",
    "    def get_new_filenames(self):\n",
    "        self.new_filenames = [file for file in self.all_filenames \n",
    "                              if file.split(self.new_file_location)[1] not in self.existing_filenames]\n",
    "\n",
    "    def get_new_filenames_without_loc(self):\n",
    "        self.new_filenames_without_loc = [file.split(self.new_file_location)[1] for file in self.new_filenames] \n",
    "\n",
    "    def gather_filenames(self):\n",
    "        self.read_all_filenames_glob()\n",
    "        self.read_existing_filenames()\n",
    "        self.get_new_filenames()\n",
    "        self.get_new_filenames_without_loc()\n",
    "\n",
    "\n",
    "def read_existing_filenames_csv(FilenameGatherer):\n",
    "    return list(pd.read_csv(FilenameGatherer.existing_file_location + \n",
    "            FilenameGatherer.existing_filenames_file)[FilenameGatherer.varname])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-59-32-a87bf603-d4d9-4315-b39c-3b9d1299c933\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-34-25-16f86d7c-2aa1-48e1-95ea-6d18e5e0c923\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-04-16-0dd357ff-17b6-4a6d-9571-dfb448b6f16e\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-19-21-9ef8ea83-4b1f-42d9-97aa-d6da6aace8c2\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-44-27-ec48a273-4b33-4553-abe8-1e31f806cc32\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-54-31-19d40465-fb9a-40ea-b947-bec0a87b04d1\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-29-23-8996e450-61f4-462b-bf03-758958814624\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-24-22-36c9cda4-1104-40b9-b661-df8eacb1834d\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-49-27-cf1951bb-809d-498d-98b8-4878ec9e69f9\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-14-19-44186211-5109-4b4c-bd65-8c86d29aed4d\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-39-26-9d0fe52e-8b78-4c63-850b-b9e09a6eb879\n",
      "BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-09-17-cd1a59aa-6249-4990-9673-b4787c85aaa8\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-49-12-768cbda2-1131-40c0-b878-54c5ed7bf72b\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-13-59-446c29a7-9f70-4f81-a470-23c520486cc3\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-54-14-6f18c336-0f51-41d8-abdf-ba2376503c98\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-59-14-be72dc45-9208-4099-b183-8d4e7207df47\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-03-56-329c4689-3387-4554-bed4-1adb3bad9ce1\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-19-02-d1c2d2ce-0e49-4d67-a0f6-9ddab2c9c4cc\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-24-04-33e5b4d3-cd4c-4859-b579-1ebf10bb5124\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-08-58-06ff6b4d-9f69-4e50-a272-69ca90bf6754\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-44-11-30d5ca9e-6869-4635-97e8-7c2651d154cd\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-29-05-7b97d696-d7f1-4785-a269-f96bc20db7b3\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-34-06-a422307c-6246-41c5-8f8b-a86c151187ad\n",
      "BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-39-07-f8c5e37c-1ebc-4186-a334-4b2942d80d58\n",
      "BLM_tweet_original_2020/07/09/01/BLM_tweet_original_delivery-1-2020-07-09-01-53-55-dd471521-1fd7-4edb-92b7-5b713d8f9ea7\n",
      "BLM_tweet_original_2020/07/09/01/BLM_tweet_original_delivery-1-2020-07-09-01-58-54-89732852-7988-4be4-bf6f-416c8f8239f4\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-17-49-7c315c6f-ea55-4e86-b0e1-7abac94a4c6c\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-23-09-ba4e1b31-5575-46a9-bd08-0b2a32405477\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-33-46-9cc84802-3a1a-4fde-be7b-9de1db4382db\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-10-40-c8533a11-7d8c-44dc-9978-487f0486e5d5\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-49-44-69100059-1935-418c-8267-b2ae45a53eda\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-28-19-1a065b56-7a52-42ca-b3ea-b1a40b504761\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-55-12-d3da10f7-4140-485e-a0af-66826861d81a\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-44-38-8c55af62-8ffe-47bf-b070-e298ca893c3d\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-05-15-0f1d31b4-a578-4298-9132-31095e26c4f8\n",
      "BLM_tweet_retweet_2020/07/09/00/BLM_tweet_retweet_delivery-1-2020-07-09-00-39-00-f276f038-d6a1-4ccb-9bb2-0d5865e55c6a\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-39-38-71c11af2-9d34-4ce0-acb4-85e7e051f5cb\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-34-19-79fd1309-481a-462b-84f0-49936088260f\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-06-05-9c061182-7083-4fac-a4e5-35285b4217f0\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-00-22-a5731789-9989-45c1-903f-ec344af58447\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-22-01-a2d8e79a-d869-4544-9b0b-e37554d2ed53\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-45-01-0f0c63ce-df2b-49a6-9d06-d7bfab17437b\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-50-57-697cf6da-3958-4bab-817f-75cc00d172f0\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-16-56-46d3144e-dd98-49c9-9554-30fdaf966c58\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-11-33-551bfadc-1117-4cc2-b466-74e341e211dc\n",
      "BLM_tweet_retweet_2020/07/09/01/BLM_tweet_retweet_delivery-1-2020-07-09-01-27-15-cfb7dc95-7c44-414d-920f-0a3564aa950d\n"
     ]
    }
   ],
   "source": [
    "# data_source = \"/Users/kotaminegishi/big_data_training/Python/dash_BLM/\"\n",
    "# data_dest = \"/Users/kotaminegishi/big_data_training/Python/dash_BLM/\"\n",
    "data_source = 'python/tests/unit/fixtures/'\n",
    "data_dest = 'python/tests/unit/fixtures/'\n",
    "\n",
    "current_time = time_now_pandas()\n",
    "# impute time during code dev\n",
    "current_time = pd.to_datetime('2020-07-09 23:59')\n",
    "current_time_str = str(current_time)\n",
    "\n",
    "append_to_file(data_dest + 'data_processing_log/processing_begin.csv',\n",
    "               '\\n'+current_time_str)\n",
    "\n",
    "# tweet data files: original \n",
    "files_original = FilenameGatherer(new_file_location = data_source, \n",
    "                                  new_file_prefix = \"BLM_tweet_original_*/*/*/*/*\", \n",
    "                                  existing_file_location = data_dest,\n",
    "                                  existing_filenames_file= 'data_filenames/files_read_BLM_tweet_original.csv')\n",
    "files_original.register_filename_reader(read_existing_filenames_csv)\n",
    "files_original.gather_filenames()\n",
    "for file in files_original.new_filenames: print(file.split(data_source)[1])\n",
    "\n",
    "# tweet data files: retweet\n",
    "files_retweet = FilenameGatherer(new_file_location = data_source, \n",
    "                                  new_file_prefix = \"BLM_tweet_retweet_*/*/*/*/*\", \n",
    "                                  existing_file_location = data_dest,\n",
    "                                  existing_filenames_file= 'data_filenames/files_read_BLM_tweet_retweet.csv')\n",
    "files_retweet.register_filename_reader(read_existing_filenames_csv)\n",
    "files_retweet.gather_filenames()\n",
    "for file in files_retweet.new_filenames: print(file.split(data_source)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"/Users/kotaminegishi/big_data_training/Python/dash_BLM/\"\n",
    "data_dest = \"/Users/kotaminegishi/big_data_training/Python/dash_BLM/\"\n",
    "\n",
    "files_1 = glob(data_source + \"BLM_tweet_original_*/*/*/*/*\")\n",
    "existing_files_1 = pd.read_csv(data_dest + 'data_filenames/files_read_BLM_tweet_original.csv')\n",
    "new_files_1 = [file for file in files_1 if file.split(data_source)[1] not in list(existing_files_1.name)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/kotaminegishi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kotaminegishi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/kotaminegishi/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kotaminegishi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kotaminegishi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon') \n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_files_to_df_json(files, orient='records', lines=False):\n",
    "    df = []\n",
    "    [ df.append(pd.read_json(file, orient=orient, lines=lines)) for file in files ]\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def convert_time(df, dst_pd_dt, timezone='US/Mountain', varname='created_at'):\n",
    "    dst = is_dst_pd_mtn(dst_pd_dt, timezone=timezone)\n",
    "    df[varname] = pd.to_datetime(df.created_at, unit='s') + pd.DateOffset(hours=-7 + dst*1) \n",
    "\n",
    "def add_time_floored_at_hour(df, varname='created_at', floored_varname='created_at_h'):\n",
    "    df[floored_varname] =  df[varname].dt.floor(\"h\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytz\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def is_dst(dt=None, timezone=\"UTC\"):\n",
    "    if dt is None:\n",
    "        dt = datetime.utcnow()\n",
    "    timezone = pytz.timezone(timezone)\n",
    "    timezone_aware_date = timezone.localize(dt, is_dst=None)\n",
    "    return timezone_aware_date.tzinfo._dst.seconds != 0\n",
    "\n",
    "def is_dst_pd_mtn(pd_dt, timezone='US/Mountain'):\n",
    "    return is_dst(pd_dt.to_pydatetime(), timezone=timezone)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DateOffset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import tokenize\n",
    "\n",
    "def get_clean_lemmatized_tokens(texts):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stopwords.extend(['#blacklivesmatter', '&amp;', 'please','retweet'])\n",
    "    \n",
    "    cleaned_tokens_list = []\n",
    "    for text in texts:\n",
    "        tokens = remove_noise(text.lower()).split()\n",
    "        clean_tokens = remove_stopwords(tokens, stopwords)\n",
    "        cleaned_tokens_list.append( \n",
    "            lemmatize_sentence(\n",
    "              clean_tokens\n",
    "            )\n",
    "        )\n",
    "    return cleaned_tokens_list\n",
    "\n",
    "def remove_noise(token):\n",
    "    token = re.sub('(https?://.*)|(www[.].*)','', token)\n",
    "    token = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", token)\n",
    "    token = re.sub(\"[.,!?]\",\" \", token)\n",
    "    return token\n",
    "\n",
    "def remove_stopwords(tokens, stopwords):\n",
    "    return [word for word in tokens if word not in stopwords]\n",
    "\n",
    "def lemmatize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence\n",
    "\n",
    "\n",
    "def join_token(token):\n",
    "    return \" \".join(str(word) for word in token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori1 = pd.read_json(files_original.new_filenames[0], orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['‚Äúhistory', 'written', 'harm', 'ones', 'harmed‚Äù\"they', 'keep', 'telling', \"there's\", 'nothing', 'called', 'white', 'privilege', 'give', 'break', '\"', 'must', 'watch', 'michael', 'holding', '(via', ')']\n",
      "[]\n",
      "['afternoon', 'wcu', 'community', 'including', 'students', 'faculty', 'staff', 'alumni', 'administration', 'gathered', 'wcu‚Äôs', 'campus', 'protest', 'event', 'consisted', 'moments', 'silence', 'taking', 'knee', 'speakers', 'remarks', 'commitment', 'work', 'together']\n",
      "[]\n",
      "['\"we\\'ve', 'looking', 'away', 'long', '\"', 'opens', 'experiences', 'racism', 'impact', 'killing', 'george', 'floyd', 'people', 'proud', 'wear', 'badges']\n",
      "['afternoon', 'wcu', 'community', 'including', 'students', 'faculty', 'staff', 'alumni', 'administration', 'gathered', 'wcu‚Äôs', 'campus', 'protest', 'event', 'consisted', 'moments', 'silence', 'taking', 'knee', 'speakers', 'remarks', 'commitment', 'work', 'together']\n",
      "['far', 'keep', 'playing', 'might', 'next', 'winner', 'üíØüèåÔ∏è']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['‚Äúhistory',\n",
       "  'write',\n",
       "  'harm',\n",
       "  'one',\n",
       "  'harmed‚Äù\"they',\n",
       "  'keep',\n",
       "  'tell',\n",
       "  \"there's\",\n",
       "  'nothing',\n",
       "  'call',\n",
       "  'white',\n",
       "  'privilege',\n",
       "  'give',\n",
       "  'break',\n",
       "  '\"',\n",
       "  'must',\n",
       "  'watch',\n",
       "  'michael',\n",
       "  'hold',\n",
       "  '(via',\n",
       "  ')'],\n",
       " [],\n",
       " ['afternoon',\n",
       "  'wcu',\n",
       "  'community',\n",
       "  'include',\n",
       "  'student',\n",
       "  'faculty',\n",
       "  'staff',\n",
       "  'alumnus',\n",
       "  'administration',\n",
       "  'gather',\n",
       "  'wcu‚Äôs',\n",
       "  'campus',\n",
       "  'protest',\n",
       "  'event',\n",
       "  'consist',\n",
       "  'moment',\n",
       "  'silence',\n",
       "  'take',\n",
       "  'knee',\n",
       "  'speaker',\n",
       "  'remark',\n",
       "  'commitment',\n",
       "  'work',\n",
       "  'together'],\n",
       " [],\n",
       " ['\"we\\'ve',\n",
       "  'look',\n",
       "  'away',\n",
       "  'long',\n",
       "  '\"',\n",
       "  'open',\n",
       "  'experience',\n",
       "  'racism',\n",
       "  'impact',\n",
       "  'kill',\n",
       "  'george',\n",
       "  'floyd',\n",
       "  'people',\n",
       "  'proud',\n",
       "  'wear',\n",
       "  'badge'],\n",
       " ['afternoon',\n",
       "  'wcu',\n",
       "  'community',\n",
       "  'include',\n",
       "  'student',\n",
       "  'faculty',\n",
       "  'staff',\n",
       "  'alumnus',\n",
       "  'administration',\n",
       "  'gather',\n",
       "  'wcu‚Äôs',\n",
       "  'campus',\n",
       "  'protest',\n",
       "  'event',\n",
       "  'consist',\n",
       "  'moment',\n",
       "  'silence',\n",
       "  'take',\n",
       "  'knee',\n",
       "  'speaker',\n",
       "  'remark',\n",
       "  'commitment',\n",
       "  'work',\n",
       "  'together'],\n",
       " ['far', 'keep', 'playing', 'might', 'next', 'winner', 'üíØüèåÔ∏è'],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clean_lemmatized_tokens(ori1.text[:10] + ori1.quoted_text[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import sys\n",
    "from nrclex import NRCLex\n",
    "from collections import Counter\n",
    "import itertools \n",
    "from copy import deepcopy\n",
    "from cached_property import cached_property\n",
    "\n",
    "class NewTweetData():\n",
    "    \n",
    "    def __init__(self, new_filenames, id_varname, current_time):\n",
    "        self.id_varname = id_varname\n",
    "        self.new_filenames = new_filenames\n",
    "        self.current_time = current_time\n",
    "        self.df_sentiments, self.df_top_emotions, self.df_count_words = [pd.DataFrame()] * 3\n",
    "        \n",
    "    @cached_property\n",
    "    def df(self): \n",
    "        if not self.new_filenames: return pd.DataFrame()\n",
    "        df = data_files_to_df_json(self.new_filenames, orient='records', lines=True)\n",
    "        convert_time(df, self.current_time, 'US/Mountain', varname='created_at')\n",
    "        add_time_floored_at_hour(df, floored_varname='created_at_h')\n",
    "        self.add_tokens_for_text_and_quoted_text(df)\n",
    "        return df.drop_duplicates(subset = [self.id_varname])\n",
    "        \n",
    "    @cached_property\n",
    "    def df_with_non_empty_tokens(self): \n",
    "        if len(self.df)==0: return pd.DataFrame()\n",
    "        return keep_if_var_is_nonempty(self.df, 'tokens')\n",
    "\n",
    "            \n",
    "    def add_tokens_for_text_and_quoted_text(self, df):\n",
    "        if hasattr(df, 'quoted_text'):\n",
    "                df['tokens'] = get_clean_lemmatized_tokens(df.text + df.quoted_text)\n",
    "        else:\n",
    "                df['tokens'] = get_clean_lemmatized_tokens(df.text)\n",
    "        \n",
    "    def assign_sentiments(self):\n",
    "        df = self.df_with_non_empty_tokens\n",
    "        if len(df): \n",
    "            sid = SentimentIntensityAnalyzer()\n",
    "            sentiments = []\n",
    "\n",
    "            for i, row in df.iterrows():\n",
    "                score = sid.polarity_scores(join_token(row['tokens']))\n",
    "                sentiments.append([row[self.id_varname], row['created_at_h']] + [score[key] for key in score])\n",
    "            self.df_sentiments = pd.DataFrame(sentiments,\n",
    "                                              columns = [self.id_varname, 'created_at_h'] + list(score.keys()))\n",
    "\n",
    "    def assign_emotions(self):\n",
    "        df = self.df_with_non_empty_tokens\n",
    "        if len(df):\n",
    "            nrc_1 = NRCLex(join_token(df['tokens'].iloc[0]))\n",
    "            emo_labels = nrc_1.affect_frequencies.keys()\n",
    "            top_emotions = []\n",
    "\n",
    "            for i, row in df.iterrows():\n",
    "                nrc = NRCLex(join_token(row['tokens']))\n",
    "                emos = [ i[0] for i in nrc.top_emotions]\n",
    "                top_emotions.append([row[self.id_varname], row['created_at_h']] + [i in emos for i in emo_labels])\n",
    "            self.df_top_emotions = pd.DataFrame(top_emotions,\n",
    "                                                columns = [self.id_varname, 'created_at_h'] + list(emo_labels))\n",
    "\n",
    "    def count_words(self):\n",
    "        df = deepcopy(self.df)\n",
    "        if len(df):\n",
    "            df['token_counter'] = df['tokens'].apply(lambda x: Counter(x))\n",
    "            self.df_words = df[[self.id_varname, 'created_at_h', 'token_counter']]\n",
    "\n",
    "    def assign_sentiments_and_wordcounts(self):\n",
    "        self.assign_sentiments()\n",
    "        self.assign_emotions()\n",
    "        self.count_words()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ori = NewTweetData(files_original.new_filenames, 'id', current_time)\n",
    "rt  = NewTweetData(files_retweet.new_filenames, 'RT_id', current_time):\n",
    "\n",
    "ori.assign_sentiments_and_wordcounts()\n",
    "rt.assign_sentiments_and_wordcounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚Äúhistory',\n",
       " 'write',\n",
       " 'harm',\n",
       " 'one',\n",
       " 'harmed‚Äù\"they',\n",
       " 'keep',\n",
       " 'tell',\n",
       " \"there's\",\n",
       " 'nothing',\n",
       " 'call',\n",
       " 'white',\n",
       " 'privilege',\n",
       " 'give',\n",
       " 'break',\n",
       " '\"',\n",
       " 'must',\n",
       " 'watch',\n",
       " 'michael',\n",
       " 'hold',\n",
       " '(via',\n",
       " ')']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.df_with_non_empty_tokens['tokens'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1281075466296688640</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1281075466955141120</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>{'‚Äúhistory': 1, 'write': 1, 'harm': 1, 'one': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1281075472454033408</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1281075472634466304</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>{'afternoon': 1, 'wcu': 1, 'community': 1, 'in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1281075489252143104</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14695</th>\n",
       "      <td>1281046366249086976</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14696</th>\n",
       "      <td>1281046366203121664</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>{'y‚Äôall': 1, 'stop': 1, 'hat': 1, '15': 1, 'ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14697</th>\n",
       "      <td>1281046367247441920</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14698</th>\n",
       "      <td>1281046368409141248</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14699</th>\n",
       "      <td>1281046369092792320</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14696 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id        created_at_h  \\\n",
       "0      1281075466296688640 2020-07-08 21:00:00   \n",
       "1      1281075466955141120 2020-07-08 21:00:00   \n",
       "2      1281075472454033408 2020-07-08 21:00:00   \n",
       "3      1281075472634466304 2020-07-08 21:00:00   \n",
       "4      1281075489252143104 2020-07-08 21:00:00   \n",
       "...                    ...                 ...   \n",
       "14695  1281046366249086976 2020-07-08 20:00:00   \n",
       "14696  1281046366203121664 2020-07-08 20:00:00   \n",
       "14697  1281046367247441920 2020-07-08 20:00:00   \n",
       "14698  1281046368409141248 2020-07-08 20:00:00   \n",
       "14699  1281046369092792320 2020-07-08 20:00:00   \n",
       "\n",
       "                                           token_counter  \n",
       "0                                                     {}  \n",
       "1      {'‚Äúhistory': 1, 'write': 1, 'harm': 1, 'one': ...  \n",
       "2                                                     {}  \n",
       "3      {'afternoon': 1, 'wcu': 1, 'community': 1, 'in...  \n",
       "4                                                     {}  \n",
       "...                                                  ...  \n",
       "14695                                                 {}  \n",
       "14696  {'y‚Äôall': 1, 'stop': 1, 'hat': 1, '15': 1, 'ti...  \n",
       "14697                                                 {}  \n",
       "14698                                                 {}  \n",
       "14699                                                 {}  \n",
       "\n",
       "[14696 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1281075466955141120</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.6818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1281075472634466304</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1281075491907055616</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.130</td>\n",
       "      <td>-0.7717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1281075492209164288</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1281075493211648000</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>1281046349098647552</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.5719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>1281046350961016832</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.6908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>1281046352462577664</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.7783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>1281046361102671872</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>1281046366203121664</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.0516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6419 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id        created_at_h    neg    neu    pos  compound\n",
       "0     1281075466955141120 2020-07-08 21:00:00  0.248  0.752  0.000   -0.6818\n",
       "1     1281075472634466304 2020-07-08 21:00:00  0.075  0.827  0.098    0.1531\n",
       "2     1281075491907055616 2020-07-08 21:00:00  0.368  0.502  0.130   -0.7717\n",
       "3     1281075492209164288 2020-07-08 21:00:00  0.075  0.827  0.098    0.1531\n",
       "4     1281075493211648000 2020-07-08 21:00:00  0.000  0.472  0.528    0.6808\n",
       "...                   ...                 ...    ...    ...    ...       ...\n",
       "6414  1281046349098647552 2020-07-08 20:00:00  0.000  0.802  0.198    0.5719\n",
       "6415  1281046350961016832 2020-07-08 20:00:00  0.000  0.551  0.449    0.6908\n",
       "6416  1281046352462577664 2020-07-08 20:00:00  0.257  0.668  0.075   -0.7783\n",
       "6417  1281046361102671872 2020-07-08 20:00:00  0.000  1.000  0.000    0.0000\n",
       "6418  1281046366203121664 2020-07-08 20:00:00  0.328  0.420  0.252    0.0516\n",
       "\n",
       "[6419 rows x 6 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.df_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticip</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1281075466955141120</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1281075472634466304</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1281075491907055616</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1281075492209164288</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1281075493211648000</td>\n",
       "      <td>2020-07-08 21:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>1281046349098647552</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>1281046350961016832</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>1281046352462577664</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>1281046361102671872</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6418</th>\n",
       "      <td>1281046366203121664</td>\n",
       "      <td>2020-07-08 20:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6419 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id        created_at_h   fear  anger  anticip  trust  \\\n",
       "0     1281075466955141120 2020-07-08 21:00:00  False  False     True   True   \n",
       "1     1281075472634466304 2020-07-08 21:00:00  False  False    False  False   \n",
       "2     1281075491907055616 2020-07-08 21:00:00  False  False    False  False   \n",
       "3     1281075492209164288 2020-07-08 21:00:00  False  False    False  False   \n",
       "4     1281075493211648000 2020-07-08 21:00:00  False   True     True   True   \n",
       "...                   ...                 ...    ...    ...      ...    ...   \n",
       "6414  1281046349098647552 2020-07-08 20:00:00  False  False    False  False   \n",
       "6415  1281046350961016832 2020-07-08 20:00:00   True   True     True   True   \n",
       "6416  1281046352462577664 2020-07-08 20:00:00  False  False    False  False   \n",
       "6417  1281046361102671872 2020-07-08 20:00:00  False  False    False  False   \n",
       "6418  1281046366203121664 2020-07-08 20:00:00  False  False    False   True   \n",
       "\n",
       "      surprise  positive  negative  sadness  disgust    joy  \n",
       "0        False      True      True     True     True  False  \n",
       "1        False      True     False    False    False  False  \n",
       "2        False     False      True    False    False  False  \n",
       "3        False      True     False    False    False  False  \n",
       "4         True      True      True     True    False   True  \n",
       "...        ...       ...       ...      ...      ...    ...  \n",
       "6414     False      True     False    False    False  False  \n",
       "6415      True      True      True     True     True   True  \n",
       "6416     False     False      True    False    False  False  \n",
       "6417     False      True     False    False    False  False  \n",
       "6418     False      True     False    False    False  False  \n",
       "\n",
       "[6419 rows x 12 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori.df_top_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt  = NewTweetData(files_retweet.new_filenames, 'RT_id', current_time)\n",
    "rt.assign_sentiments_and_wordcounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>token_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1279542869301227520</td>\n",
       "      <td>2020-07-04 16:00:00</td>\n",
       "      <td>{'freeway': 7, 'close': 7, '#diazlove': 1, '#s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280011731142664192</td>\n",
       "      <td>2020-07-05 23:00:00</td>\n",
       "      <td>{'üåµcalifornia': 1, 'patriot': 1, 'couple': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279350600703115264</td>\n",
       "      <td>2020-07-04 03:00:00</td>\n",
       "      <td>{'2': 1, 'protester': 1, 'run': 1, 'seattle': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1267799709957017600</td>\n",
       "      <td>2020-06-02 06:00:00</td>\n",
       "      <td>{'mean': 1, 'calm': 1, 'strong': 1, 'ü§î': 1, '#...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1272653236638560256</td>\n",
       "      <td>2020-06-15 16:00:00</td>\n",
       "      <td>{'#imagine': 1, 'news': 1, 'medium': 1, 'spend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1269089796422463488</td>\n",
       "      <td>2020-06-05 20:00:00</td>\n",
       "      <td>{'üó£üó£üó£üó£üó£üó£üó£üó£üó£': 1, 'kimberly': 1, 'i‚Äôm': 1, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1268965667048321024</td>\n",
       "      <td>2020-06-05 11:00:00</td>\n",
       "      <td>{'beautiful': 1, 'together': 1, 'shall': 1, 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1280255356413849600</td>\n",
       "      <td>2020-07-06 15:00:00</td>\n",
       "      <td>{'business': 1, 'owner': 1, 'protect': 1, 'wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1268944647142780928</td>\n",
       "      <td>2020-06-05 10:00:00</td>\n",
       "      <td>{'heard': 1, 'put': 1, 'statement': 1, 'suppos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1265997903987986432</td>\n",
       "      <td>2020-05-28 07:00:00</td>\n",
       "      <td>{'riot': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RT_id        created_at_h  \\\n",
       "0    1279542869301227520 2020-07-04 16:00:00   \n",
       "1    1280011731142664192 2020-07-05 23:00:00   \n",
       "2    1279350600703115264 2020-07-04 03:00:00   \n",
       "3    1267799709957017600 2020-06-02 06:00:00   \n",
       "4    1272653236638560256 2020-06-15 16:00:00   \n",
       "..                   ...                 ...   \n",
       "178  1269089796422463488 2020-06-05 20:00:00   \n",
       "179  1268965667048321024 2020-06-05 11:00:00   \n",
       "180  1280255356413849600 2020-07-06 15:00:00   \n",
       "181  1268944647142780928 2020-06-05 10:00:00   \n",
       "182  1265997903987986432 2020-05-28 07:00:00   \n",
       "\n",
       "                                         token_counter  \n",
       "0    {'freeway': 7, 'close': 7, '#diazlove': 1, '#s...  \n",
       "1    {'üåµcalifornia': 1, 'patriot': 1, 'couple': 1, ...  \n",
       "2    {'2': 1, 'protester': 1, 'run': 1, 'seattle': ...  \n",
       "3    {'mean': 1, 'calm': 1, 'strong': 1, 'ü§î': 1, '#...  \n",
       "4    {'#imagine': 1, 'news': 1, 'medium': 1, 'spend...  \n",
       "..                                                 ...  \n",
       "178  {'üó£üó£üó£üó£üó£üó£üó£üó£üó£': 1, 'kimberly': 1, 'i‚Äôm': 1, 'imp...  \n",
       "179  {'beautiful': 1, 'together': 1, 'shall': 1, 'p...  \n",
       "180  {'business': 1, 'owner': 1, 'protect': 1, 'wha...  \n",
       "181  {'heard': 1, 'put': 1, 'statement': 1, 'suppos...  \n",
       "182                                        {'riot': 1}  \n",
       "\n",
       "[183 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1279542869301227520</td>\n",
       "      <td>2020-07-04 16:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.3400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280011731142664192</td>\n",
       "      <td>2020-07-05 23:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279350600703115264</td>\n",
       "      <td>2020-07-04 03:00:00</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.7003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1267799709957017600</td>\n",
       "      <td>2020-06-02 06:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1272653236638560256</td>\n",
       "      <td>2020-06-15 16:00:00</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.154</td>\n",
       "      <td>-0.2960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1269089796422463488</td>\n",
       "      <td>2020-06-05 20:00:00</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1268965667048321024</td>\n",
       "      <td>2020-06-05 11:00:00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1280255356413849600</td>\n",
       "      <td>2020-07-06 15:00:00</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.244</td>\n",
       "      <td>-0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1268944647142780928</td>\n",
       "      <td>2020-06-05 10:00:00</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.8225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1265997903987986432</td>\n",
       "      <td>2020-05-28 07:00:00</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RT_id        created_at_h    neg    neu    pos  compound\n",
       "0    1279542869301227520 2020-07-04 16:00:00  0.000  0.588  0.412    0.3400\n",
       "1    1280011731142664192 2020-07-05 23:00:00  0.000  1.000  0.000    0.0000\n",
       "2    1279350600703115264 2020-07-04 03:00:00  0.453  0.547  0.000   -0.7003\n",
       "3    1267799709957017600 2020-06-02 06:00:00  0.000  0.517  0.483    0.6808\n",
       "4    1272653236638560256 2020-06-15 16:00:00  0.161  0.685  0.154   -0.2960\n",
       "..                   ...                 ...    ...    ...    ...       ...\n",
       "177  1269089796422463488 2020-06-05 20:00:00  0.152  0.690  0.159    0.0258\n",
       "178  1268965667048321024 2020-06-05 11:00:00  0.000  0.506  0.494    0.5994\n",
       "179  1280255356413849600 2020-07-06 15:00:00  0.394  0.363  0.244   -0.5994\n",
       "180  1268944647142780928 2020-06-05 10:00:00  0.313  0.647  0.040   -0.8225\n",
       "181  1265997903987986432 2020-05-28 07:00:00  1.000  0.000  0.000   -0.5574\n",
       "\n",
       "[182 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.df_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT_id</th>\n",
       "      <th>created_at_h</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticip</th>\n",
       "      <th>trust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1279542869301227520</td>\n",
       "      <td>2020-07-04 16:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1280011731142664192</td>\n",
       "      <td>2020-07-05 23:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1279350600703115264</td>\n",
       "      <td>2020-07-04 03:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1267799709957017600</td>\n",
       "      <td>2020-06-02 06:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1272653236638560256</td>\n",
       "      <td>2020-06-15 16:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1269089796422463488</td>\n",
       "      <td>2020-06-05 20:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1268965667048321024</td>\n",
       "      <td>2020-06-05 11:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1280255356413849600</td>\n",
       "      <td>2020-07-06 15:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1268944647142780928</td>\n",
       "      <td>2020-06-05 10:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1265997903987986432</td>\n",
       "      <td>2020-05-28 07:00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   RT_id        created_at_h   fear  anger  anticip  trust  \\\n",
       "0    1279542869301227520 2020-07-04 16:00:00   True  False    False  False   \n",
       "1    1280011731142664192 2020-07-05 23:00:00   True   True    False  False   \n",
       "2    1279350600703115264 2020-07-04 03:00:00  False  False    False  False   \n",
       "3    1267799709957017600 2020-06-02 06:00:00  False  False    False  False   \n",
       "4    1272653236638560256 2020-06-15 16:00:00  False  False    False  False   \n",
       "..                   ...                 ...    ...    ...      ...    ...   \n",
       "177  1269089796422463488 2020-06-05 20:00:00   True   True     True   True   \n",
       "178  1268965667048321024 2020-06-05 11:00:00  False  False    False  False   \n",
       "179  1280255356413849600 2020-07-06 15:00:00  False  False    False  False   \n",
       "180  1268944647142780928 2020-06-05 10:00:00  False  False    False  False   \n",
       "181  1265997903987986432 2020-05-28 07:00:00   True   True    False  False   \n",
       "\n",
       "     surprise  positive  negative  sadness  disgust    joy  \n",
       "0       False     False     False    False    False  False  \n",
       "1       False     False      True     True     True  False  \n",
       "2       False     False      True    False    False  False  \n",
       "3       False     False      True     True    False  False  \n",
       "4       False     False      True    False    False  False  \n",
       "..        ...       ...       ...      ...      ...    ...  \n",
       "177      True      True      True     True     True   True  \n",
       "178     False      True     False    False    False   True  \n",
       "179     False     False      True    False    False  False  \n",
       "180     False     False      True     True     True  False  \n",
       "181      True     False      True    False    False  False  \n",
       "\n",
       "[182 rows x 12 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.df_top_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(or_df, or_data, ref_data):\n",
    "    if or_data is None: return()\n",
    "    \n",
    "    col_data = [*or_data.columns]\n",
    "    \n",
    "    ref_data['RT_id'] = ref_data['RT_id'].astype(str) \n",
    "    \n",
    "    or_non_empty = or_df[or_df.RT_id != '']\n",
    "    \n",
    "    if len(or_non_empty)>0:\n",
    "        retweeted_data = (\n",
    "            or_non_empty[['id','RT_id','created_at_h']]\n",
    "            .join(ref_data.set_index('RT_id'), \n",
    "                   on='RT_id', rsuffix='_rt')\n",
    "            )\n",
    "\n",
    "        df_merged = (\n",
    "            or_data.reset_index()[['id','created_at_h', *col_data]] \n",
    "            .append(retweeted_data[['id','created_at_h', *col_data]])\n",
    "            )\n",
    "        \n",
    "        print('Num rows = {} + {} = {}'\n",
    "          .format(len(or_data), len(retweeted_data), len(df_merged)))\n",
    "        return df_merged\n",
    "   \n",
    "    else: \n",
    "        print('Num rows = {}'.format(len(or_data)))\n",
    "        return or_data.reset_index()[['id','created_at_h', *col_data]] \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentiments = merge_datasets(or_df = ori.df, \n",
    "                                or_data = ori.df_sentiments, \n",
    "                                ref_data = ref_sentiments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_matching_rt_data(ori_df, ori_data, rt_data):\n",
    "    if not len(ori_data): return pd.DataFrame()\n",
    "    col_data = [*ori_data.columns]\n",
    "    ori_matched = get_matching_rt_data(ori_df, rt_data)\n",
    "    \n",
    "    if len(ori_matched):\n",
    "        df_appended = (\n",
    "            ori_data\n",
    "            .append(ori_matched[[*col_data]])\n",
    "            )\n",
    "        print('Num rows = original:{} + retweet:{} = total:{}'\n",
    "          .format(len(ori_data), len(ori_matched), len(df_appended)))\n",
    "        return df_appended \n",
    "   \n",
    "    else: \n",
    "        print('Num rows = original:{}'.format(len(ori_data)))\n",
    "        return or_data\n",
    "\n",
    "def get_matching_rt_data(ori_df, rt_data): \n",
    "    convert_vars_to_str(rt_data,['RT_id']) \n",
    "    ori_to_be_matched = keep_if_var_is_nonempty(ori_df, 'RT_id')\n",
    "    \n",
    "    if len(ori_to_be_matched):\n",
    "        matched_data = (\n",
    "            ori_to_be_matched[['id','RT_id','created_at_h']]\n",
    "            .join(rt_data.set_index('RT_id'), \n",
    "                   on='RT_id', rsuffix='_rt')\n",
    "            )\n",
    "        return matched_data\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stats from cumulative retweet to match with new data\n",
    "retweets = pd.read_json(data_dest + \"data_cumulative/retweet/2020_all_retweets.json\",\n",
    "     lines=True, orient='records')\n",
    "rt_sentiments = pd.read_csv(data_dest + \n",
    "    'data_cumulative/retweet/2020_all_sentiments.csv')\n",
    "rt_emotions = pd.read_csv(data_dest + \n",
    "    'data_cumulative/retweet/2020_all_emotions.csv')\n",
    "rt_words = pd.read_json(data_dest + \n",
    "    'data_cumulative/retweet/2020_all_words.json', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_and_drop_duplicates(df1, df2, subset):\n",
    "    return df1.append(df2).drop_duplicates(subset = subset)\n",
    "\n",
    "retweets = append_and_drop_duplicates(rt_retweet, rt.df, 'RT_id')\n",
    "rt_sentiments = append_and_drop_duplicates(rt_sentiments, rt.df_sentiments, 'RT_id')\n",
    "rt_emotions = append_and_drop_duplicates(rt_emotions, rt.df_top_emotions, 'RT_id')\n",
    "rt_words = append_and_drop_duplicates(rt_words, rt.df_words, 'RT_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updated cumulative data: retweet, retweet-words, sentiments, and emotions.\n"
     ]
    }
   ],
   "source": [
    "file_rt_loc = 'data_cumulative/retweet/'\n",
    "retweets.to_json(f'{data_dest}{file_rt_loc}2020_retweets.json', orient='records', lines=True)\n",
    "rt_words.to_json(f'{data_dest}{file_rt_loc}2020_rt_words.json', orient='records', lines=True)\n",
    "rt_sentiments.to_csv(f'{data_dest}{file_rt_loc}2020_rt_sentiments.csv', index=False) \n",
    "rt_emotions.to_csv(f'{data_dest}{file_rt_loc}2020_rt_emotions.csv', index=False) \n",
    "print('  Updated cumulative data: retweet, retweet-words, sentiments, and emotions.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows = original:6419 + retweet:12597 = total:19016\n",
      "Num rows = original:6419 + retweet:12597 = total:19016\n",
      "Num rows = original:14696 + retweet:12597 = total:27293\n"
     ]
    }
   ],
   "source": [
    "new_sentiments = append_matching_rt_data(ori.df, ori.df_sentiments, rt_sentiments)\n",
    "new_emotions = append_matching_rt_data(ori.df, ori.df_top_emotions, rt_emotions)\n",
    "new_words = append_matching_rt_data(ori.df, ori.df_words, rt_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Updated cumulative data: sentiments, emotions, words, and original.\n"
     ]
    }
   ],
   "source": [
    "# add new data into cumulative datasets\n",
    "time_as_filename = 'created_at_' + current_time_str.replace(\" \",\"_\")\n",
    "new_sentiments.to_csv(f'{data_dest}data_cumulative/sentiments/{time_as_filename}.csv', index=False)\n",
    "new_emotions.to_csv(f'{data_dest}data_cumulative/emotions/{time_as_filename}.csv', index=False)\n",
    "new_words.to_json(f'{data_dest}data_cumulative/words/{time_as_filename}.json', orient='records', lines=True)\n",
    "ori.df.to_json(f'{data_dest}data_cumulative/original/{time_as_filename}.json', orient='records', lines=True)\n",
    "print('  Updated cumulative data: sentiments, emotions, words, and original.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-59-32-a87bf603-d4d9-4315-b39c-3b9d1299c933',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-34-25-16f86d7c-2aa1-48e1-95ea-6d18e5e0c923',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-04-16-0dd357ff-17b6-4a6d-9571-dfb448b6f16e',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-19-21-9ef8ea83-4b1f-42d9-97aa-d6da6aace8c2',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-44-27-ec48a273-4b33-4553-abe8-1e31f806cc32',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-54-31-19d40465-fb9a-40ea-b947-bec0a87b04d1',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-29-23-8996e450-61f4-462b-bf03-758958814624',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-24-22-36c9cda4-1104-40b9-b661-df8eacb1834d',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-49-27-cf1951bb-809d-498d-98b8-4878ec9e69f9',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-14-19-44186211-5109-4b4c-bd65-8c86d29aed4d',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-39-26-9d0fe52e-8b78-4c63-850b-b9e09a6eb879',\n",
       " 'BLM_tweet_original_2020/07/09/03/BLM_tweet_original_delivery-1-2020-07-09-03-09-17-cd1a59aa-6249-4990-9673-b4787c85aaa8',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-49-12-768cbda2-1131-40c0-b878-54c5ed7bf72b',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-13-59-446c29a7-9f70-4f81-a470-23c520486cc3',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-54-14-6f18c336-0f51-41d8-abdf-ba2376503c98',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-59-14-be72dc45-9208-4099-b183-8d4e7207df47',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-03-56-329c4689-3387-4554-bed4-1adb3bad9ce1',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-19-02-d1c2d2ce-0e49-4d67-a0f6-9ddab2c9c4cc',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-24-04-33e5b4d3-cd4c-4859-b579-1ebf10bb5124',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-08-58-06ff6b4d-9f69-4e50-a272-69ca90bf6754',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-44-11-30d5ca9e-6869-4635-97e8-7c2651d154cd',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-29-05-7b97d696-d7f1-4785-a269-f96bc20db7b3',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-34-06-a422307c-6246-41c5-8f8b-a86c151187ad',\n",
       " 'BLM_tweet_original_2020/07/09/02/BLM_tweet_original_delivery-1-2020-07-09-02-39-07-f8c5e37c-1ebc-4186-a334-4b2942d80d58',\n",
       " 'BLM_tweet_original_2020/07/09/01/BLM_tweet_original_delivery-1-2020-07-09-01-53-55-dd471521-1fd7-4edb-92b7-5b713d8f9ea7',\n",
       " 'BLM_tweet_original_2020/07/09/01/BLM_tweet_original_delivery-1-2020-07-09-01-58-54-89732852-7988-4be4-bf6f-416c8f8239f4']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_original.new_filenames_without_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'created_at',\n",
       " 'is_retweet',\n",
       " 'RT_id',\n",
       " 'RT_retweet_count',\n",
       " 'user_id',\n",
       " 'user_name',\n",
       " 'followers_count',\n",
       " 'following_count',\n",
       " 'text',\n",
       " 'quoted_text',\n",
       " 'RT_text',\n",
       " 't_co',\n",
       " 'tags',\n",
       " 'urls',\n",
       " 'lang',\n",
       " 'created_at_h',\n",
       " 'tokens']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append new file names \n",
    "if len(ori.df):\n",
    "    new_files_1s = [file.split(data_source)[1] for file in new_files_1]\n",
    "\n",
    "    pd.DataFrame(new_files_1s, \n",
    "             columns = {'name'}\n",
    "            ).to_csv(data_dest + 'data_filenames/files_read_BLM_tweet_original_updated.csv', \n",
    "                     mode='a', header=False, index=False)\n",
    "\n",
    "if len(rt.df): \n",
    "    new_files_2s = [file.split(data_source)[1] for file in new_files_2]\n",
    "\n",
    "    pd.DataFrame(new_files_2s, \n",
    "             columns = {'name'}\n",
    "            ).to_csv(data_dest + 'data_filenames/files_read_BLM_tweet_retweet_updated.csv', \n",
    "                     mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "if new_original: del new_sentiments, new_emotions, new_words, ori, rt\n",
    "if new_retweet: del cum_retweet, ref_sentiments, ref_emotions, ref_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'created_at_h', 'neg', 'neu', 'pos', 'compound']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
